## 消息队列（MQ）
记录学习消息队列的的笔记，基本资料来源于https://github.com/doocs/advanced-java ，推荐阅读

### 消息队列的用处
1.消息队列主要的应用场景是解耦，异步和削峰：

解耦：当一个系统的需要调用多个系统去发送业务数据时，耦合性太强，导致新增其他系统或删除其他系统接口调用时需要修改代码，而且还需要考虑在调用过程中系统宕机之后数据应该如何处理等，这样考虑的方面就太多了，如果使用MQ，直接将数据发送到MQ，其他系统自己去消费数据，其他系统新增或取消数据调用就很方便，而且数据的维护就放在了其他系统中，减小了主系统的复杂程度。

异步：一个系统的业务逻辑需要调用其他多个系统，调用链太长，导致响应返回时间过长，体验太差，使用MQ把调用数据发送到MQ，其他系统自己去消费相关消息，主系统响应速度大大提升。

削峰：主要是在短时间的对高并发进行限制，防止系统崩溃，MQ设置最大并发量，高并发时保证多余的请求堆积在MQ中，在后面的时间再去慢慢消费，确保系统不会崩溃。

2.消息队列的优缺点：

优点：

解耦，异步和削峰

缺点：

1.系统可用性降低：引入MQ导致系统增加外部依赖，宕机的可能性增加，同时需要保证MQ的高可用才能保证系统的正常运行

2.系统的复杂性提高：引入MQ需要考虑额外的问题，消息的重复消费，消费顺序，消息丢失等

3.一致性问题：多个系统消费MQ消息，但是其中一个或多个系统消费失败，导致数据出现不一致的情况。

所以，引入MQ会使系统的复杂度提升，需要考虑清楚之后再接入。

### 消息队列对比
![timewoo](https://timewoo.github.io/images/MQ1.png)

### 消息队列的高可用
#### RabbitMQ 的高可用性：RabbitMQ是基于主从来实现高可用，主要有三种模式，单机，集群和镜像集群，主要记录集群和集群镜像
1.集群（非高可用）：在多台服务器上启动多个RabbitMQ的实例，但是元数据和实际的数据只存在一台服务器上，其他实例去同步元数据和实际数据，当消费请求到达其他实例上时，
实例会从元数据的实例上拉取数据，只是不同的集群，并不是分布式，也无法做到高可用，因为元数据的服务器宕机后其他实例就无法拉取数据，系统就挂了，所以这个只是为了提高消息的吞吐量。

2.镜像集群（高可用）：消息的元数据和实际数据存在于多个实例上，每个RabbitMQ节点都有一个元数据的镜像，写消息时会同步到所有的节点上，好处是可以所有节点都有全部的数据，
任意节点宕机都不影响系统的正常运行，坏处是性能开销大，而且不是分布式的，无法有效拓展，因为所有数据都会同步到所有服务器上，数据量大时横向拓展无效。
那么如何开启这个镜像集群模式呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，
也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。

#### Kafka 的高可用性：
1.Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，
每个 partition 就放一部分数据。这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。

2.kafka 0.8以前没有HA机制（High Availability, 高可用性），任一服务器宕机后存储在上面的数据就无法读取和写入，无法做到高可用。
0.8以后采用副本机制，即每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本，所有的replica选举一个leader来进行生产和消费，
其他replica就是follower，leader会将写入的数据同步到所有的follower，如果一个节点宕机后，它在其他服务器上还有副本，可以保证系统的正常运行，而且如果leader所在服务器宕机后，
其它的follower会选举出一个新的leader来保证读写的正常运行，确保高可用。

3.kafka的同步复制机制 生产者写数据时选择leader节点写入，写入磁盘之后其他follower主动从leader节点拉取数据，一旦follower拉取完数据之后就发送ack给leader，
leader收到所有follower的ack之后就返回生产者写入成功。消费时会从leader节点去读数据，但是只有所有follower返回ack之后，消息才会被消费者获取到。

#### RocketMQ 的高可用：架构类似于kafka，一个broker包含多个topic，一个topic存放在多个broker上，这样保证了分布式的集群，同时提供了master/slave的结构，slave定时从master同步数据，如果master宕机，则slave提供消费服务，但是不能写入消息。这样就保证了高可用
1.单个Master：这种方式风险较大，一旦Broker 重启或者宕机时，会导致整个服务不可用，不建议线上环境使用。

2.多Master模式：优点：配置简单，单个Master 宕机或重启维护对应用无影响，在磁盘配置为 RAID10 时，即使机器宕机不可恢复情况下，由于 RAID10 磁盘非常可靠，
消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢）。性能最高。缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到受到影响。

3.多 Master 多 Slave 模式，异步复制：优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，因为 Master 宕机后，消费者仍然可以从 Slave 消费，此过程对应用透明。不需要人工干预。性能同多 Master 模式几乎一样。缺点：Master 宕机，磁盘损坏情况，会丢失少量消息。

4.多 Master 多 Slave 模式，同步双写：优点：数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高。缺点：性能比异步复制模式略低，大约低 10%左右，发送单个消息的 RT 会略高。目前主宕机后，备机不能自动切换为主机，后续会支持自动切换功能。

### 消息队列的幂等性
#### kafka消费模式: 有一个offset的概念，即每个消息写入时都分配一个offset，相当于编号，然后消费者消费数据之后，定时定期将消费的offset提交，这样就保证服务器在宕机后重启会在offset的位置继续消费。
问题：如果服务器宕机后发生在提交offset之前，那么服务器重启之后就会从原来的offset位置消费数据，就会出现重复消费。

#### RabbitMQ消费模式：

#### RocketMQ消费模式：

#### 解决：由于MQ适用场景复杂，所以需要在业务中根据具体的场景去保证，主要的解决类型：1.数据库的存储需要保证唯一，存在则更新，2.redis是天然幂等性，每次都是set，3.其他场景,需要给消息分配一个唯一id，消费时在redis中查询是否存在，存在则已经消费过，不重复消费。

### 消息队列的可靠性
#### 数据丢失的场景
1.生产者丢失消息：生产者在发送到MQ的时候丢失了消息，消息并没有发送到MQ

RabbitMQ：提供事务功能，生产者在发送数据之前开启RabbitMQ事务channel.txSelect，然后发送消息，如果消息丢失，生产者报错，就可以回滚事务channel.txRollback，然后就重试发送消息，如果收到消息，那么就可以提交channel.txCommit。但是这样同步机制会导致吞吐量会下来，因为太消耗性能，所以为了确保消息不丢失，可以开启confirm模式，在生产者设置confirm模式，每次消息会分配一个唯一id，如果消息写入RabbitMQ会给回传生产者ack消息，如果RabbitMQ没处理消息，就会回调nack接口，告诉生产者消息接收失败，然后生产者就会重试，还可以在生产者处维护id状态，超时重试。事务是同步的，confirm是异步，所以一般采用confirm机制

Kafka：只要设置acks=all，就不会丢失，只有leader的收到消息，并且所有follower都同步到消息之后才认为这次写成功，否则就会无限重试。

2.MQ丢失消息：MQ在存储数据的时候丢失

RabbitMQ：开启持久化，这样服务器重启后还可以从磁盘恢复数据，就算没有持久化到磁盘，也只是丢失少量数据。设置持久化的步骤是：1.创建queue的时候将其设置为持久化，就保证queue的元数据，但不会持久化queue内的数据，2.生产者发送消息时将消息的deliveryMode为2，设置消息为持久化。只有两个都设置才不会丢失数据，同时持久化只会丢失一点数据，同时持久化可以和生产者的confirm机制配合，只有消息被持久化到磁盘后，才通知生产者ack，所以即使在持久化之前服务器宕机，也可以重试。

Kafka：Kafka的follower正在同步leader数据时，leader所在的服务器宕机，导致follower数据没有同步完成，然后follower开始重新选举新的leader，就会导致新的leader的数据会丢失。为了不丢失数据，最少需要4个参数：1.给topic设置replication.factor，必须大于1，就是要求每个partitioni最少有2个副本。2.在服务端设置min.insync.replicas，必须大于1，要求一个leader可以感知到一个follow，这样就确保leader宕机后还存在一个follower。3.在生产者端设置acks=all，这样就会要求每条数据写入所有副本之后才会认为写成功。4.在生产者端设置retries=MAX,写入失败就会无限重试，直到写入成功为止。这样就保证服务器宕机后切换leader数据不会丢失。

3.消费端丢失消息：消费者消费时处理消息异常，无法重试

RabbitMQ：关闭MQ的自动ack机制，通过在程序中确保消息处理成功之后发送ack，超时就会将消息发送给其他的消费者消费，消息就不会丢失。

Kafka：和RabbitMQ类似，关闭自动提交offset，这样在处理过程完成后才提交offset，确保数据不会丢失，但是还有一种情况，就是处理完成提交offset之前就宕机，这样还是会出现重复消费的情况，所以需要保证幂等性。

### 消息队列的顺序
#### 适用场景：mysql同步数据将binlog的日志发送到MQ，MQ依次消费写入同步库，必须保证数据的操作顺序。
RabbitMQ：拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

![timewoo](https://timewoo.github.io/images/MQ2.png)

Kafka：1.一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。2.写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

![timewoo](https://timewoo.github.io/images/MQ3.png)

### 消息队列延时、失效和存储满
#### 消息队列积压消息
先处理消费者的问题，保证消费者正常，然后新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。然后部署临时分发程序，消费到信息后分发queue，然后扩容服务器部署消费者，消费queue，相当于部署临时分发程序来发消息，等积压的消息消费完在恢复系统。

#### 消息队列消息过期
RabbitMQ可以设置过期时间，就是TTL，如果消息在queue中积压超过一定时间就会被清理掉，只有手动去重新批量导入数据。

#### 消息队列存储慢
先将消息消费并且丢弃掉，快速将积压的消息处理掉，然后在空闲的时间手动去批量补导数据。

### 如何设计一个MQ
#### 基本方向：1.支持可伸缩性，可以快速扩容，采用分布式的概念，即broker->topic->partition,每个partition放一个机器，存储一部分数据，类型kafka的架构。2.MQ持久化的考虑，顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。3.MQ高可用，多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。4.数据丢失问题。

### RocketMq:

RocketMq主要由四大部分组成，NameServer，Broker，Producer和Consumer。四个部分都可以各自组成集群，NameServer主要是负责对源数据的管理，包括对topic
和路由信息的管理，类似Dubbo中的Zookeeper，但是比Zookeeper相比较更轻量级，NameServer节点之间互相独立，没有信息交互。NameServer主要是维护心跳和提供
Topic-Broker的关系数据，Broker启动时会向NameServer注册，Producer在发送消息时会根据Topic到NameServer获取Broker路由信息，Consumer也会定时获取
topic的信息。Broker时消息中转角色，负责存储消息，转发消息，Broker是具体提供业务的服务器，单个Broker节点与所有的NameServer节点保持长连接以及心跳，并且
会定时将topic信息注册到NameServer，Broker主要用来消息存储，以topic为维度支持轻量级的队列。Producer是消息生产者，负责产生消息，一般由业务系统负责产生消息。
消息通过Producer发送到Broker集群，提供同步发送，异步发送和单向发送三种，同步发送是指在发送方发送数据后需要得到接受方的响应后才会发送下个消息，用于重要的通知
消息，比如重要的邮件信息，营销信息。异步发送是指发送方发送数据后不需要接受方的响应即可发送下个消息，一般用于链路时间长并且对响应时间敏感的业务场景。比如用户视频
上传后通知启动转码服务。单向发送是指只负责向服务器发送消息而不需要等待服务器响应并且没有回调函数的触发，一般用于耗时短并且可靠性不高的场景，比如日志采集。Consumer
是消息消费者，负责消费消息，一般是后台系统负责异步消费。Consumer支持PUSH和PULL两种消费模式，支持集群消费和广播消息，提供实时的消息订阅机制。PULL是消费者主动
从服务器拉取消息，只要批量拉取到消息就会启动消费，是主动消费型。PUSH是将消息的拉取，消费进度和内部维护工作进行封装，只暴露消息到达时的回调执行接口给应用程序，
是被动消费型，PUSH内部还是会去拉取消息，和PULL不同的是PUSH需要注册监听器，当监听器触发时进行消费。

topic是消息的一级分类，tag是消息的二级分类，比如topic可以分成订单类消息，推送类消息等，tag就是对应topic下的二级分类，比如退款消息，支付成功消息等，group是
指一类相同的Producer或Consumer，即多个相同的服务消费时需要指定相同的group，同时需要有相同的消费逻辑。

rocketMq的延迟消息是生产者在发送消息时指定一个延时时间，当到达延时消息之后消息才会投送到消费者。rocketMq的延迟消息并不支持任意时间片，仅支持18个固定的时间段，
默认是1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h，分别代表18个延迟等级，主要流程是当所有延迟消息到达broker后，会存放到SCHEDULE_TOPIC_XXX
的topic下，这个topic比较特殊，对客户端是不可见的，包括使用rocketmq-console，也查不到这个topic。SCHEDULE_TOPIC_XXX下存在18个队列，每个队列中存放的消息
都是同一个延迟级别消息。broker端启动一个timer和timerTask的任务，定时从这个topic中拉取数据，如果延迟时间到了就会把消息发送到指定topic下进行消费。即通过
SCHEDULE_TOPIC_XXX来中转消息。

rocketMq的事务消息是生产者发送消息时能够保证本地事务和消息发送的原子性。生产者发送消息到rocketMq时消息会标识为prepare，这时不会发送到消费端，生产者会进行
本地事务的执行，执行完成后会给prepare消息发送commit或rollback消息，收到commit响应的prepare就会发送到消费端去消费，而收到rollback响应的prepare就会丢弃
该消息，保证本地事务和消息发送保持一致，一般在分布式事务中使用，但是事务消息不保证消费端的事务，消费端如果消费失败可以才用重试机制来保证消费端的事务执行。

rockerMq死信队列是指当消费者未成功消费消息，返回Reconsume_later给rocketMq的broker时，rocketMq就会将该消息放入重试队列中，一般是%RETRY%+consumergroup的名字，
重试的消息会在延迟的某个时间点，默认是10s，进行再一次的投送到消费者，若重试次数到达最大重试次数，默认是16，消费者还是消费失败，rocketMq不会直接丢弃该消息而是放入到
死信队列中，这种不能被正常消费的消息称为死信消息(Dead-Letter Message)，存储死信消息的队列称为死信队列(Dead-Letter Queue,DLQ)。死信队列中的消息不会被消费者
正常消费，一般情况下DLQ对消费者不可见。死信消息存储的有效期和正常消息相同，均为3天，3天后自动清除。所以需要在3天内对死信消息进行处理。每个死信队列对应一个groupId，每个
消费组都有一个死信队列。如果groupId没有产生死信消息，rocketMq不会为该group创建死信队列。一个死信队列包含对应group下的所有死信消息，对于同一个group共享同一个死信队列。
由于死信队列对消费者不可见，所以只能在rocketMq的console界面才能发送死信队列的消息。对于死信消息的处理可以重新在控制台重新发送消息，也可以在控制台将死信消息发送到原来
的topic中重新进行消费，但是需要保证消息消费的幂等性。