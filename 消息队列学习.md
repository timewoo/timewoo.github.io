## 消息队列（MQ）
记录学习消息队列的的笔记，基本资料来源于https://github.com/doocs/advanced-java ，推荐阅读

### 消息队列的用处
1.消息队列主要的应用场景是解耦，异步和削峰：
解耦：当一个系统的需要调用多个系统去发送业务数据时，耦合性太强，导致新增其他系统或删除其他系统接口调用时需要修改代码，而且还需要考虑在调用过程中系统宕机之后数据应该如何处理等，这样考虑的方面就太多了，如果使用MQ，直接将数据发送到MQ，其他系统自己去消费数据，其他系统新增或取消数据调用就很方便，而且数据的维护就放在了其他系统中，减小了主系统的复杂程度。

异步：一个系统的业务逻辑需要调用其他多个系统，调用链太长，导致响应返回时间过长，体验太差，使用MQ把调用数据发送到MQ，其他系统自己去消费相关消息，主系统响应速度大大提升。

削峰：主要是在短时间的对高并发进行限制，防止系统崩溃，MQ设置最大并发量，高并发时保证多余的请求堆积在MQ中，在后面的时间再去慢慢消费，确保系统不会崩溃。

2.消息队列的优缺点：
优点：解耦，异步和削峰

缺点：
1.系统可用性降低：引入MQ导致系统增加外部依赖，宕机的可能性增加，同时需要保证MQ的高可用才能保证系统的正常运行

2.系统的复杂性提高：引入MQ需要考虑额外的问题，消息的重复消费，消费顺序，消息丢失等

3.一致性问题：多个系统消费MQ消息，但是其中一个或多个系统消费失败，导致数据出现不一致的情况。

所以，引入MQ会使系统的复杂度提升，需要考虑清楚之后再接入。

### 消息队列对比
![timewoo](https://timewoo.github.io/images/MQ1.png)

### 消息队列的高可用
#### RabbitMQ 的高可用性：RabbitMQ是基于主从来实现高可用，主要有三种模式，单机，集群和镜像集群，主要记录集群和集群镜像
1.集群（非高可用）：在多台服务器上启动多个RabbitMQ的实例，但是元数据和实际的数据只存在一台服务器上，其他实例去同步元数据和实际数据，当消费请求到达其他实例上时，
实例会从元数据的实例上拉取数据，只是不同的集群，并不是分布式，也无法做到高可用，因为元数据的服务器宕机后其他实例就无法拉取数据，系统就挂了，所以这个只是为了提高消息的吞吐量。

2.镜像集群（高可用）：消息的元数据和实际数据存在于多个实例上，每个RabbitMQ节点都有一个元数据的镜像，写消息时会同步到所有的节点上，好处是可以所有节点都有全部的数据，
任意节点宕机都不影响系统的正常运行，坏处是性能开销大，而且不是分布式的，无法有效拓展，因为所有数据都会同步到所有服务器上，数据量大时横向拓展无效。
那么如何开启这个镜像集群模式呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，
也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。

#### Kafka 的高可用性：
1.Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，
每个 partition 就放一部分数据。这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。

2.kafka 0.8以前没有HA机制（High Availability, 高可用性），任一服务器宕机后存储在上面的数据就无法读取和写入，无法做到高可用。
0.8以后采用副本机制，即每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本，所有的replica选举一个leader来进行生产和消费，
其他replica就是follower，leader会将写入的数据同步到所有的follower，如果一个节点宕机后，它在其他服务器上还有副本，可以保证系统的正常运行，而且如果leader所在服务器宕机后，
其它的follower会选举出一个新的leader来保证读写的正常运行，确保高可用。

3.kafka的同步复制机制 生产者写数据时选择leader节点写入，写入磁盘之后其他follower主动从leader节点拉取数据，一旦follower拉取完数据之后就发送ack给leader，
leader收到所有follower的ack之后就返回生产者写入成功。消费时会从leader节点去读数据，但是只有所有follower返回ack之后，消息才会被消费者获取到。

#### RocketMQ 的高可用：架构类似于kafka，一个broker包含多个topic，一个topic存在多个broker，这样保证了分布式的集群，同时提供了master/slave的结构，slave定时从master同步数据，如果master宕机，则slave提供消费服务，但是不能写入消息。这样就保证了高可用
1.单个Master：这种方式风险较大，一旦Broker 重启或者宕机时，会导致整个服务不可用，不建议线上环境使用。

2.多Master模式：优点：配置简单，单个Master 宕机或重启维护对应用无影响，在磁盘配置为 RAID10 时，即使机器宕机不可恢复情况下，由于 RAID10 磁盘非常可靠，
消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢）。性能最高。缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到受到影响。

3.多 Master 多 Slave 模式，异步复制：优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，因为 Master 宕机后，消费者仍然可以从 Slave 消费，此过程对应用透明。不需要人工干预。性能同多 Master 模式几乎一样。缺点：Master 宕机，磁盘损坏情况，会丢失少量消息。

4.多 Master 多 Slave 模式，同步双写：优点：数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高。缺点：性能比异步复制模式略低，大约低 10%左右，发送单个消息的 RT 会略高。目前主宕机后，备机不能自动切换为主机，后续会支持自动切换功能。

### 消息队列的幂等性
#### kafka消费模式: 有一个offset的概念，即每个消息写入时都分配一个offset，相当于编号，然后消费者消费数据之后，定时定期将消费的offset提交，这样就保证服务器在宕机后重启会在offset的位置继续消费。
问题：如果服务器宕机后发生在提交offset之前，那么服务器重启之后就会从原来的offset位置消费数据，就会出现重复消费。

#### RabbitMQ消费模式：

#### RocketMQ消费模式：

#### 解决：由于MQ适用场景复杂，所以需要在业务中根据具体的场景去保证，主要的解决类型：1.数据库的存储需要保证唯一，存在则更新，2.redis是天然幂等性，每次都是set，3.其他场景,需要给消息分配一个唯一id，消费时在redis中查询是否存在，存在则已经消费过，不重复消费。

### 消息队列的可靠性
#### 数据丢失的场景
1.生产者丢失消息：生产者在发送到MQ的时候丢失了消息，消息并没有发送到MQ

RabbitMQ：提供事务功能，生产者在发送数据之前开启RabbitMQ事务channel.txSelect，然后发送消息，如果消息丢失，生产者报错，就可以回滚事务channel.txRollback，然后就重试发送消息，如果收到消息，那么就可以提交channel.txCommit。但是这样同步机制会导致吞吐量会下来，因为太消耗性能，所以为了确保消息不丢失，可以开启confirm模式，在生产者设置confirm模式，每次消息会分配一个唯一id，如果消息写入RabbitMQ会给回传生产者ack消息，如果RabbitMQ没处理消息，就会回调nack接口，告诉生产者消息接收失败，然后生产者就会重试，还可以在生产者处维护id状态，超时重试。事务是同步的，confirm是异步，所以一般采用confirm机制

Kafka：只要设置acks=all，就不会丢失，只有leader的收到消息，并且所有follower都同步到消息之后才认为这次写成功，否则就会无限重试。

2.MQ丢失消息：MQ在存储数据的时候丢失

RabbitMQ：开启持久化，这样服务器重启后还可以从磁盘恢复数据，就算没有持久化到磁盘，也只是丢失少量数据。设置持久化的步骤是：1.创建queue的时候将其设置为持久化，就保证queue的元数据，但不会持久化queue内的数据，2.生产者发送消息时将消息的deliveryMode为2，设置消息为持久化。只有两个都设置才不会丢失数据，同时持久化只会丢失一点数据，同时持久化可以和生产者的confirm机制配合，只有消息被持久化到磁盘后，才通知生产者ack，所以即使在持久化之前服务器宕机，也可以重试。

Kafka：Kafka的follower正在同步leader数据时，leader所在的服务器宕机，导致follower数据没有同步完成，然后follower开始重新选举新的leader，就会导致新的leader的数据会丢失。为了不丢失数据，最少需要4个参数：1.给topic设置replication.factor，必须大于1，就是要求每个partitioni最少有2个副本。2.在服务端设置min.insync.replicas，必须大于1，要求一个leader可以感知到一个follow，这样就确保leader宕机后还存在一个follower。3.在生产者端设置acks=all，这样就会要求每条数据写入所有副本之后才会认为写成功。4.在生产者端设置retries=MAX,写入失败就会无限重试，直到写入成功为止。这样就保证服务器宕机后切换leader数据不会丢失。

3.消费端丢失消息：消费者消费时处理消息异常，无法重试

RabbitMQ：关闭MQ的自动ack机制，通过在程序中确保消息处理成功之后发送ack，超时就会将消息发送给其他的消费者消费，消息就不会丢失。

Kafka：和RabbitMQ类似，关闭自动提交offset，这样在处理过程完成后才提交offset，确保数据不会丢失，但是还有一种情况，就是处理完成提交offset之前就宕机，这样还是会出现重复消费的情况，所以需要保证幂等性。

### 消息队列的顺序
#### 适用场景：mysql同步数据将binlog的日志发送到MQ，MQ依次消费写入同步库，必须保证数据的操作顺序。
RabbitMQ：拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。
![timewoo](https://timewoo.github.io/images/MQ2.png)

Kafka：1.一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。2.写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。
![timewoo](https://timewoo.github.io/images/MQ3.png)

### 消息队列延时、失效和存储满
#### 消息队列积压消息
先处理消费者的问题，保证消费者正常，然后新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。然后部署临时分发程序，消费到信息后分发queue，然后扩容服务器部署消费者，消费queue，相当于部署临时分发程序来发消息，等积压的消息消费完在恢复系统。

#### 消息队列消息过期
RabbitMQ可以设置过期时间，就是TTL，如果消息在queue中积压超过一定时间就会被清理掉，只有手动去重新批量导入数据。

#### 消息队列存储慢
先将消息消费并且丢弃掉，快速将积压的消息处理掉，然后在空闲的时间手动去批量补导数据。

### 如何设计一个MQ
#### 基本方向：1.支持可伸缩性，可以快速扩容，采用分布式的概念，即broker->topic->partition,每个partition放一个机器，存储一部分数据，类型kafka的架构。2.MQ持久化的考虑，顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。3.MQ高可用，多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。4.数据丢失问题。