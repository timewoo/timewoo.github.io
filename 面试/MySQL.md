# MySQL

## MySQL存储引擎：

MyISAM在5.5之前是MySQL默认的存储引擎，性能很快，同时提供大量的特性，包括全文索引，压缩，空间函数等。但是MyISAM不支持事务和行级锁，同时在MySQL崩溃后无法安全的恢复，所以在5.5之后引入了InnoDB(事务性数据库引擎)，在MySQL 8.0中，InnoDB作为默认的MySQL存储引擎。大部分情况下MySQL都选择InnoDB，但是如果不考虑数据崩溃和事务，同时需要高密集的读操作，可以尝试MyISAM，但是在目前的需求下一般都要考虑这些场景。

区别：InnoDB支持行锁(row-level)和表锁，默认是行锁，MyISAM只支持表锁；MyISAM强调是性能，每次查询都是原子性，所以其执行速度比InnoDB快，但是不支持事务，InnoDB支持事务和外键，是具有事务回滚和崩溃修复能力的事务安全型表；MyISAM不支持外键，InnoDB支持外键；InnoDB支持MVCC，用来应对高并发。

## MySQL字符集和校对规则：

字符集是指一种从二进制编码到某类字符符号的映射，校对规则是指在某种字符集下的排序规则，比如在不同的校对规则下，相同数据的排序规则可能会有差异。MySQL采用类似继承的方式指定字符集，即表在没有指定字符集的情况下默认使用数据库的字符集。

## 索引：

MySQL的索引存储的数据结构主要有BTree索引和哈希索引。哈希索引底层是哈希表，适用于对于单条数据的查询，查询很快，比如=或者<=>表达式，但是对于其他表示式不会使用索引，比如<或者范围查询。所以在ORDER BY时也无法使用索引，因为无法获取下一条数据。而且Hash索引只能查询完整的key，无法像BTree一样使用前缀索引。其他场景一般使用BTree索引，BTree索引使用B树中的B+Tree，MyISAM中的BTree索引实现是非聚簇索引，即B+Tree的叶子节点data域中存放的是数据记录的地址，在索引检索时，首先按照B+Tree搜索算法搜索索引，如果key存在，则取出节点的data域的值，然后再通过data的地址值找到对应的数据。InnoDB主索引采用聚簇索引，因为InnoDB数据文件本身就是索引文件，MyISAM中数据和索引是分开的，而InnoDB的数据本身按照B+Tree组织成一个索引结构，节点的data域存放的就是数据本身，索引key是数据表的主键，因此InnoDB的数据本身就是主索引，其他索引称为辅助索引，辅助索引是非聚簇索引，辅助索引的节点data域存放的是数据的主键，InnoDB在根据主索引搜索时，直接找到主键的节点，取出data域的数据即可，而根据辅助索引搜索时，会先找到主键的值，然后再在主索引上找到数据，因此，表的主键字段不易过长，也不建议使用非单调的字段作为主键，避免主索引频繁分裂。其实聚簇索引和非聚簇索引与MySQL的存储引擎并没有强关联，MyISAM的索引使用非聚簇索引，InnoDB主索引使用聚簇索引，辅助索引使用非聚簇索引。

## 缓存：

MySQL可以在my.cnf中加入配置来开启缓存，在相同查询条件以及数据情况下，会直接返回缓存中的数据，相同条件包括查询条件，查询数据库，客户端的版本协议等一些可能会影响结果的条件，因此在不同字符上会导致缓存不命中，同时查询中包含用户自定义函数，存储函数，用户变量，临时表，MySQL的系统表，查询结果也不会被缓存。
当缓存建立后，MySQL缓存查询系统会跟踪查询中涉及的每张表，如果表结构或数据发生变化，缓存也会失效。虽然缓存能够提升查询效率，但是也带来了额外开销，每次查询都需要进行缓存操作，缓存失效后还需要销毁，得不偿失，而且在开启缓存后，缓存就很可能成为性能的瓶颈，所以MySQL8去掉了缓存的设置。

## 事务：

事务是指逻辑上的一组操作，要么都成功，有么都失败。事务拥有ACID的特性：

- A：Atomicity，原子性，事务是最小的执行单位，不允许分割，事务的原子性保证动作要么全部完成，要么全部失败。

- C：Consistency，一致性，执行事务后，数据库从一个正确状态转到另一个正确状态。

- I：Isolation，隔离性，并发访问数据库时，一个用户的事务不会被其他事务所干扰，各并发事务之间数据库是相互独立的。

- D：Durability，持久性，一个事务被提交后，它对数据库数据的改变是持久的，即使数据库发生故障也不会对其有影响。

由于数据库多线程操作比较常见，所以数据库在并发事务可能会造成脏读，修改丢失，不可重复读和幻读四种类型。

- 脏读(Dirty read)：是指一个事务在修改数据还未提交时，另一个事务访问到了还未提交的数据，由于数据未提交，后续可能发生回滚，所以另一个事务读的就是脏数据。
- 修改丢失(Lost to modify)：是指在并发事务中，一个事务修改了另一个事务的提交数据，导致事务的修改被丢失了。
- 不可重复读(Non-repeatable read)：是指一个事务多次访问同一数据，在访问过程中另一个事务修改了相关数据，导致事务多次访问同一数据得到的结果不一样。
- 幻读(Phantom read)：类似不可重复读，是指在一个事务中多次读取数据时另一个事务插入或删除了相关数据，导致事务多次访问获取的数据数量不一致。幻读和不可重复读的区别是一个是多次访问发现数据有删除或新增，一个是多次访问同一数据发现数据被修改。

为了应对并发事务之间出现的问题，sql标准设置了四种事务隔离级别，读取未提交，读取已提交，可重复读，可串行化。

- 读取未提交(READ-UNCOMMITTED)：是最低的隔离级别，允许读取到事务未提交的数据变更，可能导致脏读，幻读，不可重复读。
  
- 读取已提交(READ-COMMITTED)：允许读取到事务已经提交的数据变更，可能导致幻读和不可重复读。

- 可重复读(REPEATABLE-READ)：是指对同一个字段的多次读取结果都是一致的，除非数据本身被自身的事务修改，可能导致幻读。

- 可串行化(SERIALIZABLE)：是最高级别的隔离，是完全服从ACID原则，就是事务之间的顺序是串行化的，可以防止脏读，幻读和不可重复读。

MySQL的InnoDB默认的事务隔离级别是可重复读，但是InnoDB实现可重复读的同时可以避免幻读，主要实现原理根据sql的查询方式不一样，直接select是通过mvcc来通过快照读来实现一个事务中的查询都是在快照中获取，不会被其他事务操作影响，通过select for update查询时主要是通过使用Next-key Lock算法，即通过record+gap 锁定一个范围，包含记录本身，一般是锁定一个范围，其他事务在需要修改这个范围内的数据时会等待，所以可以解决幻读问题，即MySQL的可重复读的实现已到达sql隔离的可串行化标准。由于隔离级别越高，需要加锁越多，所以大部分数据库的隔离级别是读取提交内容。InnoDB的可重复读虽然可以避免幻读，但是在分布式的情况下无法做到事务隔离，所以分布式情况下选用串行化隔离。

## MySQL锁：

### InnoDB锁类型：

- 共享锁和排它锁（Shared and Exclusive Locks）：InnoDB基于读写锁的概念实现的两类标准行级锁，共享锁和排它锁。

  - 共享锁（S）：允许获取锁的事务读取对应的行记录，不同的事务可以读取锁定的记录，也可以获取其他的共享锁。
  - 排它锁（X）：允许获取锁的事务更新或者删除对应的行记录，同一时间只能有一种锁，阻止其他事务加锁，依赖于数据库的隔离级别，可能阻止其他事务写入同一行或者读取同一行。InnoDB默认的隔离级别（Repeatable Read）通过允许事务读取排它锁的行记录来提升并发。

  不同的事务可以对相同的行记录获取共享锁，排它锁同一时间只能有一个事务获取锁，其他事务在获取锁时需要等待。在表级锁中也存在共享锁和排他锁的概念，只是作用的范围不同，行级锁是锁住对应行的记录，表级锁是锁住整个表。

- 意向锁（Intention Locks）：InnoDB实现的一种特殊的表级锁，为了支持多粒度的锁机制而设计的，可以实现行级锁和表级锁共存。作用是表级锁在获取锁时可以快速进行锁冲突的判断，比如对一张表加表锁时需要判断两步，第一步是判读是否已有表级排它锁，第二步是判断是否已有行级锁。对于第二步，就需要判断表中的每一行数据，在表数据较大时效率比较低下。因此InnoDB设计了意向锁，在事务获取行级锁时同时设置对应的意向锁，这样在其他事务加表锁时就只需要判断意向锁，将时间复杂度O(N)变成O(1)，提高了加锁的效率。

  - 意向共享锁（Intention Shared Locks，IS）：当事务获取行级共享锁时需要设置意向共享锁，代表表中存在行级共享锁。
  - 意向排它锁（Intention Exclusive Locks，IX）：当事务获取行级排它锁时需要设置意向排它锁，代表表中存在行级排它锁。

  表级锁和意向锁的兼容性如下：

  |      | X    | IX   | S    | IS   |
  | ---- | ---- | ---- | ---- | ---- |
  | X    | 冲突 | 冲突 | 冲突 | 冲突 |
  | IX   | 冲突 | 兼容 | 冲突 | 兼容 |
  | S    | 冲突 | 冲突 | 兼容 | 兼容 |
  | IS   | 冲突 | 兼容 | 兼容 | 兼容 |

  当锁兼容时事务可以获取锁，当锁不兼容时事务需要等待锁释放才能获取锁。

  意向锁只会阻塞表级锁的请求，比如LOCK TABLES ... WRITE。意向锁的目的是为了标识表中已存在行级锁或正在使用行级锁。

  意向锁无法通过用户手动获取和释放，只能通过系统自动操作维护。可以通过SHOW ENGINE INNODB STATUS或者InnoDB  monitor输出：

  ```mysql
  TABLE LOCK table `test`.`t` trx id 10080 lock mode IX
  ```

- 记录锁（Record Locks) ：记录锁是对索引记录进行加锁，比如使用SELECT c1 FROM t WHERE c1=10 FOR UPDATE，就会对t.c1=10的记录加锁，其他事务无法插入，更新，删除对应的记录。记录锁总是锁定的是索引的记录，当表没有显示的指定索引时，InnoDB会默认创建一个隐藏的聚簇索引来作为记录锁的锁定索引。可以通过SHOW ENGINE INNODB STATUS或者InnoDB  monitor输出：

  ```mysql
  RECORD LOCKS space id 58 page no 3 n bits 72 index `PRIMARY` of table `test`.`t`
  trx id 10078 lock_mode X locks rec but not gap
  Record lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 0
   0: len 4; hex 8000000a; asc     ;;
   1: len 6; hex 00000000274f; asc     'O;;
   2: len 7; hex b60000019d0110; asc        ;;
  ```

- 间隙锁（Gap Locks）：间隙锁是在索引记录之间加锁，或者是在第一个索引之前以及最后一个索引之后加锁，比如使用SELECT c1  FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE，就会对t.c1 10-20之间的记录加锁，其他事务无法在10-20之间插入数据比如15，即使当前表中没有对应的数据。

  间隙锁可能跨越了单个索引值，多个索引值，甚至是空值。

  间隙锁是为了平衡性能和并发的一种考虑，主要是为了避免幻读，并且只会在某些隔离级别中才会存在。（REPEATABLE-READ）

  当使用唯一索引搜索唯一的记录时，并不会触发间隙锁。比如当使用SELECT * FROM t WHERE id = 100，只会使用记录锁锁定id=100的记录，至于其他事务是否在前面插入数据并不重要。但是当id不是索引或者不是唯一索引时，将会锁住id=100之前的记录。因为当id不是唯一索引时，如果不锁住间隙，其他事务可以插入其他数据，导致出现幻读。

  不同的事务可以在同一个间隙内持有冲突的间隙锁，比如事务A持有gap S-lock，事务B可以在相同的间隙内持有gap X-lock。原因是当索引记录删除时需要将不同事务的gap锁合并，如果间隙锁也存在冲突的话，对于mysql的并发影响较大，毕竟间隙锁唯一的目的只是防止在间隙内插入数据，只会和插入操作有冲突，其他间隙锁没有冲突。

  如果使用READ-COMMITTED隔离级别时，gap对索引和搜索禁用，只会做外键约束和重复键检查。

  需要注意的是当查询的条件不存在时，gap会将查询前后的间隙锁住，比如当使用SELECT * FROM t WHERE id = 100时，如果表中无相关数据，会将查询值前后存在的记录锁住，比如99~105。如果在同一个事务中存在插入操作时，比如不存在则更新时，在高并发情况下会出现死锁，因为两个事务会锁住相同间隙，同时插入时有需要等待对方释放锁，所以会造成死锁。

- Next-Key Locks：将记录锁和间隙锁结合的锁机制，锁住当前索引以及索引之前的间隙。

  当表中存在索引记录10，11，13，20时，对应的next-key会锁住对应的范围：

  ```
  (negative infinity, 10]
  (10, 11]
  (11, 13]
  (13, 20]
  (20, positive infinity)
  ```

  InnoDB在REPEATABLE-READ隔离级别下，通过next-key lock来避免幻读。

  可以通过SHOW ENGINE INNODB STATUS或者InnoDB  monitor输出：

  ```
  RECORD LOCKS space id 58 page no 3 n bits 72 index `PRIMARY` of table `test`.`t`
  trx id 10080 lock_mode X
  Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0
   0: len 8; hex 73757072656d756d; asc supremum;;
  
  Record lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 0
   0: len 4; hex 8000000a; asc     ;;
   1: len 6; hex 00000000274f; asc     'O;;
   2: len 7; hex b60000019d0110; asc        ;;
  ```

- 插入意向锁（Insert Intention Locks）：
- AUTO-INC Locks：
- Predicate Locks for Spatial Indexs：

MyISAM采用表级锁(table-level locking)，InnoDB采用行级锁(row-level locking)和表级锁，默认为行级锁。表级锁是MySQL中粒度最大的一种锁，是对当前整张表进行加锁，实现简单，资源消耗较少，加锁比较快，也不会出现死锁，但是触发锁冲突的概率最高，并发度最低。行级锁是MySQL粒度最小的一种锁，只是针对当前操作的行进行加锁，行级锁能够大大减少锁冲突的概率，并发度最高，但是加锁的开销也大，加锁也慢，容易出现死锁。InnoDB的行锁算法主要有Record lock(单行索引记录上的加锁)，Gap lock(间隙锁，锁定的一个范围内的索引记录，不包括查询的记录)和Next-key lock(record+gap，锁定一个范围内的索引记录，包括查询的记录本身)。InnoDB默认查询使用的是Next-key lock，但是在查询的是唯一索引时会将next-key lock降级为record lock，Gap间隙锁是为了阻止多个事务将记录插入同一范围，或在同一范围删除记录，防止幻读。可以在MySQL中设置事务隔离级别为RC，或者设置innodb_locks_unsafe_for_binlog为1来显示的关闭Gap锁。

## mvcc(多版本控制)：

mvcc是指多版本控制，是用来提升数据库并发的一种技术，在早期的数据库中，只要涉及到写操作都会加锁，引入多版本控制后，只有写写操作才会加锁，这样就提升了InnoDB的并发度，
InnoDB在数据更新时将旧数据存放在undo log日志文件中，通过undo log日志可以找到旧数据给用户读(按照隔离的级别，有些读请求只能看到旧数据)，同时可以在回滚的时候根据
undo log日志来覆盖数据，同时在InnoDB内部会记录一个全局的活跃读写的事务组，用来判断事务之间的可见性。mvcc可以通过乐观锁和悲观锁来实现，同时mvcc只能在读取已提交和
可重复读的隔离级别下工作。

在MySQL中，会维护一个全局的trx_sys事务链，是一个链表结构，保存的都是没有提交的事务，当事务提交之后就会从trx_sys事务链中删除。
read view(读视图)类似一个事务的快照存储结构，主要是用来做可见性判断的，保存的是对本事务不可见的其他活跃事务，主要存储low_limit_id(当前事务链中最大的事务编号+1)，
up_limit_id(当前事务链中最小的事务编号)和trx_ids(当前事务链中的事务编号集合)，read View存储的是当前所有的活跃事务编号，即未提交的事务的集合，但是不包含当前事务。
InnoDB在不同隔离级别下生成read view的时机也不同，在可重复读级别下，事务在begin/start transaction之后的第一条select语句后会创建一个read view，将当前的活跃事务
存储起来，在整个事务中都使用这一个read view，而在读取已提交级别下，事务的所有查询语句都会重新创建一个read view，将原来的read view重置。因此在读取提交级别下，
read view内的活跃事务结合可能有变化，导致出现幻读和不可重复读出现。undo log是InnoDB实现mvcc事务的主要组成，当数据发生变更时，会在undo log文件中记录老版本的数据，
5.6之前默认存储在系统表空间中(ibdata)，5.6之后可以使用独立的Undo表空间。旧数据的事务需要读取数据时，当前行不可见的情形下需要根据undo链来找到满足可见性的数据记录，
当undo链很长时可能会比较耗时。INSERT操作在事务提交前对当前事务可见，而且只有在事务回滚时才需要，所以产生undo日志在事务提交后可以删除，InnoDB归为insert_log,
而对于UPDATE和DELETE需要维护多版本的信息，不仅在事务回滚时需要，而且在读一致性也需要，只有在read view不需要该日志记录时，才会被purge日志，因此在InnoDB这两种操作
产生的undo日志被归为update_undo。InnoDB会在每行数据添加三个隐藏字段，DB_TRX_ID(6字节的事务id，标识最近一次修改(insert|update)的数据的事务id)，DB_ROLL_PTR(7字节
undo log日志中回滚段的记录，即如何回滚的sql语句)，DB_ROW_ID(递增的字段，当未指定主键或唯一索引时，默认根据字段生成聚簇索引)

mvcc的实现主要通过可见性算法，即比较DB_TRX_ID和read view中low_limit_id，up_limit_id的大小，当DB_TRX_ID<up_limit_id，说明数据的修改事务在当前事务之前已经提交，
则当前事务直接获取数据，当DB_TRX_ID>=low_limit_id，说明数据的修改事务在当前事务之后开启，在当前事务内提交，读取的数据被其他事务修改，数据不可见，就会在undo log日志
去寻找当前数据的旧版本数据，如果旧版本数据的事务id<up_limit_id，则获取这个事务id的数据，当up_limit_id<=DB_TRX_ID<low_limit_id，则会遍历read view中的trx_ids，
如果DB_TRX_ID不在trx_ids集合内，说明事务已经提交了，则数据是可见的，如果DB_TRX_ID在trx_ids集合内，并且和当前事务id相同的话就是当前事务修改的，所以也是可见的，如果
DB_TRX_ID在trx_ids集合内并且不和当前事务id一致，则有未提交的事务，数据不可见。

## 索引详解：

索引能够大大加快数据检索的速度，帮助服务器避免排序和临时表，将随机IO变为顺序IO，可以加快表和表之间的关联，创建唯一索引可以保证数据的唯一性。但是给表加索引并不一定可以
加快查询效率，因为对表中数据新增，修改和删除时，需要额外维护索引，索引需要占用额外的的物理空间，同时创建索引和维护索引需要耗费额外时间，所以不能随便建立索引。

MySQL中索引主要有两种，哈希索引和BTree索引，哈希索引底层是哈希表，在单条数据查询时效率较高，但是哈希索引不支持顺序和范围查找。BTree索引在不同的存储引擎实现不一样，一般
都是将BTree实现为B+Tree，原因是BTree所有的节点都包含索引key和data域，B+Tree树只有叶子节点存放key和data域，其他节点只存放索引key；BTree的叶子节点是独立的，B+Tree
的叶子节点有一条引用链指向和它相邻的叶子节点；BTree的搜索位置不确定，可能匹配到任意节点，而B+Tree最后匹配的都是叶子节点。
在MyISAM中主要是B+Tree的叶子节点的data域存放的是数据记录的地址，在索引检索时，首先按照B+Tree的搜索算法查询索引，key存在则取出对应的data域的数据地址，然后通过地址去查询对应数据的值，
这个称为非聚簇索引；在InnoDB中数据文件和索引文件是一体的，按照B+Tree组织成一个结构，叶子节点data域保存完整的数据记录，用主键作为索引的key的是主索引，也称为聚簇索引，
而用其他字段作为索引的称为辅助索引，叶子节点的data域存储的是主键的值，然后再根据主键值查询主索引。因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，
这样会造成主索引频繁分裂。

索引按照存储索引key类型主要分为主键索引和辅助索引，主键索引(Primary key)是指使用主键作为索引key，主键索引又称为聚簇索引，在InnoDB中，当没有显示的指定主键时，会
判断是否有唯一索引的字段，如果有，就将该字段的默认为主键，否则就会自动创建一个6byte的自增主键。辅助索引是指索引的叶子节点的data域存储的是主键，根据索引key获取记录
主键，然后再去主键索引查询具体记录，唯一索引，普通索引，前缀索引，全文索引等属于辅助索引，唯一索引是指作为索引的字段不能出现重复，但是允许null值，一张表可以创建多个唯一索引，
唯一索引一般是为了保证字段值的唯一性，并不是为了查询效率。普通索引是一般的索引，允许null值和重复值，一张表可以创建多个普通索引，主要是为了查询效率。前缀索引是指对
字符串类型字段，只对前几个字符创建索引，索引数据小。全文索引主要是为大文本数据的关键字建立索引，MySQL 5.6之前只有MyISAM支持全文索引，5.6之后InnoDB也支持。
覆盖索引是指索引内包含所有需要查询的字段的值，由于在使用辅助索引需要查询两次表，所以覆盖索引在节点存储的key是要查询的字段值，比如对(username,age)建立覆盖索引，则
索引的key是包含username和age的两个字段的值，当根据key查询到索引位置时，可以直接返回覆盖索引包含的字段值，不需要在根据叶子节点的主键值再去查询主索引，提高查询效率。
索引又可以分为聚簇索引和非聚簇索引，主要是看B+Tree的叶子节点data存储的是数据类型，存储的是记录的就是聚簇索引，例如主键索引，其他的则是非聚簇索引，例如MyISAM存储
记录的地址，辅助索引存储主键的值。聚簇索引缺点是需要依赖于有序的数据，因为B+Tree是多路的平衡树，如果索引不是有序的，就需要在插入时排序，如果索引很长，则插入或查找
就会很慢，同时更新代价大。非聚簇索引缺点也是需要依赖于有序数据，而且获取的时主键的值，可能需要进行回表(二次查询)。

索引主要依靠MySQL的存储格式，MySQL存储数据的基本格式是页。

![timewoo](https://timewoo.github.io/images/mysql.jpg)

![timewoo](https://timewoo.github.io/images/mysql1.jpg)

MySQL将数据存储为多个页，每个数据页可以组成一个双向的链表，每个数据页存储的记录内部又形成一个单向链表，由于数据页中的记录按照主键排序，所以会将内部的记录分成一个个组，
然后将每组的最大记录按照顺序存储在一起，形成页目录，在通过主键查询记录时先遍历数据页获取记录存储的数据页，然后通过对页目录进行二分法查询对应记录的所存储的槽，也就是分组，
再遍历槽中的记录获取指定记录。如果不是主键查询的话，在获取记录所在的数据页后，只能遍历数据页中的所有记录来获取指定记录，查询时间很慢。时间复杂度是O(n)。
由于默认数据页是无序的，所以需要遍历查询数据页才能获取记录存储的位置，索引主要是对数据页排序，查询时能够快速找到对应的数据页。索引使用B+Tree结构，所有节点的结构都是数据页，
但是非叶子节点存储的是索引key和对应的子节点的数据页标识，只有在叶子节点存储索引key和data域记录，数据页内部是经过排序的，所以能够根据索引key快速找到对应的叶子数据页，再获取到
叶子数据页上的准确数据。

![timewoo](https://timewoo.github.io/images/mysql2.jpg)

![timewoo](https://timewoo.github.io/images/mysql3.jpg)

最左前缀原则是在创建联合索引，即多个字段以一定的顺序生成索引时，例如(username,age,sex)，在查询语句中出现的查询条件精确匹配索引的左边一列或多列，那么可以命中索引，
即where username = xxx and age = xxx和where username = xxx可以命中索引，但是where age = xxx不能命中索引。如果查询条件全部匹配但是顺序不一致，查询引擎会
自动优化为匹配索引的顺序，即where age = xxx and username = xxx and sex = xxx，可以命中索引。所以在创建联合索引时，应该考虑将使用频繁的字段放在左边。同时应该避免冗余索引，
即是索引的功能相同，能够命中就肯定能命中，比如(username,age)和(username)都能命中，所以需要尽量扩展而不是创建新索引。即只要查询条件中包含最左的索引就可以命中索引，
就算不是严格按照索引顺序，引擎也会自动优化成匹配索引的顺序。至于为什么需要最左匹配才能命中索引是和InnoDB的B+Tree索引结构决定的，当建立联合索引时，索引值有是多个，B+Tree非
叶子节点上存储多个key值，叶子节点的data域存储所有的索引key和主键id，B+Tree在构建时先根据最左边的key排序，在最左边key相同的情况下在根据key的创建顺序构建。即(a,b,c)联合索引，
非叶子节点按照先按照a排序，非叶子节点中a相同的按照b排序，b相同的按照c排序。因此在B+Tree中a是有序的，但是b，c是无序的。因此在联合索引中出现范围查询时，范围查询后面的字段无法使用索引，
比如a>1 and b=2，a可以命中索引b不行，因为a查询的是一个范围，而b只是在a相同的情况下才是有序，在a的范围中是无序的，所以无法命中索引。

![timewoo](https://timewoo.github.io/images/mysql4.png)

索引应该在需要经常搜索的字段上创建，比如where后面。在经常排序的字段上，因为索引已经排过序了，可以加快排序的时间。避免在索引字段上使用函数，这样会使索引无法命中。
在表关联字段上加索引可以加快连接速度。可以使用自增字段作为主键索引。索引字段值尽量不设置为null，虽然设置为null不影响索引的效率，但是null需要更多的空间存储且无法参与
某些运算，同时由于InnoDB将null值认为是最小的值，所以null值都是存储在B+Tree的最左边，当查询条件是IS NULL时是可以命中索引，因为null在B+Tree的最左边，但是IS NOT NULL
就不行。对于冗余索引尽量删除，减少性能消耗。尽可能建立联合索引而不是单个索引，在!=或者<>时也不会命中索引，like中匹配%xx%也不会命中索引。

对于BTree索引，在对column使用表达式时可以命中索引，比如=,>,>=,<,<=或者BETWEEN。在使用LIKE时，如果LIKE的参数不是以%通配符开头的常量时也可以命中索引，比如LIKE 'Patrick%' OR LIKE 'Pat%_ck%'。在使用IS NULL时也会命中索引。

## MySQL备份和恢复：

MySQL的crash-safe是指在任意时间段内奔溃，重启后之前提交的数据都不会丢失。MySQL的crash-safe主要是保证InnoDB事务中的数据不丢失，因为只有InnoDB存在事务。
crash-safe主要是通过redo log和undo log日志文件来保证重启后已提交的数据不会丢失，未提交的数据会自动回滚。MySQL中主要存在binlog，redo log和undo log
三种日志文件，binlog是归档日志，存在于MySQL的server层产生，不属于任何引擎，所以MyISAM和InnoDB中都存在并且相同，主要是用来记录数据库的sql语句(除了查询语句)，
binlog会一直记录，当记录超过单个日志文件的最大值，默认是1G，就会新起一个文件继续记录，由于binlog记录的是每个操作的sql语句，所以主要是用来数据库主从同步和备份。
可以通过binlog日志文件将数据恢复到任意时间点，在主从架构时从库也可以监听主库的binlog日志来完成同步。其实MySQL对于数据的变更并不是直接修改磁盘上的数据，而是先
在内存中查询数据，然后在内存中更新，同时将数据写入到binlog日志中，然后触发落盘机制异步将数据刷新到磁盘中。这样做的目的是为了提高性能，主要是将数据写入磁盘是随机写，
需要找到对应数据的磁盘位置才能修改，性能开销大，无法满足MySQL的性能要求，所以采用在内存中修改然后异步落盘，又为了防止断电导致数据丢失，会先写入binlog日志文件中，
保证断电重启后数据能够恢复，虽然写binlog日志文件也是写磁盘，但是binlog是顺序写入，相比随机写入性能开销小。因此大多数的存储系统都会采用WAL(Write Ahead Log)技术，
即日志先行，在保证数据一致性和持久性的的同时提升了语句执行的性能。如果在不考虑事务的情况下，binlog其实已经做到了数据不丢失，但是在有事务的情况下，在事务未最终commit
之前就会记录在binlog日志文件中，这样是为了保证binlog和数据库实际的数据变更保持一致。如果在commit之后写入，在写入binlog之前断电重启就会丢失数据。但是在事务最终
commit之前写入binlog，如果在commit之前断电重启就无法回滚数据。因此单靠binlog日志无法保证事务的数据不丢失，MySQL的InnoDB引擎为了解决这个问题引入了redo log和
undo log日志文件，在不影响MySQL binlog日志的存储逻辑下来实现事务的数据不丢失。redo log是重做日志，是在InnoDB的引擎层产生，主要是记录数据库中每个数据页的修改，
由于MySQL的数据是以数据页的形式存在，redo log日志存储数据页上的修改在断电重启后能够很快找到对应的数据页进行数据恢复。redo log是一个固定大小的文件，从头部开始写入，
写到末尾之后就会回到开头覆盖写入，形成一个循环，在覆盖数据页时会判断数据是否已经落盘。undo log主要是用来保证事务的数据回滚和支持mvcc，undo log日志存储的是事务中
修改操作的相反记录，即delete操作会在undo log中记录insert操作，回滚时可以根据undo log来恢复到事务之前的记录。在mvcc中也可以通过undo log来提供旧数据。在InnoDB
中事务操作数据的流程是先在内存中查询数据，没有则在磁盘获取读入内存，在内存中修改完成后同时写入undo log和redo log，redo log中记录的是操作状态的prepare，然后在
binlog中记录逻辑操作，commit之后将redo log的记录状态修改为commit。主要是用到了2PC的思想来保证redo log和binlog的数据一致性，因为binlog是数据库保证主从同步的
关键日志，需要保证redo log和binlog的一致性，在两次修改redo log中间加入binlog，若在未写入binlog时断电重启，会发现redo log中的数据为prepare并且binlog中无数据，
就会根据undo log回滚数据，若在写入binlog后断电重启，发现redo log中数据为prepare并且binlog中有数据，就会将redo log的数据修改为commit，即在binlog中写入的数据
就会认为是需要提交的数据。在单事务的情况下binlog和redo log提交的写入顺序是一致的，但是在多事务中redo log和binlog写入顺序有交叉，比如redo log中prepare
是T1->T2，binlog写入T1->T2，redo log中commit是T2->T1，这样主库数据是T2->T1，从库数据是T1->T2。为了保证在多事务中日志写入顺序一致，早期通过prepare_commit_mutex
锁来保证事务的prepare-commit中其他事务无法操作，但是在锁冲突激烈时性能消耗大，而且redo log和binlog落盘写入很慢，影响性能。因此在MySQL5.6引入了binlog的
组提交，即BLGC(Binary Log Group Commit)，通过引入队列来保证一组事务commit的操作和binlog落盘日志一致。在prepare阶段事务竞争prepare_commit_mutex来
顺序写入redo log，然后释放prepare_commit_mutex锁。然后commit阶段拆分成三步Flush Stage，Sync Stage和Commit Stage，每一个Stage都拥有一个队列，
每个队列都有一组事务，第一个事务是leader，其他事务是follow，leader控制Stage内的事务操作。Flush Stage内Leader持有Lock_log mutex锁，并且将队列内所有事务
写入binlog缓存中。Sync Stage时leader释放锁，持有Lock_sync mutex锁并且将队列的binlog落盘。Commit Stage时leader释放锁，持有Lock_commit mutex锁并且
将队列内的所有事务逐一进行commit，每个队列是按照三个Stage顺序执行，但是不同队列可以交叉执行，这样实现了一组事务的提交，降低了锁的粒度，锁竞争减少，而且一组数据的
落盘减少IO消耗。







