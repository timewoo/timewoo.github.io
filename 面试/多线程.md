# 多线程

1.进程和线程：

进程是程序的一次执行过程，是系统运行程序的基本单位，系统运行一个程序即是一个进程从创建，运行到消亡的过程。线程是在进程执行过程中产生的
更小的执行单位，同类的多个线程共享进程的堆和方法区资源，但是每个线程拥有自己的程序计数器，虚拟机栈和本地方法栈。

![timewoo](https://timewoo.github.io/images/JVM.png)

一个进程包含多个线程，多个线程共享进程的堆和方法区(JDK1.8之后的元空间)资源，每个线程有自己的程序计数器，虚拟机栈和本地方法栈。程序计数器，
虚拟机栈和本地方法栈都是线程私有的，计数器的作用是字节码通过改变计数器来依次读取指令，完成代码的执行，同时在多线程中记录当前线程执行位置，
以便在线程切换时可以回到上一个线程的执行位置，如果线程执行的是native方法，计数器无法记录当前位置，只有执行java代码时才能记录，计数器私有
是为了程序切换后能恢复正确的执行位置；虚拟机栈是每个Java方法在执行的同时会创建一个栈帧用来存储局部变量表，操作数栈，常量池引用等，从方法调用
到完成的过程对应一个栈帧在虚拟机栈中入栈和出栈的过程，本地方法栈和虚拟机栈类似，虚拟机栈执行的是java服务，本地方法栈执行native方法，在
HotSpot虚拟机中和Java虚拟机合二为一，虚拟机栈和本地方法栈私有是为了保证线程的局部变量不被其他线程访问到。

2.堆和方法区

堆是进程中最大的一块内存，主要存放新创建的对象，方法区主要存放加载的类信息，常量，静态变量，即时编译后的代码数据，堆和方法区是线程共享的资源。

3.线程死锁：

线程死锁是指多个线程同时被阻塞，它们中的一个或多个都在等待某个资源被释放，由于线程被无限期的阻塞，因此程序不可能正常终止。

死锁产生的条件：

互斥条件：一个资源任意时刻只由一个线程占用。

请求和保持条件：一个线程因请求资源而阻塞时，对已获取的资源不释放。

不剥夺条件：线程已获得的资源在未使用完成之前不能被其他线程剥夺，只有自己使用完成后才释放资源。

循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。

避免死锁：

破坏互斥条件：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。

破坏请求与保持条件 ：一次性申请所有的资源。

破坏不剥夺条件 ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。

破坏循环等待条件 ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

4.sleep和wait的区别：

sleep没有释放锁，wait释放锁，都可以暂停线程的执行，wait主要用于线程间的通信/交互，sleep主要用于暂停线程执行，线程调用wait方法，暂停的线程
不会自动苏醒，需要别的线程调用同一对象的notify或者notifyAll方法，调用sleep方法可以指定暂停时间，到点自动苏醒，wait(long time)也可以设置超时自动苏醒。

5.Thread调用start()方法使线程处于就绪状态，会自动执行run()内的方法，和直接调用run()方法的不同：

new一个Thread，线程进入新建状态，调用start()方法，会启动一个线程进入就绪状态，等待获取时间片，获取时间片后线程会调用run()执行线程。而直接
调用Thread的run()方法只是单纯的方法调用，并没有生成另一个线程，还是在主线程中执行，调用 start 方法方可启动线程并使线程进入就绪状态，
而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。

6.synchronized：

synchronized关键字是解决多线程之间访问资源的同步性，synchronized修饰的方法或代码块在任意时刻只能有一个线程在执行，在java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方从 JVM 层面对synchronized 较大优化，
所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

synchronized主要是用来修饰实例方法，静态方法和代码块，修饰实例方法给当前对象加锁，进入同步代码需要获取当前对象实例的锁，简称对象锁；修饰静态方法是给当前类加锁，会作用于类的所有对象实例，简称类锁，类锁和对象锁是不互斥的，即两个线程可以分别获取同一个对象的类锁和对象锁，不会形成阻塞；修饰代码块是给特定对象加锁，线程需要获取特定对象的锁才能执行同步方法。尽量不使用synchronized(String)对String对象加锁，因为String对象在JVM中是字符串常量池，具有缓存功能，即直接对String类赋值时会去字符串常量池寻找是否有相同值的String对象，有则直接会去字符串常量池的获取对象，即String str = "a"和String str2 = "a"是同一个对象，而String str = new String("a")和String str2 = new String("a")则是不同对象，如果直接采用synchronized(String)，就可能导致两个线程对同一个字符串可能锁住(直接赋值)，可能锁不住(new 创建)，造成混乱，如果要实现synchronized(String)对不同的线程都锁住同一个字符串，可以是使用synchronized(String.intern())，String.intern()会强制在字符串常量池中寻找是否有相同值的String，有则直接返回引用，没有则在字符串常量池创建，然后返回引用，所以对于new创建的字符串，值相同的也会返回相同的对象，synchronized(String.intern())就可以实现对不同线程的同一个字符串锁住，实现同步。

synchronized实现单例模式
```java
public class Singleton {

    private volatile static Singleton uniqueInstance;

    private Singleton() {
    }

    public static Singleton getUniqueInstance() {
       //先判断对象是否已经实例过，没有实例化过才进入加锁代码
        if (uniqueInstance == null) {
            //类对象加锁
            synchronized (Singleton.class) {
                if (uniqueInstance == null) {
                    uniqueInstance = new Singleton();
                }
            }
        }
        return uniqueInstance;
    }
}
```
uniqueInstance使用volatile修饰是为了防止在多线程的情况下，由于JVM的指令重排，导致获取的对象没有初始化。uniqueInstance = new Singleton();
代码执行分为三步，为 uniqueInstance 分配内存空间，初始化 uniqueInstance和将 uniqueInstance 指向分配的内存地址，由于JVM具有指令重排的特性，
可能会先分配内存空间，再指向内存地址，最后初始化。在单线程下不会出现问题，但是在多线程中，可能导致uniqueInstance还未初始化就被其他线程获取。
使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。

synchronized关键字底层实现：

同步代码块时：使用monitorenter和monitorexit指令，monitorenter是同步代码块开始的位置，monitorexit是同步代码块结束的位置，当执行monitorenter指令时，线程试图获取锁也就是获取对象的monitor的持有权，monitor是存在于每个java对象的对象头中，synchronized就是通过获取monitor来获取锁，也就是Java中任意对象都可以作为锁的原因，然后所有锁对象都有一个锁计数器，当计数器为0时线程可以获取对象锁，同时将锁计数器加1，执行代码后，monitorexit将锁计数器设为0，表明锁被释放，如果获取对象锁失败，会一直等待其他线程释放锁。

同步方法时：同步方法使用ACC_SYNCHRONIZED来标识，JVM通过此标识来判断方法是否是同步的，从而执行相应的monitor操作。即ACC_SYNCHRONIZED会隐式的调用monitor指令。

JDK1.6之后的synchronized：

JDK1.6之后引入了锁的大量优化，偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。锁主要存在四种状态：无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，随着锁的竞争程度而逐渐升级，锁可以升级不能降级，这种策略是为了提高获得锁和释放锁的效率。

轻量级锁：JDK1.6之后引入，轻量级锁提升同步效率的依据是“对于绝大部分锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！

重量级锁：重量级锁主要是依赖于对象内部的monitor锁，而monitor又依赖于操作系统的MutexLock(互斥锁)。

偏向锁：偏向锁和轻量级锁的目的类似，都是为了在没有多线程竞争的情况下，减少传统的重量级锁使用操作系统互斥量产生的性能损耗，轻量级锁在无竞争的情况下采用CAS去代替互斥量，偏向锁则将同步操作消除掉，即会偏向于第一个获取锁的线程，如果锁没有被其他线程获取，持有锁的线程将不会进行同步操作。但是当竞争激烈时偏向锁就失效了，因为每次获取锁的线程可能不是同一个。在线程进行锁的获取时会在对象头中存储获取偏向锁的线程ID，由于每个对象头都有锁标识来判断对象锁是偏向锁，轻量级锁还是重量级锁。若线程获取到对象是可偏向状态则会通过CAS将线程ID写入对象头，成功则获取锁继续执行，若对象是已偏向状态则会判断对象头内的线程ID是否和当前线程一致，相同则不进行获取锁操作直接执行，若不一致则表示已被其他线程获取，则需要撤销偏向锁，撤销偏向锁首先需要暂停持有偏向锁的线程，然后检查线程是否存活，若线程死亡则对象头设置为无锁状态，若线程存活则在到达全局安全点(所有工作线程都停止字节码的执行)时线程会被挂起，然后偏向锁升级为轻量级锁，最后唤醒线程继续执行，偏向锁失败后不会立即膨胀为重量级锁，会先升级为轻量级锁。

自旋锁和自适应自旋：竞争激烈的情况下，轻量级锁失败后，JVM为了避免线程在操作系统上挂起，还会进行自旋操作。互斥操作对性能最大的影响就是阻塞的实现，因为挂起线程/恢复线程的操作都需要转入内核态中完成（用户态转换到内核态会耗费时间）。由于一般线程持有锁的时间不会很长，所以阻塞时不让线程挂起，而是让线程执行一个循环，即自旋操作，可以使用更小的消耗让线程恢复。但是自旋不能代替阻塞，如果线程持有锁的时间不长，可以采用自旋，但是持有锁的时间过长，就需要采取阻塞，同时，自旋不能无限制的循环，需要有一个次数限制来保证超过限制后线程需要挂起，JDK1.6引入了自适应的自旋锁，即自旋的次数不固定，而是根据上一次自旋的线程次数和锁的拥有者的状态。

锁消除：JVM在运行时检测到共享数据不可能存在竞争，将锁消除，减少无意义的请求锁的时间。

锁粗化：在一般情况下，我们会将锁的范围尽量减小在一个范围内，要求线程持有锁的时间尽可能短，但是在某些情况下，对同一个锁进行频繁的同步和释放，会造成性能上的损耗，反而不利于性能提升，锁粗化就是告诉我们任何事情都有个度，有些情况下我们反而希望把很多次锁的请求合并成一个请求，以降低短时间内大量锁请求、同步、释放带来的性能损耗。

synchronized和ReentrantLock：

两者都是可重入锁，可重入锁就是获取锁的线程可以再次获取内部锁，同一个线程获取锁时都会使锁计数器加1，需要等锁计数器变为0才会释放锁；synchronized依赖于JVM(虚拟机优化)，ReentrantLock依赖于API(lock和unlock)；ReentrantLock拥有其他功能，可以中断等待锁的线程(lock.lockInterruptibly())，可以指定锁是公平锁还是非公平锁(公平锁即先等待的线程先获取锁，synchronized是非公平锁)，可以实现选择性的线程通知，synchronized和线程的wait，notify和notifyAll结合可以实现线程的等待通知机制，但是notify是通知等待线程中的一个，notifyAll通知的是所有处于等待状态的线程，如果需要通知特定线程，ReentrantLock配合Condition接口与newCondition()方法可以实现通知特定线程，Condition在JDK1.5之后才有，可以在一个Lock对象中创建多个Condition实例(对象监视器)，线程对象可以注册在指定的condition中，通过指定Condition的通知方法通知在此condition下的等待线程。

7.volatile：

在jdk1.2以前，java内存模型总是从主存中读取变量，不需要考虑多线程对同一变量的操作，而以后的线程可以把变量存储在本地内存中，而不是在主存中进行读写，就可能出现一个线程修改了主存中的变量，而另一个线程还继续使用本地内存中的变量，造成数据不一致。可以将变量声明为volatile，这就指示JVM这个变量是不稳定的，每次都需要到主存中读取，保证变量的可见性和防止指令重排。

jdk对于volatile的实现：

- 字节码层面：通过在字段上添加一个ACC_VOLATILE字段的访问标识符
- JVM层面：使用内存屏障（Memory Barrier），由于在CPU指令执行过程中系统底层为了优化指令可能发生重排序，导致变量的读写顺序发送改变。为了确保部分指令在执行过程中按照顺序执行，JVM将内存屏障在volatile变量的前后插入，来保证变量读写指令的顺序，同时JVM的内存屏障在读指令之前会使本地内存变量失效，从主存中获取，在写指令之后的内存屏障会将最新数据写回到主存中。

为什么说volatile无法保证原子性？

首先需要明确volatile对于变量的原子操作（基础变量的赋值，int i = 1）是可以保证原子性，对于变量的复合操作（i++）是无法保证原子性。因为对于复合操作，比如自增i++，实际上是有三个步骤：

- 线程从主存中获取最新的变量值到本地内存中
- 在本地内存中将变量加1
- 线程将本地内存中的变量值刷新到主存中

而volatile保证的可见性仅仅是在获取变量时，如果有其他线程修改了变量，本线程会将本地内存的变量置为无效，重新从主存中加载最新变量到本地内存，而且当变量已经被读入执行栈帧后就不会再重新读取，这样在两个线程执行上述第三步，将本地内存变量刷新到主存中就会互相覆盖。

reference：https://blog.csdn.net/weixin_43767015/article/details/105518264

8.并发需要考虑的问题：

原子性：一个操作或多个操作要么全部成功，要么全部失败，synchronized保证原子性。

可见性：当一个线程对变量进行操作后，其他线程可以立即看到操作后的变量，volatile保证共享变量的可见性。

有序性：代码在执行过程中的顺序不一定是编码的顺序，volatile禁止了指令重排。

9.synchronized和volatile：

volatile是线程同步的轻量级实现，性能比synchronized好，但是volatile只能修饰变量，synchronized可以修饰方法和代码块；多线程访问volatile修饰的变量时
不会发生阻塞，使用synchronized可能发生线程阻塞；volatile可以保证数据的可见性，synchronized可以保证数据的原子性和可见性；volatile主要解决多个线程
之间变量的数据可见性，synchronized主要解决多个线程之间访问资源的同步性。

10.ThreadLocal：

多线程中创建的变量可以被任意一个线程访问，即变量是共享的，ThreadLocal可以让每个线程绑定自己的变量，每个线程都会拥有变量的本地副本，获取和更新都是修改的本地副本中的变量，从而避免了线程安全的问题。

```java
public class Thread implements Runnable {
/**
 * 线程中维护的ThreadLocal变量，默认为null
 */
ThreadLocal.ThreadLocalMap threadLocals = null;

/**
 * 线程中维护的inheritableThreadLocal变量，InheritableThreadLocal是ThreadLocal的子类
 */
ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;

}

public class ThreadLocal<T> {

    /**
     * 获取当前线程，在ThreadLocalMap中查找，存在变量则获取本地变量，不存在则获取初始化值
     */
    public T get() {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null) {
            ThreadLocalMap.Entry e = map.getEntry(this);
            if (e != null) {
                @SuppressWarnings("unchecked")
                T result = (T)e.value;
                return result;
            }
        }
        return setInitialValue();
    }

    /**
     * 设置变量值，在ThreadLocalMap中查找当前线程存放变量的Map，存在更新，不存在新增
     */
    public void set(T value) {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null)
            map.set(this, value);
        else
            createMap(t, value);
    }
}
```
Thread本地维护一个threadLocals和inheritableThreadLocals变量，都是ThreadLocalMap类型的，默认情况下都是null，只有当前线程调用ThreadLocal的get()方法或set()方法才会创建并初始化值，最终Thread的本地变量是存放在ThreadLocalMap中而不是ThreadLocal中，ThreadLocalMap是ThreadLocal内部实现的HashMap，key是ThreadLocal，value就是ThreadLocal的本地变量副本值。如果当前线程创建了多个ThreadLocal，线程Thread内部的threadLocals存储的就是多个ThreadLocal的本地变量值。简单来说，每个Thread都有自己的ThreadLocalMap，调用ThreadLocal的get或set方法时会根据Thread获取对应的ThreadLocalMap，然后根据对应的ThreadLocal来获取或设置值。ThreadLocal内部的ThreadLocalMap维护的是多个线程的同一个ThreadLocal的变量值，因为ThreadLocal只有一个，而Thread内部的ThreadLocalMap存储的是一个线程中多个ThreadLocal的变量值，线程可以拥有多个ThreadLocal。

![timewoo](https://timewoo.github.io/images/ThreadLocal.png)

ThreadLocal内存泄漏是由于ThreadLocalMap的key是ThreadLocal的弱引用，value是强引用，如果ThreadLocal没有被外部强引用，在垃圾回收时，key会被回收，而value不会被清理，就会出现ThreadLocalMap中出现key为null的Entry出现，如果不做处理，value可能永远都不会被回收，就可能出现内存泄漏。因为ThreadLocalMap中的get(),set()和remove()方法会清理key为null的对象，所以最好使用完ThreadLocal后手动调用remove方法。(弱引用是指对象拥有更短的生命周期，在垃圾回收中，发现弱引用的对象，不管内存空间是否足够，都会回收内存，只是垃圾回收是个优先级很低的线程，可能不会立刻发现弱引用对象)

11.线程池：

降低资源消耗：通过重复利用已创建的线程来降低线程创建和销毁的消耗。

提高响应速度：任务到达时不需要等待线程的创建就能执行。

提高线程的可管理性：可以统一分配，调优和监控线程。

Runnable和Callable：Runnable自jdk1.0就存在，Callable jdk1.5才引入，Callable主要用来处理Runnable不支持的情形，Runnable不支持线程的返回结果或抛出检查异常，但是Callable可以。

execute()和submit()：execute()用于提交没有返回值的任务，无法判断任务是否被线程池执行；submit()用于提交需要返回值的任务，线程池会返回一个Future对象，来判断任务是否执行，通过Future的get()的方法可以获取返回值，但是会阻塞当前线程直到任务完成，而get(long time)会设置阻塞超时时间，超时会立即返回。

创建线程池：一是通过ThreadPoolExecutor的构造方法去创建；二是通过Executor框架的Executors类来实现；Executors主要创建三种类型的线程池：newFixedThreadPool(int nThreads)返回一个固定线程数量的线程池，新任务提交后如果有空闲线程则立即执行，没有则等待在一个任务列表中，等待线程空闲后执行；newSingleThreadExecutor(ThreadFactory threadFactory)返回一个只有一个线程的线程池，新任务提交后没有空闲则保存在任务队列中，等待线程空闲后先进先出的顺序执行；newCachedThreadPool(ThreadFactory threadFactory)返回一个可根据实际情况调整的线程池，新任务没有空闲线程则创建线程执行。Executors创建的线程池底层都是调用ThreadPoolExecutor的构造方法，而且Executors创建的线程池使用的等待队列的容量是Integer.MAX或者是无界队列，无法指定队列的容量，容易出现内存溢出。所以推荐使用ThreadPoolExecutor来创建线程池。

ThreadPoolExecutor

```java
/**
 * corePoolSize:核心线程数，最小可以同时运行的线程数
 * maximumPoolSize:任务队列达到队列容量时，当前可同时运行的最大线程数
 * keepAliveTime:线程池线程数大于核心线程数，没有新任务，多余线程等待指定时间后被销毁
 * unit:时间参数
 * workQueue:任务队列，任务判断核心线程是否空闲，没有空闲则放入任务队列
 * threadFactory:创建新线程时使用，可以设置线程的名字
 * handler:饱和策略，指线程池最大线程数已用尽并且任务队列已满的情况下对新任务的处理策略
 *         ThreadPoolExetuor.AbortPolicy:直接抛出RejectedExecutionException异常拒绝新任务，默认使用的饱和策略
 *         ThreadPoolExetuor.CallerRunsPolicy:会直接调用当前线程来执行新任务，会阻塞当前线程
 *         ThreadPoolExecutor.DiscardPolicy:不处理新任务，直接丢弃
 *         ThreadPoolExecutor.DiscardOldestPolicy:丢弃最早未处理的任务
 */
new ThreadPoolExecutor(int corePoolSize,
                       int maximumPoolSize,
                       long keepAliveTime,
                       TimeUnit unit,
                       BlockingQueue<Runnable> workQueue,
                       ThreadFactory threadFactory,
                       RejectedExecutionHandler handler)
```
ThreadPoolExecutor线程池execute(Runnable)运行任务时，先判断线程池的运行线程数是否到达corePoolSize，没有则调用线程执行任务，到达则判断workQueue是否已满，没有则将任务加入队列，满了则判断线程池线程数量是否到达maximumPoolSize，没有则创建线程执行任务，到达则判断饱和策略，如果是CallerRunsPolicy就会调用当前线程执行任务。

ThreadPoolExecutor线程池一般在全局变量和局部变量中定义创建，如果在全局变量中，则所有的线程都是使用的同一线程池，线程池会进行复用，并且由于static修饰，所以JVM中线程数量不会增加。当在局部变量中进行线程池创建时，每次方法的调用都会创建线程池，如果不手动关闭线程池的话就可能出现线程一直增长，导致JVM内存泄漏，手动关闭线程池有shutdown()和shutdownNow()，shutdown()的操作不会影响正在执行的线程，在线程全部执行完成后关闭线程池。shutdownNow()会立即关闭线程池，同时会返回未完成的线程任务列表。

线程池的submit()会返回Future对象，由于线程池submit()创建线程任务时线程已经运行，所以对任一线程的Future对象get()时只会阻塞主线程，其他任务线程不会阻塞，所以其他线程任务可以很快返回，get()只会阻塞需要执行时间最长的线程。

当线程池中的任务出现异常时，如果使用execute执行则会抛出异常，但是不会影响其他任务的执行，当使用submit执行时不会抛出异常，只有对Future对象进行get()时会抛出
异常。

12.并发容器：

ConcurrentHashMap：线程安全的HashMap，jdk1.7是采用分段加锁，jdk1.8是采用对单个Node节点加锁。

CopyOnWriteArrayList：线程安全的List，适合读多写少的场景，比Vector好，CopyOnWriteArrayList在读取时不会加锁，写入时读取操作也不会加锁，只有在
写入和写入操作时需要同步等待，将读取的性能提升到最大，CopyOnWriteArrayList底层所有可变操作(set,add)都是将原数组复制一份，在拷贝的数组上进行操作，操作完成后将原数组引用替换为拷贝数组的引用，所以保证写操作不会影响到读操作

```java
@SuppressWarnings("unchecked")
private E get(Object[] a, int index) {
    return (E) a[index];
}

/**
 * {@inheritDoc}
 * 读取操作未加锁和同步，每次读取不一定是最新的，但是会达到最终一致性
 * @throws IndexOutOfBoundsException {@inheritDoc}
 */
public E get(int index) {
    return get(getArray(), index);
}

/**
 * 新增操作会获取锁，避免多线程复制多个数组副本，在副本内修改完成后将原数组引用指向副本引用
 */
public boolean add(E e) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        Object[] elements = getArray();
        int len = elements.length;
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        newElements[len] = e;
        setArray(newElements);
        return true;
    } finally {
        lock.unlock();
    }
}

/**
 * 和新增操作类似
 */
public E set(int index, E element) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        Object[] elements = getArray();
        E oldValue = get(elements, index);

        if (oldValue != element) {
            int len = elements.length;
            Object[] newElements = Arrays.copyOf(elements, len);
            newElements[index] = element;
            setArray(newElements);
        } else {
            // Not quite a no-op; ensures volatile write semantics
            setArray(elements);
        }
        return oldValue;
    } finally {
        lock.unlock();
    }
}
```

ConcurrentLinkedQueue：线程安全的非阻塞队列，通过链表作为底层数据结构，主要使用CAS来实现多线程安全问题，并发性能较好。

BlockingQueue：线程安全的阻塞队列，主要运用于消费者-生产者问题，当队列容量已满时，生产者线程会阻塞，当队列为空时，消费者线程会阻塞。
主要实现是ArrayBlockingQueue，LinkedBlockingQueue和PriorityBlockingQueue，ArrayBlockingQueue是BlockingQueue的有界队列实现，底层是
数组，一旦创建，容量就不能改变，并发采用可重入锁(ReentrantLock)，读取和插入都需要获取锁，当队列容量已满时，插入元素将会使线程阻塞，容量为空时，获取元素也会使线程阻塞，ArrayBlockingQueue默认是非公平性，即不是按照线程等待的时间顺序来访问ArrayBlockingQueue，可以在初始化ArrayBlockingQueue时指定为公平性，ArrayBlockingQueue(int capacity, boolean fair)，这样就会按照线程等待顺序访问ArrayBlockingQueue；LinkedBlockingQueue底层是单向链表的阻塞队列，如果初始化未指定队列容量，则容量是Integer.MAX，类似于无界队列。为了防止队列的容量增长过快消耗内存，一般指定队列的容量，指定容量后和ArrayBlockingQueue一样无法扩容；
PriorityBlockingQueue：支持队列排序的无界阻塞队列，默认情况下采用自然顺序排列，可以自定义类的compareTo()方法实现排序规则，或初始化时通过构造参数Comparator指定排序规则。
队列是真正的无界队列，即在队列容量不足时可以扩容，扩容最大为Integer.MAX_VALUE - 8，可以初始化指定容量或者默认容量(11)，是PriorityQueue的线程安全容器，不可以插入null值，
由于队列可以排序，所以插入的元素必须是可以比较大小的(comparable)，因为是无界队列，所以插入时不会阻塞线程，只有消费时容量为空时会阻塞线程。

ConcurrentSkipListMap:跳表的实现，底层是Map，用于快速查找。跳表的出现是为了一些无法快速查找的容器(链表，map等)，使用跳表结构能使它们实现快速查找。
跳表的实现是在元数据结构之上维护类似索引的结构，最底层维护所有数据，上一层维护下一层的数据的索引，在查找过程中是跳跃的。元素的必须是排过序的。
![timewoo](https://timewoo.github.io/images/ConcurrentSkipListMap.jpg)
跳表类似于平衡树，但是平衡数的插入和删除可能需要对全局数据进行调整，对于高并发下的操作效率不高，而跳表只需要调整局部数据，可以在部分数据上加锁来
实现高并发操作，性能更好。

13.悲观锁和乐观锁：

悲观锁是认为在多线程中线程间的读写冲突频繁，所以在获取资源时必须获取资源锁才能操作，否则就让线程阻塞，数据库的行锁，表锁，读锁和写锁，synchronized和ReentrantLock等都是悲观锁的实现，适用于写多读少的情形。

乐观锁是认为在多线程中线程间的读写冲突不频繁，所以在获取资源时不会加锁，只在更新资源时判断是否有更改，使用版本号和CAS(compare and swap比较和交换)机制。适用于读多写少的情形。

乐观锁的缺点：ABA问题，即判断资源是否更改只是判断前后是否一致，如果是A->B->A，CAS就无法判断是否更改，可以采用版本号的方法来解决。JDK1.5的AtomicStampedReference类的compareAndSet()方法会比较当前引用是否和预期的引用相等，并且当前值是否等于预期值，如果相等则用原子方式将引用和值更新；循环时间长，CAS在发现资源前后不一致之后会尝试重试，采用自旋方式，即不阻塞而是采用循环的方式，但是长时间循环会给CPU带来非常大的开销；CAS只能保证一个共享变量的原子性，JDK1.5之后的AtomicReference类可以保证引用对象的原子性，可以把多个变量放在一个对象内进行CAS操作。

14.AQS(AbstractQueueSynchronizer):

是用来构建锁和同步器的框架，ReentrantLock，Semaphore等都是基于AQS，能够通过AQS自定义需要的同步器。AQS核心思想是，如果被请求的资源空闲，则将请求的线程设置为工作线程，并且将资源锁定，如果被请求的资源正在被占用，就需要一套线程阻塞等待以及被唤醒的锁分配机制，AQS通过CLH(Craig,Landin,and Hagersten队列是一个虚拟的双向队列，即不存在队列实例，仅存在节点间的关系)队列锁来实现。AQS将暂时获取不到锁的线程加入队列中。
![timewoo](https://timewoo.github.io/images/AQS.png)

```java
/**
 * 同步状态，volatile线程可见
 */
private volatile int state;

/**
 * 返回同步状态
 */
protected final int getState() {
    return state;
}

/**
 * 设置同步状态
 */
protected final void setState(int newState) {
    state = newState;
}

/**
 * CAS设置同步状态
 */
protected final boolean compareAndSetState(int expect, int update) {
    // See below for intrinsics setup to support this
    return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
```
AQS使用变量state来表示同步状态，通过内置的FIFO队列来实现线程的排队工作，同时通过CAS来实现对state的原子性操作。

AQS对资源的共享定义为独占(exclusive)和共享(share)，独占是指同一时间只能有一个线程访问资源，执行操作，如ReentrantLock，独占锁又分为公平锁(按照线程在队列中先后顺序获取锁)和非公平锁(线程通过两次CAS去获取锁，没有获取到的当前线程再加入到队列中等待唤醒)。
```java
public class ReentrantLock implements Lock, java.io.Serializable {

    /**
     * 同步器实现 
     */
    private final Sync sync;

    /**
     * 继承AQS的锁定实现
     */
    abstract static class Sync extends AbstractQueuedSynchronizer {

        /**
         * 非公平锁获取独占锁
         */
        final boolean nonfairTryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            // 锁未被线程持有，CAS设置同步状态，成功设置当前线程
            if (c == 0) {
                if (compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            // 判断是否是当前线程获取锁，是则进行重入操作  
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0) // overflow
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
    }

    /**
     * 默认初始化是非公平锁
     */
    public ReentrantLock() {
        sync = new NonfairSync();
    }

    /**
     * 设置初始化同步器是公平锁还是非公平锁
     */
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }

    /**
     * 非公平锁
     */
    static final class NonfairSync extends Sync {
        private static final long serialVersionUID = 7316153563782823691L;

        /**
         * CAS判断线程是否能够改变state同步状态
         */
        final void lock() {
            if (compareAndSetState(0, 1))
                // 成功改变状态将线程设为独占
                setExclusiveOwnerThread(Thread.currentThread());
            else
                // 自旋或重入获取锁
                acquire(1);
        }
        // 调用非公平锁加锁操作
        protected final boolean tryAcquire(int acquires) {
            return nonfairTryAcquire(acquires);
        }
    }

    /**
     * tryAcquire获取独占锁，addWaiter构造同步队列，将线程加入队列，acquireQueued自旋获取锁，selfInterrupt安全中断线程
     * 在线程获取不到锁并且自旋获取锁失败，线程会安全中断，不会报错
     */
    public final void acquire(int arg) {
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }

    /**
     * 公平锁
     */
    static final class FairSync extends Sync {
        private static final long serialVersionUID = -3000897897090466540L;

        final void lock() {
            acquire(1);
        }

        /**
         * 公平锁自身实现的获取独占锁操作
         */
        protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                // 判断是否有线程等待时间超过当前线程并且CAS设置同步状态
                if (!hasQueuedPredecessors() &&
                    compareAndSetState(0, acquires)) {
                    //当前线程获取锁
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            // 判断是否是当前线程获取锁，是则进行重入操作 
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0)
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
    }

}
```
ReentrantLock初始化默认是非公平锁，可以设置ReentrantLock(true)来初始化为公平锁，非公平锁lock时会先使用CAS设置state同步状态，成功则将当前线程设置为独占，失败调用acquire方法，而公平锁是直接调用acquire方法，acquire判断!tryAcquire(arg)和acquireQueued(addWaiter(Node.EXCLUSIVE), arg)是否都成功，tryAcquire在非公平锁中是通过再一次CAS设置同步状态，成功设置线程独占，失败则判断当前独占线程和该线程是否是同一对象，是则进行重入操作，同步状态加1；在公平锁中，tryAcquire是判断队列中是否有线程等待时间超过当前线程和CAS设置同步状态，没有等待线程以及CAS成功则设置线程独占，失败则进行重入判断。
如果tryAcquire失败，则调用acquireQueued线程自旋获取锁。因此非公平比公平锁多一次CAS设置同步状态，在第一次CAS时未进入等待队列的线程可以获取到锁，不需要进行线程的唤醒，提高了效率，公平锁在tryAcquire会判断线程等待时间。非公平锁拥有更大的吞吐量，性能更好，但是容易让队列中的线程处于饥饿状态。

共享是指多个线程可以同时执行，如Semaphore/CountDownLatch,CyclicBarrier,ReadWriteLock，ReentrantReadWriteLock是允许多个线程对同一资源进行读操作的同步器。

自定义的同步器只需要继承AQS，然后自己实现关于state的获取和释放即可，其他的线程等待队列的维护，AQS已经实现。AQS底层使用的是模板方法模式，实现类继承AbstractQueueSynchronizer并重写指定方法，然后将AQS组合在自定义的同步组件中，调用模板方法即可调用实现类重写的方法，基本上实现类需要重写isHeldExclusively(线程是否独占资源)，tryAcquire(独占方法，尝试获取资源)，tryRelease(独占方法，尝试释放资源)，tryAcquireShared(共享方法，尝试获取资源)和tryReleaseShared(共享方式，尝试释放资源)，AQS中这些方法默认是都是抛出UnsupportedOperationException，需要实现类自己实现，方法的实现必须是内部线程安全的，同时应该是简短而不阻塞，AQS的其他方法都是final，即实现类无法重写只能使用，ReentrantLock将state初始化为0，线程获取锁设置state+1，释放锁state-1，同一时间只有一个线程获取锁，但是锁可以重入，即直到state为0，其他线程才能获取锁，CountDownLatch将state初始化和子线程数量一致，子线程执行完成state-1，所有子线程完成state为0，则调用unpark唤醒主线程继续执行。一般同步器只需要实现独占和共享中的一种即可，但是也可以实现两种，类似ReentrantReadWriterLock。AQS中的等待队列是一个FIFO的队列，未获取到锁的线程会加入等待队列并且放在队尾，同时会通过一个死循环来自旋的尝试获取锁，自旋的线程会判断队列中前一位节点的状态，若前节点处于等待状态会调用LockSupport.park()方法阻塞当前线程，AQS的锁在释放的时候会从后往前找到第一个可用的，符合条件的线程，然后调用LockSupport.unpark()将线程唤醒，因此AQS中公平锁和非公平锁并不是指解锁的时候通知等待队列线程的方式，因为通知的都是第一个等待线程，而是在加锁时判断线程在等待队列中的位置。

15.Semaphore(信号量)：

可以指定多个线程同时访问资源
```java
public class Semaphore implements java.io.Serializable {

    /**
     * 实现的同步器
     */
    private final Sync sync;

    /**
     * Synchronization implementation for semaphore.  Uses AQS state
     * to represent permits. Subclassed into fair and nonfair
     * versions.
     */
    abstract static class Sync extends AbstractQueuedSynchronizer {
        private static final long serialVersionUID = 1192457210091910933L;

        Sync(int permits) {
            setState(permits);
        }

        final int getPermits() {
            return getState();
        }
        
        /**
         * 非公平锁加锁
         */
        final int nonfairTryAcquireShared(int acquires) {
            for (;;) {
                // 获取当前剩余的信号量
                int available = getState();
                // 当前线程获取后剩余的信号量
                int remaining = available - acquires;
                // CAS设置信号量
                if (remaining < 0 ||
                    compareAndSetState(available, remaining))
                    return remaining;
            }
        }

        protected final boolean tryReleaseShared(int releases) {
            for (;;) {
                int current = getState();
                int next = current + releases;
                if (next < current) // overflow
                    throw new Error("Maximum permit count exceeded");
                if (compareAndSetState(current, next))
                    return true;
            }
        }

        final void reducePermits(int reductions) {
            for (;;) {
                int current = getState();
                int next = current - reductions;
                if (next > current) // underflow
                    throw new Error("Permit count underflow");
                if (compareAndSetState(current, next))
                    return;
            }
        }

        final int drainPermits() {
            for (;;) {
                int current = getState();
                if (current == 0 || compareAndSetState(current, 0))
                    return current;
            }
        }
    }

    /**
     * 非公平锁
     */
    static final class NonfairSync extends Sync {
        private static final long serialVersionUID = -2694183684443567898L;
        
        // 设置初始信号量
        NonfairSync(int permits) {
            super(permits);
        }
        
        // 尝试获取信号量
        protected int tryAcquireShared(int acquires) {
            return nonfairTryAcquireShared(acquires);
        }
    }

    /**
     * Fair version
     */
    static final class FairSync extends Sync {
        private static final long serialVersionUID = 2014338818796000944L;

        FairSync(int permits) {
            super(permits);
        }

        protected int tryAcquireShared(int acquires) {
            for (;;) {
                // 判断队列是否有等待时间比当前线程长的线程，有则当前线程不获取锁
                if (hasQueuedPredecessors())
                    return -1;
                int available = getState();
                int remaining = available - acquires;
                // CAS设置信号量
                if (remaining < 0 ||
                    compareAndSetState(available, remaining))
                    return remaining;
            }
        }
    }

    /**
     * 设置同时执行的信号量，默认非公平锁
     */
    public Semaphore(int permits) {
        sync = new NonfairSync(permits);
    }

    /**
     * 设置同时执行的信号量和锁类型
     */
    public Semaphore(int permits, boolean fair) {
        sync = fair ? new FairSync(permits) : new NonfairSync(permits);
    }

    /**
     * 可中断获取信号量，默认为1
     */
    public void acquire() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }

    /**
     * 获取指定信号量
     */
    public void acquire(int permits) throws InterruptedException {
        if (permits < 0) throw new IllegalArgumentException();
        sync.acquireSharedInterruptibly(permits);
    }

    /**
     * 获取信号量，中断抛出异常
     */
    public final void acquireSharedInterruptibly(int arg)
            throws InterruptedException {
        // 判断线程是否中断
        if (Thread.interrupted())
            throw new InterruptedException();
        // 调用对应锁的获取信号量方法，失败则阻塞等待其他线程释放信号量
        if (tryAcquireShared(arg) < 0)
        // 阻塞线程自旋等待获取信号量
            doAcquireSharedInterruptibly(arg);
    }

}
```
Semaphore是共享型的同步器，初始化可以设置信号量和锁类型，Semaphore(int permits, boolean fair)，也有公平锁和非公平锁，默认是非公平锁，Semaphore初始化设置信号量，state的值也会初始化为信号量的值，然后线程调用acquire，默认获取一个信号量，也可以设置获取信号量的值acquire(int permits)，然后Semaphore会调用不同锁的tryAcquireShared方法获取信号量，公平锁和非公平锁的tryAcquireShared都是启动一个循环，判断当前线程获取信号量后剩余信号量是否大于0以及CAS设置state为剩余信号量是否成功，成功则返回剩余信号量，失败则线程自旋等待信号量释放。公平锁多一步调用hasQueuedPredecessors判断队列是否有等待线程，有则当前线程不获取信号量。需要注意Semaphore在获取信号量之后需要释放对应信号量，否则会阻塞线程执行。

16.CountDownLatch(倒计时器)：

```java
public class CountDownLatch {
    /**
     * 自定义同步器
     */
    private static final class Sync extends AbstractQueuedSynchronizer {
        private static final long serialVersionUID = 4982264981922014374L;
        //设置state为任务数量
        Sync(int count) {
            setState(count);
        }

        int getCount() {
            return getState();
        }
        // 判断任务是否全部完成
        protected int tryAcquireShared(int acquires) {
            return (getState() == 0) ? 1 : -1;
        }
        // 释放任务数量
        protected boolean tryReleaseShared(int releases) {
            // Decrement count; signal when transition to zero
            for (;;) {
                int c = getState();
                if (c == 0)
                    return false;
                int nextc = c-1;
                if (compareAndSetState(c, nextc))
                    return nextc == 0;
            }
        }
    }

    private final Sync sync;

    /**
     * 初始化任务数量
     */
    public CountDownLatch(int count) {
        if (count < 0) throw new IllegalArgumentException("count < 0");
        this.sync = new Sync(count);
    }

    /**
     * 主线程等待
     */
    public void await() throws InterruptedException {
        // 判断任务线程是否全部执行完成
        sync.acquireSharedInterruptibly(1);
    }

    /**
     * 主线程超时等待
     */
    public boolean await(long timeout, TimeUnit unit)
        throws InterruptedException {
        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
    }
   /**
     * 线程任务完成释放任务数量
     */
    public void countDown() {
        sync.releaseShared(1);
    }

}
```
允许多个线程阻塞在一个地方，直到所有的线程都执行完毕，使用的是AQS共享锁。CountDownLatch初始化时设置线程数量state也设置成任务线程的数量，主线程调用await方法去判断任务线程是否全部执行完毕，失败则主线程自旋等待线程全部执行完成。任务线程调用countDown方法将state值减1。主要应用场景一个是主线程等待其他线程全部加载完毕再运行，还有一个场景是需要多个线程同时触发，首先初始化一个共享CountDownLatch，初始化任务为1，然后多个线程执行前调用CountDownLatch的await方法，然后主线程调用countDown方法释放任务线程，然后多个线程就被同时唤醒。由于主线程需要等待所有任务线程都完成，所以初始化count时需要设置为任务线程数量，否则主线程将一直阻塞，导致死锁。

17.CyclicBarrier(循环栅栏)：

CyclicBarrier和CountDownLatch类似，同样可以实现线程间等待，主要是通过ReentrantLock和Condition实现，让一组线程在到达一个同步点时阻塞，只有这组所有的线程都达到后，线程才会继续执行。
```java
public class CyclicBarrier {
    /**
     * 生成的屏障实例，默认是没有打破，打破则屏障失效
     */
    private static class Generation {
        boolean broken = false;
    }

    /**  
     * 屏障入口的锁，访问全局变量需要加锁
     */
    private final ReentrantLock lock = new ReentrantLock();
    /**  
     * 等待屏障打破的条件
     */
    private final Condition trip = lock.newCondition();
    /**  
     * 总共需要多少线程达到屏障才打破
     */
    private final int parties;
    /**  
     * 当所需线程都到达屏障后的回调任务
     */
    private final Runnable barrierCommand;
    /**  
     * 当前屏障
     */
    private Generation generation = new Generation();

    /**
     * 还需要多少线程到达才能打破屏障
     */
    private int count;

    /**
     * 初始化屏障，设置parties和回调任务
     */
    public CyclicBarrier(int parties, Runnable barrierAction) {
        if (parties <= 0) throw new IllegalArgumentException();
        this.parties = parties;
        this.count = parties;
        this.barrierCommand = barrierAction;
    }

    /**
     * 初始化屏障，设置parties
     */
    public CyclicBarrier(int parties) {
        this(parties, null);
    }

    /**
     * 设置屏障上线程等待的超时时间
     */
    public int await(long timeout, TimeUnit unit)
        throws InterruptedException,
               BrokenBarrierException,
               TimeoutException {
        return dowait(true, unit.toNanos(timeout));
    }

    /**
     * 线程等待
     */
    private int dowait(boolean timed, long nanos)
        throws InterruptedException, BrokenBarrierException,
               TimeoutException {
        // 获取锁
        final ReentrantLock lock = this.lock;
        // 加锁
        lock.lock();
        try {
            // 获取屏障
            final Generation g = generation;
            // 判断屏障有没有打破，打破则抛出异常
            if (g.broken)
                throw new BrokenBarrierException();
            // 判断线程是否中断，中断则打破屏障，然后抛出异常
            if (Thread.interrupted()) {
                breakBarrier();
                throw new InterruptedException();
            }
            // 获取还需要多少线程达到
            int index = --count;
            if (index == 0) {  // tripped
                boolean ranAction = false;
                try {
                    // 获取回调任务
                    final Runnable command = barrierCommand;
                    if (command != null)
                        command.run();
                    // 执行回调任务
                    ranAction = true;
                    // 重置屏障，唤醒其他线程
                    nextGeneration();
                    return 0;
                } finally {
                    if (!ranAction)
                        breakBarrier();
                }
            }

            // 需要等待其他线程到达
            for (;;) {
                try {
                    // 非超时则一直等待，直到中断或唤醒
                    if (!timed)
                        trip.await();
                    // 判断超时大于0则等待超时时间
                    else if (nanos > 0L)
                        nanos = trip.awaitNanos(nanos);
                } catch (InterruptedException ie) {
                    // 判断当前屏障是否被打破，没有则打破，抛出异常
                    if (g == generation && ! g.broken) {
                        breakBarrier();
                        throw ie;
                    } else {
                        // 设置中断
                        Thread.currentThread().interrupt();
                    }
                }
                // 等待出现异常，屏障被打破，则抛出异常
                if (g.broken)
                    throw new BrokenBarrierException();
                // 屏障被重置，则返回index
                if (g != generation)
                    return index;
                // 超时并且等待时间已过则打破屏障并且抛错
                if (timed && nanos <= 0L) {
                    breakBarrier();
                    throw new TimeoutException();
                }
            }
        } finally {
            // 释放锁
            lock.unlock();
        }
    }
}
```
CyclicBarrier初始化设置屏障需要到达的线程数量和打破屏障后的回调任务，然后每个线程调用CyclicBarrier的await方法通知CyclicBarrier线程到达屏障并且等待，等待的线程判断是否是最后一个线程，是则调用回调任务，重置屏障，唤醒所有线程，否则就循环等待后续线程到达。CyclicBarrier可以复用屏障，而CountDownLatch只能使用一次。CyclicBarrier是多个线程在任意一个线程未到达时，所有线程都必须等待，而CountDownLatch是等待其他线程完成后等待的线程才能继续执行，区别就是一个是多个线程互相等待，直到到达同一起点，在一起继续执行，一个是一个或多个线程等待其他多个线程完成某件事后才能执行。











