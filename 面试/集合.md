# 集合

1.集合类：

除了Map，其他集合类都实现了Collection接口。

![timewoo](https://timewoo.github.io/images/Collections.jpeg)

2.List,Set,Map:

List：存储的元素是有序的，可重复的，包含ArrayList（Object[]数组），Vector（Object[]数组），LinkedList（jdk1.7之前是循环链表，之后是双向链表）。

Set：存储的元素是无序的，不可重复的，包含HashSet（无序，唯一，基于HashMap实现，底层采用HashMap保存元素，添加数据保存成Map的key，value设置成固定的Object的对象，源码中是
空对象new Object()，采用Map的key不能重复的特性来保证Set不能添加重复元素），LinkedHashSet（是HastSet的子类，内部通过LinkedHashMap实现，LinkedHashMap是Map和双向链表的实现，
一般map除了本身存储数据的结构外，还会维护一个Entry<K,V>用来存储key-value的值，方便遍历。LinkedHashMap在初始化时在创建Map时，初始化一个自定义的Entry<K,V>继承HashMap的Node节点，
由于Node节点本身是链表形式，所以Entry<K,V>会存储前后节点，LinkedHashMap在插入时会在Entry<K,V>中按照插入顺序记录，当遍历LinkedHashSet时，底层遍历的是Entry<K,V>，所以是
有序的，按照插入顺序，而遍历HashSet时，底层遍历的存储数据的数组，即按照数据存放的顺序，所以是无序的），TreeSet（有序，唯一，内部为红黑树）。

Map：存储键值对，key无序，不可重复。value无序，可重复。包含HashMap（jdk1.8之前由数组和链表组成，数组存放数据，链表解决哈希冲突，jdk1.8之后，当链表长度大于
阈值时，默认是8，然后会判断数组长度，长度小于64会先选择数组扩容，大于会将链表转换为红黑树，减少搜索时间），LinkedHashMap（双向链表和Map），HashTable（数组+链表），
TreeMap（红黑树，自平衡的排序二叉树）。HashMap和LinkedHashMap的key和value可以为null值，HashTable的key和value都不能为null值，TreeMap的key不能为null，value可以为空，
因为HashMap在put计算key的hashCode时会判断key是否为null，是则返回0，而HashTable是直接计算key的hashCode，而null调用hashCode时会报空指针异常，而且HashTable put判断value
是否为null，是则抛出空指针异常。TreeMap在put时会通过compare比较key，当比较的key是null值时会抛出空指针异常。

3.List集合：

ArrayList和LinkedList：ArrayList底层实现是Object[]数组，LinkedList底层是双向链表；ArrayList和LinkedList都是线程不安全的；ArrayList底层用数组，
所以插入和删除时间受元素位置影响，指定位置的插入和删除会导致后面的数据后移或前移一位，LinkedList是链表，插入和删除数据都是更新元素的前后驱节点；ArrayList
支持随机元素访问，LinkedList不支持；内存占用方面ArrayList总会在列表的尾部预留一定空间，LinkedList每个元素额外存放前后驱节点。

ArrayList和LinkedList插入和删除效率：根据插入或删除元素的位置不同，两种集合的操作时间也不相同。当元素在首部插入或删除时，ArrayList需要前移或后移该元素
之后的所有元素，而LinkedList只需要修改元素的前后驱节点即可，所以ArrayList<LinkedList；当元素在尾部插入和删除时，ArrayList可以快速访问到尾部数据，不需要
移动数据，而LinkedList保存有头尾节点的数据，所以也能快速访问到尾部数据，两种List尾部数据操作差别不大。但是当ArrayList扩容时需要复制数据，会导致操作时间
增加；当元素在中间插入或删除时，ArrayList支持快速随机访问，可以快速获取元素位置下标，LinkedList根据二分遍历查找元素，越靠近中间遍历时间越长。所以越靠近
中间位置，LinkedList的插入和删除会慢。

4.ArrayList快速随机访问：

实现RandomAccess接口，只是一个标识，并没有实际的实现方式，这个标识只是标志集合具有随机访问的功能，因为ArrayList底层是Object[]数组，底层实现了随机访问，
RandomAccess接口只是一个标识，用来在某些方法中判断集合是否支持随机访问，在 Collections.binarySearch() 方法中，它要判断传入的 list 是否 RamdomAccess 的实例，
如果是，调用indexedBinarySearch()方法，如果不是，那么调用iteratorBinarySearch()方法。

5.ArrayList扩容：

```
/**
 * 默认第一次扩容
 */
private static final int DEFAULT_CAPACITY = 10;

/**
 * 出现在需要用到空数组的地方，其中一处是使用自定义初始容量构造方法时候如果你指定初始容量为0的时候，那么elementData指向该数组。
 * 另一处是使用包含指定collection集合元素的列表的构造方法时，如果被包含的列表中没有数据，那么elementData指向该数组。
 */
private static final Object[] EMPTY_ELEMENTDATA = {};

/**
 * 如果使用默认构造方法，那么elementData指向该数组。在添加元素时会判断是否是使用默认构造器第一次添加，如果是数组就会扩容至10个容量。
 */
private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};

/**
 * 设置初始化容量
 */
public ArrayList(int initialCapacity) {
    if (initialCapacity > 0) {
        this.elementData = new Object[initialCapacity];
    } else if (initialCapacity == 0) {
        this.elementData = EMPTY_ELEMENTDATA;
    } else {
        throw new IllegalArgumentException("Illegal Capacity: "+
                                           initialCapacity);
    }
}

/**
 * 无参构造设置初始化容量
 */
public ArrayList() {
    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
}

/**
 * 初始化集合设置容量
 */
public ArrayList(Collection<? extends E> c) {
    // 集合转为数组
    elementData = c.toArray();
    // 判断是否是空数组
    if ((size = elementData.length) != 0) {
        // 有数据判断是否是Object对象，不是则转换成Object[]数组
        // 这个判断主要是考虑通过特殊转换的集合调用toArray()的方法返回的不一定是Object[]数组，
        // 比如Arrays.toList()方法返回的ArrayList是Arrays内部实现的一个类，toArray的实现是a.clone()，即是拷贝原数组对象
        // 在给数组赋值一个Object对象时就会报错，所以需要强制转化成Object[]数组。
        if (elementData.getClass() != Object[].class)
            elementData = Arrays.copyOf(elementData, size, Object[].class);
    } else {
        // 空数组赋值容量为空
        this.elementData = EMPTY_ELEMENTDATA;
    }
}
```
以无参构造ArrayList时，实际上初始化赋值是一个空数组，并没有出现扩容。只有添加第一个元素时，无参构造的ArrayList会直接扩容成初始值10，
而有参构造的ArrayList会根据初始容量判断扩容。jdk1.7只会有一个EMPTY_ELEMENTDATA静态空数组变量用来给无参构造赋值，有参构造直接new
一个空数组，jdk8将有参构造的空数组变成一个静态变量，ArrayList空实例中所有的空数组指向一个，优化性能。

```
/**
 * Appends the specified element to the end of this list.
 *
 * @param e element to be appended to this list
 * @return <tt>true</tt> (as specified by {@link Collection#add})
 */
public boolean add(E e) {
    // 判断是否扩容
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    elementData[size++] = e;
    return true;
}

/**
 * Appends the specified element to the end of this list.
 *
 * @param e element to be appended to this list
 * @return <tt>true</tt> (as specified by {@link Collection#add})
 */
private void ensureCapacityInternal(int minCapacity) {
    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
}

/**
 * Appends the specified element to the end of this list.
 *
 * @param e element to be appended to this list
 * @return <tt>true</tt> (as specified by {@link Collection#add})
 */
private static int calculateCapacity(Object[] elementData, int minCapacity) {
    // 判断是否是无参构造的，无参的直接比较初始容量(10)和添加元素的数量的较大值
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        // 无参构造添加的第一个元素会扩容成初始容量10
        return Math.max(DEFAULT_CAPACITY, minCapacity);
    }
    return minCapacity;
}

/**
 * Appends the specified element to the end of this list.
 *
 * @param e element to be appended to this list
 * @return <tt>true</tt> (as specified by {@link Collection#add})
 */
private void ensureExplicitCapacity(int minCapacity) {
    // 数组的改变标识增加
    modCount++;

    // 元素容量不足进行扩容
    if (minCapacity - elementData.length > 0)
        grow(minCapacity);
}

/**
 * Increases the capacity to ensure that it can hold at least the
 * number of elements specified by the minimum capacity argument.
 *
 * @param minCapacity the desired minimum capacity
 */
private void grow(int minCapacity) {
    // 获取集合元素容量
    int oldCapacity = elementData.length;
    // 扩容成原容量的1.5倍
    int newCapacity = oldCapacity + (oldCapacity >> 1);
    // 如果扩容后的容量比添加元素后的容量小，直接扩容成添加后的元素
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    // 如果扩容后的容量比数组推荐最大容量(Integer.MAX_VALUE-8)大则重新分配容量或溢出异常
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    // minCapacity is usually close to size, so this is a win:
    // 将原数据复制到扩容后的数组
    elementData = Arrays.copyOf(elementData, newCapacity);
}

private static int hugeCapacity(int minCapacity) {
    // minCapacity<0是指当minCapacity大于Integer.MAX_VALUE之后，计算机二进制计算后会变成负数，判断成数组溢出
    if (minCapacity < 0) // overflow
        throw new OutOfMemoryError();
    // minCapacity>MAX_ARRAY_SIZE(Integer.MAX_VALUE-8，实际上这只是ArrayrList建议的数组的最大长度，某些VM的实现可能需额外的长度存储一些头信息，
    // 最大长度超过MAX_ARRAY_SIZE在某些VM上可能引发OutOfMemoryError)，则设置成最大容量(Integer.MAX_VALUE)，否则设置成MAX_ARRAY_SIZE
    return (minCapacity > MAX_ARRAY_SIZE) ?
        Integer.MAX_VALUE :
        MAX_ARRAY_SIZE;
}

```
new ArrayList()和new ArrayList(0)在扩容方面是不同的，无参构造的ArrayList在第一次添加元素时会判断是否是无参构造的第一次添加，是的话会将容量
扩充为初始的默认值10，然后当添加到达10以后扩容成15，22，33，49，73...这样。而0参数构造的的ArrayList第一次添加会扩容成1，
然后是2，3，4，6，9，13...这样严格按照1.5倍扩容，这样扩容增长较慢。

ArrayList判断扩容的条件是当值size>length，即集合的元素数量大于内部的数组的长度之后，会将内部数组的元素复制到扩容后的数组内，多余部分为null。

ArrayList扩容不一定每次都是旧容量的1.5倍，int newCapacity = oldCapacity + (oldCapacity >> 1); oldCapacity为奇数时会丢掉小数，偶数就是
1.5倍。获取新的容量后还要和需要的容量比较，如果新的容量小于所需的容量，就直接扩容成需要的容量，比如10个元素时，需要添加6个元素，但是扩容只新增5个，
最后就会容量就会变成16个。
```
if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
```

ArrayList内部的System.arraycopy()和Arrays.copyOf()：

都是复制数组，copyOf()内部调用的就是arraycopy(),arraycopy()需要目标数组，将原数组拷贝到自定义的数组或原数组，可以选择拷贝的起点和长度以及
放入新数组的位置，copyOf()是在系统内部自动新建一个数组，并且返回该数组。

ArrayList的ensureCapacity(int minCapacity)方法可以手动指定扩容的容量，可以减少自动扩容的计算时间。

6.无序性和不可重复性：

无序性是指存储的数据在底层数组中不按照数组的索引顺序添加，而是按照数据的哈希值决定。不可重复性是指添加元素时按照equals判断时是否重复数据，
同时重写equals和hashCode方法。

7.HashSet，LinkedHashSet，TreeSet：

HashSet底层是HashMap，线程不安全，可以存储null；LinkedHashSet是HashSet的子类，链表组成的HashSet，按照添加顺序遍历；TreeSet底层使用
红黑树实现，能够按照元素添加顺序遍历，可以自定义排序规则。

8.HashMap和Hashtable：

HashMap是非线程安全的，Hashtable是线程安全的，因为Hashtable内部的方法基本上经过synchronized修饰，但是效率不高，保证线程安全可以使用ConcurrentHashMap；
HashMap的效率比Hashtable高，HashTable基本被淘汰；HashMap可以存储null的key和value，但是null key只能有一个，null value可以有多个，Hashtable
不允许null的key和value。

```
/**
 * 无参默认的容量(16)，必须是2的幂次方
 */
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

/**
 * 最大的容量(2^30)。2的幂次方
 */
static final int MAXIMUM_CAPACITY = 1 << 30;

/**
 * 默认的加载因子
 */
static final float DEFAULT_LOAD_FACTOR = 0.75f;

/**
 * 链表转化为红黑树的阈值，大于8，链表转化为红黑树
 */
static final int TREEIFY_THRESHOLD = 8;

/**
 * 红黑树转化成链表的阈值，当扩容方法resize()中判断是否是树节点，是的话调用split()拆分红黑树，
 * 当拆分的后的红黑树节点数量<=6时，会将红黑树转换为链表。只在split()方法内部使用这个阈值，在remove方法
 * 中并不会判断此阈值，因此不能使用该变量！
 */
static final int UNTREEIFY_THRESHOLD = 6;

/**
 * 哈希表转化成红黑树的最小容量，哈希表的容量>=64时，才允许链表转化成红黑树，否则只是扩容不转化。
 */
static final int MIN_TREEIFY_CAPACITY = 64;

/**
 * 哈希表中存储的key-value节点数组，长度是2的幂次方，链表节点或红黑树节点
 */
transient Node<K,V>[] table;

/**
 * 存储键值对集合，底层还是根据节点对象去获取key-value
 */
transient Set<Map.Entry<K,V>> entrySet;

/**
 * 集合中的元素数量
 */
transient int size;

/**
 * 扩容的阈值(容量 * 加载因子)，哈希表大小大于阈值时会发生扩容操作
 * @serial
 */
int threshold;

/**
 * 实际的加载因子，是控制数组存放数据的疏密程度，约趋近于1，数据存放越密集，越会发生哈希冲突，链表的长度越长
 * @serial
 */
final float loadFactor;

/**
 * 初始容量和加载因子构造
 */
public HashMap(int initialCapacity, float loadFactor) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException("Illegal initial capacity: " +
                                           initialCapacity);
    // 大于最大容量则返回最大容量
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException("Illegal load factor: " +
                                           loadFactor);
    this.loadFactor = loadFactor;
    // 设置扩容阈值，设置的扩容阈值是初始设置的容量的转化成的最小2的幂次方，
    // 至于为什么不设置成容量*加载因子，由于初始化map后第一次put时table数组没有初始化，会触发
    // 扩容操作，会判断threshold的值，如果为空，则扩容后容量为默认容量(16)，扩容阈值是16*0.75，
    // 如果threshold有值则扩容成threshold的值，由于map保证容量为2的幂次方来保证减少哈希冲突，如果这里将
    // threshold设置为容量*加载因子，由于加载因子不固定，所以threshold可能不是2的幂次方，所以这里只是用
    // threshold保存转换后的容量，再扩容时才真正的设置threshold的值
    this.threshold = tableSizeFor(initialCapacity);
}

/*
 * 扩容操作
 */
final Node<K,V>[] resize() {
    // 获取旧数组
    Node<K,V>[] oldTab = table;
    // 获取旧数组容量 第一次扩容旧数组为0
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    // 获取设置的扩容阈值
    int oldThr = threshold;
    int newCap, newThr = 0;
    // 旧容量大于0
    if (oldCap > 0) {
        // 如果旧数组容量大于等于最大容量，设置扩容阈值为Integer.MAX，直接返回旧数组
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 如果旧数组扩容2倍后新数组容量小于最大容量并且旧数组容量大于等于初始默认容量(16)，新阈值设置为
        // 旧阈值的两倍，因为容量扩充了两倍
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    // 旧容量小于0，旧扩容阈值大于0，设置新容量为旧扩容阈值，第一次put时会扩容到扩容阈值，如果Map初始化设置了加载因子和容量时会设置扩容阈值，
    // 由于Map需要保证每次扩容都是2的幂次方，但是无法控制设置的初始化的加载因子，所以会在初始化时将扩容阈值设置为tableSizeFor获取的容量值。
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
        // 旧容量小于0并且旧扩容阈值小于等于0，新容量设置为默认初始容量(16)，新扩容阈值设置为默认加载因子*默认容量，即0.75f*16
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        // 如果新的扩容阈值等于0，计算新容量*加载因子，新容量小于最大容量并且计算的值小于最大容量则
        // 设置扩容阈值为计算的值，否则设置为Integer.MAX
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    // 复制数据
    @SuppressWarnings({"rawtypes","unchecked"})
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        // 遍历转移旧数据
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                // 设置旧数组为null
                oldTab[j] = null;
                if (e.next == null)
                    // Node没有子节点则通过hash计算在新数组的下标，存进新数组
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    // Node节点是红黑树则进行拆分
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                    // 存放在新数组不需要移动索引位置的头尾节点
                    Node<K,V> loHead = null, loTail = null;
                    // 存放在新数组需要移动索引位置的头尾节点
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        // 获取子节点
                        next = e.next;
                        // 当前节点的hash&旧容量==0，将节点存储在不需要移动索引的链表中
                        // e.hash & oldCap的结果是否为0可以判断在新旧数组中节点的索引是否改变
                        // 由于容量都是2的幂次方
                        // e.hash  xxx0xxxxx                        xxx0xxxxx
                        // oldCap  000100000             oldCap-1   000011111
                        // newCap  001000000             newCap-1   000111111
                        // 由于需要保证e.hash&(oldCap-1)和e.hash&(newCap-1)是一样的，而newCap-1比oldCap-1的二进制多一个高位1
                        // 则e.hash对应在高位1的位置必须是0，由于oldCap除了对应高位是1外其他位是0，所以可以通过e.hash&oldCap
                        // 来判断e.hash的对应高位是否是0，若是0则代表在新旧数组中节点的位置不变。
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        // 当前节点的hash&旧容量!=0，将节点存储在需要移动索引的链表中
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    // 不需要移动索引的链表放在新数组的原位置
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    // 需要移动索引的链表在新数组的索引是在旧数组的索引加上旧数组容量
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}


/**
 * 使用位移确保返回大于等于cap的最小2的幂次方，由于Map的容量需要保证为2的幂次方(为了减少哈希冲突)，需要对设置的初始容量进行转化
 */
static final int tableSizeFor(int cap) {
    int n = cap - 1;
    // 下面五个移位或运算主要是将n除了高位1的所有低位全部变成1，即将1xxxx->11111，或(|) 只要有1就是1，
    // 这样产生的数字11111+1之后变成100000，就是n+1大于1xxxx的最小2的幂次方，
    // 在cap不是2的幂次方时可以直接使用下面的移位或，但是当cap是2的幂次方时直接移位或
    // 会得到大于cap的2的幂次方，所以将cap-1之后计算就可以得到大于等于cap的最小2幂次方
    // 下面的移位或是将n的最高位和每个低位进行或运算，由于n的最高位一定是1，所以或运算会
    // 将低位全部变成1。
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    // 当cap为0时n就会小于0，最小2的幂次方就是2^0=1，当n>=MAXIMUM_CAPACITY时就设置为MAXIMUM_CAPACITY
    // 其他返回n+1
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}

/**
 * 设置初始容量，默认加载因子(0.75f)
 */
public HashMap(int initialCapacity) {
    this(initialCapacity, DEFAULT_LOAD_FACTOR);
}

/**
 * 无参构造设置默认容量(16)和默认加载因子(0.75f)
 */
public HashMap() {
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}

```
无参构造时，HashMap默认容量是16，每次扩容是原来的2倍，Hashtable默认是11，每次扩容是2n+1。有参构造时，HashMap会设置成大于等于设置容量的最小2的幂次方，
Hashtable直接使用设置的容量；JDK1.8之后HashMap用链表或红黑树解决冲突，当链表长度大于8并且数组长度大于64时，会将链表转换为红黑树，如果长度小于64会先
进行扩容操作而不转化红黑树。其实在HashMap初始化时并没有创建一个指定容量的Map，只有在第一次put时才会进行Map容器的初始化构建。HashMap的树形链表转化为
链表时主要是在resize()和remove()方法中，resize()方法内对树形链表会调用split()方法拆分，当树形链表的节点数量<=UNTREEIFY_THRESHOLD(6)时会将树形链表
转化为普通链表。remove()方法中对树形链表调用removeTreeNode()方法，在删除节点之前会判断树的结构是否能够构成红黑树，即最少为3，最多为10个节点时无法构成
红黑树，红黑树会转化为普通链表。

9.HashMap实现：

JDK1.8之前：底层采用数组加链表的链表散列，HashMap通过key的hashCode进行扰动函数之后获取hash值，然后通过(n - 1) & hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），
当位置已经存放了元素之后，判断该元素和要存入的的元素的hash值和key值是否相等，相等则覆盖，不相等则通过拉链法，即链表解决冲突。

HashMap使用hash函数(扰动函数)而不是直接使用hashCode()，是为了防止一些实现较差的hashCode()，减少哈希碰撞的次数。jdk1.8减少了扰动的次数，提高性能。
```
/**
 * jdk 1.8 hash扰动函数
 */
static final int hash(Object key) {
  int h;
  // key.hashCode()：返回散列值也就是hashcode
  // ^ ：按位异或
  // >>>:无符号右移，忽略符号位，空位都以0补齐
  return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}


/**
 * jdk 1.7 hash扰动函数
 */
static int hash(int h) {
    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).

    h ^= (h >>> 20) ^ (h >>> 12);
    return h ^ (h >>> 7) ^ (h >>> 4);
}

```

JDK1.7插入链表数据采用头插法，JDK1.8采用尾插法，头插法是将新节点放在链表头部，尾插法将新节点放在链表的尾部。头插法能够使后面插入的数据
更大概率被访问，相比尾插法不需要遍历链表，效率更高。但是头插法在多线程的扩容情况下可能会出现循环链表情况，造成遍历死循环。主要是在JDK1.7扩容
的时候会遍历旧数组，通过头插法插入到新数组，即扩容后的链表顺序会颠倒。
```
void transfer(Entry[] newTable, boolean rehash) {
    //新数组容量
    int newCapacity = newTable.length;
    //旧数组，将桶中的每一个链表转移到新数组中，注意这里是从链表的头部开始遍历的
    for (Entry<K,V> e : table) {
        // 遍历数组内的链表
        while(null != e) {
            //关键位置1
            Entry<K,V> next = e.next;
            //关键位置2
            /*hashCode-->扰动算法-->h & (length-1) 计算在新数组中的位置*/
            if (rehash) {
                e.hash = null == e.key ? 0 : hash(e.key);
            }
            // 获取key在新数组的位置
            int i = indexFor(e.hash, newCapacity);
            /*这三步，就是头插法的运用,后续的节点将会插入到新数组链表头部*/
            // 当前链表节点的下级节点设置为新数组已经存储的节点，然后将新数组节点设置为新更新的节点，后插入的节点放在链表的头部
            // 比如链表是1->2->3，e=1->2->3，遍历1时e.next=newTable[i]=null，那么e=1->null，那么newTable[i]=e=1->null，e=2->3,
            // 当遍历2时e.next=newTable[i]=1->null，那么e=2->1->null，newTable[i]=2->1->null，e=3
            // 所以e.next=newTable[i]是将遍历的当前节点放入新数组链表的头部，newTable[i] = e是将链表放回新数组，e = next是继续遍历下一个节点
            e.next = newTable[i];
            newTable[i] = e;
            e = next;
        }
    }
}
```
当两个线程A和B同时put都需要扩容时，假设链表为1->2，当A线程在关键位置1时还未进行插入节点操作，B线程已经完成扩容操作，虽然AB线程创建的新数组是相互隔离的，
但是内部的元素是共享的，即AB的Entry内的链表数据是共享的，A和B开始的Entry都是1->2，A在关键位置1时B将Entry变为为2->1，A线程进行节点插入操作，e=1->2，
next=2，插入节点e.next=newTable[i]=null，newTable[i]=1，e=2，第二次遍历时e=2，由于B将e变成了2->1，next=1，e.next=newTable[i]=1，newTable[i]=2->1，
e=1，第三次遍历时e=1，next=null，e.next=newTable[i]=2->1，newTable[i]=1->2->1，e=null，第四次遍历的时候判断e=null，跳出while，这时新数组中的Entry
中1.next=2，2.next=1，形成了环形链表，这样在进行链表遍历时就会出现死循环。JDK1.8的尾插法避免了死循环的出现，但是在多线程中给新数组赋值时会出现相互覆盖的
情况，所以不能避免节点丢失，因此并发情况下建议使用ConcurrentHashMap。

10.HashMap结构：

![timewoo](https://timewoo.github.io/images/HashMap.png)

11.HashMap的长度是2的幂次方：

HashMap为了减少碰撞，需要将数据平均分配，如果直接采用hash的值(-2147483648 到 2147483647，前后加起来大概 40 亿的映射空间)，只要将数据映射的
均匀基本很难出现碰撞，但是内存无法存储这么大的数组，所以需要将hash的值和数组的长度进行取模运算(hash%length)，得到的余数就是存放在数组中的位置下标。
考虑到采用二进制的&操作会提高运算效率，如果length是2的幂次方，则hash%length == hash&(length-1)，所以数组长度设置为2的幂次方可以加快获取下标的运算效率。

12.线程安全的Map：

JDK1.7的ConcurrentHashMap对底层数组进行分段，每一段数据分配一个锁Segment，每个锁只锁定部分数据，多线程访问不同数据段时不会存在锁竞争。提高并发效率。
JDK1.8的ConcurrentHashMap丢弃分段锁，直接对table数组的每个Node节点加锁，提高并发度，同时用CAS(类似乐观锁，维护一个变量，操作时比较变量来判断是否有并发操作)来完成对单个元素的读写操作。
Hashtable采用全表锁来控制并发，效率低下。

13.集合的快速失败（fail-fast）：

快速失败（fail-fast）是java集合的一种检错机制，在用迭代器对集合进行遍历时，在多线程下操作非安全失败（fail-safe）的集合时可能触发fail-fast，抛出ConcurrentModificationException
异常，在单线程下遍历的同时修改集合也会触发fail-fast，原理是当迭代器调用next()或hasNext()遍历集合时，会判断两个变量modCount（集合修改的次数，包括add和remove操作）
和expectedModCount（默认赋值modCount）是否相等，相等则返回遍历数据，不等则抛出异常，终止遍历。如果多个线程操作或单个线程遍历时修改集合，会导致modCount改变而expectedModCount不变，
就会抛异常，而Iterator的修改方法在改变modCount的同时修改expectedModCount，所以Iterator可以在遍历的同时修改集合。

安全失败（fail-safe）是指集合在遍历时不会直接访问集合的数据，而是复制原来集合的数据，在拷贝的集合上进行遍历，原数组的改变不会影响拷贝数组。




