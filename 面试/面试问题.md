1. java基础
   1. 基础类型的字节占用，最大最小值，int 4字节，-2^31~2^31-1，20亿
   2. Object的方法，具体有toString，clone，equals，wait，notify，notifyAll，getClass，hashCode
   3. string，stringBuffer，stringBuilder，string采用final修饰数组，无法修改，所以需要创建新对象，stringbuffer和stringbuild没有使用final修饰数组，所以可以修改原数组，stringbuffer线程安全，stringbuilder线程不安全。string的不可变性是为了保证运行常量池的需要，保证在常量池中的字符串不可变，为了保证在多线程下同步的问题，由于string的不变性，hashcode不变，可以缓存hashcode。避免安全问题。
   4. 深拷贝和浅拷贝，String的拷贝，深拷贝，对象内的引用变量拷贝一份，浅拷贝，对象内的引用变量拷贝地址。
   5. 反射能够获取的类信息，类信息，属性，方法，注解
   6. 泛型的作用，JDK 1.5之前没有泛型时，当需要定义集合类时，由于集合可以存储String、Integer等不同对象，只能定义为Object对象，但是这样当插入不同类型数据时需要手动进行类型转化，同时运行期可能出现类型转化错误，所以JDK 1.5出现泛型，创建时确定参数类型，类型转化判断提前到编译器。
      1. 类型安全，类型转化错误从运行期提前到编译期
      2. 消除强制类型转化，可以直接获取对应的类型，无需强制转化
   7. 泛型擦除，由于泛型是在编译器实现，所以在字节码层面不包含泛型的类型信息，这主要是为了保证和JDK 1.5之前的版本开发的依赖库进行兼容，因此泛型的类型是相同的，一般都是object类型，List<String>.class = List<Integer>.class，字节码层面都是List。这样如果通过反射调用List的add()方法就可以插入不同类型的数据，因为反射是在字节码层面去实现的。
   8. 泛型 extends和super的区别，extends T代表泛型的数据都是T的子类，获取的数据都可以转化成T，所以可以进行数据的读取，但是在插入时编译器无法判断子类数据之间是否有冲突，所以限制数据的插入。super T代表泛型的数据都是T的超类，甚至是Object，插入数据可以保证是T的超类，但是在获取时无法判断是T的哪个父类，甚至是Object的，所以限制数据的获取。
   9. 注解的作用，可以对包，参数，类，接口，方法等添加标注，使用反射可以获取对应的标注信息。比如spring在类上添加@Component或者在属性上添加@Value，可以通过反射获取到对应的注解信息。
   10. java特性，使用场景，封装（将对象的属性隐藏在内部，只能用对外提供的方法操作属性，优势是出口统一，方便做统一处理；对外隐藏内部实现，修改无需改变方法调用），继承（在已有类的基础上创建新类，新类可在父类基础上新增功能，优势是可以提高代码的复用性，程序的可维护性，提升开发效率，子类拥有父类所有属性和方法，无法访问父类私有属性和方法），多态（一个对象在不同情况下有多种状态，父类引用实际指向子类的实例，运行期确认状态）
   11. 自定义注解使用场景，做统一处理，日志或者接口权限校验
   12. 抽象类使用，抽象子类同一属性。
   13. 设计模式使用场景，责任链、适配器、模板、策略模式
   14. for和foreach区别，foreach无法跳出循环，无法进行修改。foreach使用的是迭代器，内部使用next来进行遍历，会有额外操作，所以在大数据量下会比单纯的forloop效率低。
   15. function和consumer区别，function消费对象，需要有返回值，consumer消费对象，不需返回值。
   16. SPI，service provider interface，java内置的服务发现机制，java定义一个抽象接口，开发人员可自定义加载外部实现类来做到扩展和替换。类似JDBC和Dubbo等框架定义接口形式，开发可自行进行扩展和实现。主要是通过ServiceLoader来反射获取对应实现类，在配置完成接口和实现类后，需要在META-INF/services下新建对应接口的全限定名文件，然后文件内部配置实现类全限定名。然后通过ServiceLoader加载配置文件，然后通过反射实例化所有实现类，加载到内存中。缺点是一个接口多个实现需要全部遍历实例化，会破坏双亲委派原则，SPI直接使用classloader加载具体类。
2. 集合
   1. Map实现类，HashMap put流程，resize过程
   2. HashMap、HashTable、ConcurrentHashMap线程安全和实现，hashMap线程不安全，hashTable线程安全，效率低，get，put都使用synchronized修饰，ConcurrentHashMap线程安全，1.7分段加锁，1.8单个node节点加锁
   3. CopyOnWriteArrayList多线程访问，写写加锁，读取时copy一份数据，读写不干扰。
   4. 有序map，TreeMap，
3. 多线程
   1. volatile原理（内存屏障，可见性）、synchronized原理（互斥锁，重量级锁）
   2. synchronized和ReentrantLock区别（可重入，公平非公平锁，自动解锁，中断，唤醒指定线程）
   3. AQS 思想、实现类（通过同步器来实现互斥，队列存储线程（双向链表），Reentrantlock，Simphore，CountDownLatch、CyclicBarrier），公平和非公平区别，非公平锁比公平锁多一次CAS操作。
   4. CAS，具体实现类有哪些（JUC下atomic包，AtomicInteger，AtomicBoolean，AtomicReference，getAndSet，compareAndSet）
   5. 如何确定线程池初始化数量，CPU密集型（一些逻辑运算）使用cpu+1，IO密集型（文件网络操作）使用2*cpu
   6. 线程池为什么需等待队列满后才创建新线程，如何反转这个流程，由于创建线程需要获取到全局锁，会影响并发效率，所以线程池在核心线程满了以后会把任务放入等待队列中，是为了作为缓冲，避免线程创建引发的锁竞争。如果想反转这个流程需要自定义线程池，继承ThreadPoolExecutor，重写execute方法，同时需要自定义队列，继承LinkedBlockingQueue，重写offer方法，execute内部去创建新线程，同时自定义队列的offer去判断最大线程数来放入队列。tomcat线程池类似。
   7. 哪些线程安全的类，atomic，stringbuffer，concurrentHashMap，copyOnWriteArrayList
4. JVM
   1. jmm内存模型，原子性，可见性和有序性，原子性：赋值，可见性：内存屏障，有序性：指令重排
   2. 1.8的metaspace的gc和1.7的永久代gc的不同，都是在full gc过程中去回收内存，永久代是根据对象的可达性分析去回收，元空间是判断对象的类加载器ClassLoader是否可以回收来回收对象。
   3. 内存分配方式，空闲列表（free list）和碰撞指针（bump pointer）
   4. 对象回收判断方法，引用计数法和可达性分析，引用计数法如何解决循环引用，使用recycler算法解决
   5. GC Root，必须是一组活跃的引用，即全局引用变量以及栈内的引用变量。活跃线程栈帧的引用变量；类的静态引用变量；已被加载的java类以及类加载器；JNI句柄；方法区常量池中的引用；被synchronized持有的引用对象等。
   6. 常见垃圾回收器，CMS（并发老年代），G1（并发新老代，分区），Serial（新生代串行），Serial Old（老年代串行）
   7. JVM的GC有哪些，都是在哪些情况下出现，young gc（eden满）、old gc（老年代满了）、full gc（元空间满了）
   8. gc的stw，如何高效进行垃圾回收
   9. full GC，老年代或者元空间内存不足
   10. 如何判断CPU升高原因，top查看进程CPU占用，查找CPU占用过高的进程，然后查询进程下占用CPU高的线程，然后使用jstack显示堆栈信息，是否有频繁GC，使用jstat查看GC次数，jmap下载dump文件查看堆栈快照。使用MAT分析dump文件。
5. spring AOP底层实现
   1. 静态代理：代理类和真实类实现相同接口，动态代理：真实类实现接口（反射）、cglib：真实类继承父类（ASM，拦截器）
   2. 流程 annotation->注入AnnotationAwareAspectJAutoProxyCreator Bean->BeanPostProcessor处理->获取所有切面通知组装成链表->使用JDK或者cglib生成代理对象->方法调用时动态代理使用invoke方法增强，cglib会调用第一个拦截器的intercept方法->筛选通知链表->链式调用通知->调用真实方法
6. spring 容器启动流程 prepareRefresh（预处理，开始时间和活跃标志，property source初始化）-> obtainFreshBeanFactory（刷新beanfactory，xml注入需要销毁重新加载，annotation设置ID）-> prepareBeanFactory（设置beanfactory class loader，设置忽略自动装配和进行自动装配的接口）-> postProcessBeanFactory（子类实现自定义beanfacotoryPostprocessor）-> invokeBeanfactoryPotProcess（顺序执行beanfactoryPotProcessor，手动指定，实现PriorityOder接口，实现Order接口，剩余beanfacotyPostProcessor）-> registerBeanPostProcessor（注册BeanPostProcessor，顺序和上面一样）-> initMessageSource（国际化、消息绑定与解析）-> initApplicationEventMulticaster（初始化事件广播器）-> OnRefresh（子类自定义刷新逻辑）-> registerListeners（注册监听器，接收广播器事件派发）-> finishBeanFactoryInitialization（初始化所有单例bean）-> finishRefresh（清理缓存，初始化生命周期后置处理器，回调生命周期后置处理器OnRefresh，发布刷新事件）-> restCommonCaches（重置反射元数据缓存）
   1. bean的生命周期，初始化->设置属性->调用自定义Aware接口实现->beanPostProcessor前置处理->afterProperties->调用init->beanPostProcessor后置处理->使用->销毁调用destory方法
   2. beanFactory和factoryBean区别：beanFactory是一个工厂类，是IOC的核心接口，用于实例化、定位、配置以及管理对象之间的的依赖，定义了IOC底层的编程规范。factorybean是一个bean，是一个能够生产或者修饰对象的工厂bean。beanFacotry只提供了基本的依赖注入、依赖查找，而factorybean则提供了复杂bean的创建，比如代理对象的创建等。
   3. 自定义bean
   4. 事务传播级别
      1. PROPAGATION_REQUIRED：存在则合并，否则新建事务
      2. PROPAGATION_SUPPORTS：存在则合并，否则就没有事务
      3. PROPAGATION_MANDATORY：存在则合并，否则就报错
      4. PROPAGATION_REQUIRES_NEW：创建新事务，存在则挂起旧事务
      5. PROPAGATION_NOT_SUPPORTED：非事务运行，存在则挂起旧事务
      6. PROPAGATION_NEVER：非事务运行，存在则报错
      7. PROPAGATION_NESTED：存在事务则嵌套，否则就新建事务
   5. 如何判断有没有事务
   6. 循环依赖，三级缓存，singletonObjects（初始化完成的bean），earlySingletonObjects（实例化为初始化的bean），singletonFactories（进入实例化阶段的单例工厂bean），三级缓存逐级查询，首先放在三级缓存中，实例化后放在二级缓存，初始化后放在一级缓存中，三级缓存的目的是为了保证注入是代理对象，因为代理对象是在bean的后置处理器生成的，如果只有两级缓存就无法获取代理对象，所以需要三级缓存来处理注入代理对象的问题。
   7. 如何构建一个starter，spring boot 启动时会有自动装配的过程，即会在类路径下查找spring.factories文件，加载自动配置的bean到IOC容器中，所以构建一个自定义starter，首先创建一个spring项目，引入spring boot starter依赖，然后创建一个自动配置类，使用@Configuration和@Bean注解，然后再项目的resources/META-INF目录下创建spring.factories文件，文件配置对应的类，org.springframework.boot.autoconfigure.EnableAutoConfiguration=配置类全限定名。然后构建完成后就可以再起来项目中使用。
   8. 自动装配设计，通过扫描META-INF/spring.factories文件，将文件配置中的类信息加载到spring容器中，并执行类中定义的各种操作，无需配置xml文件即可使用三方依赖组件的功能。
   9. 自定义注解实现
7. spring mvc，解决了在java web开发中使用Servlet的复杂度，通过Model-View-Controller的结构，对外屏蔽Servlet的原始方法，开发者更加注重于API相关设计和开发。
8. spring cloud
   1. spring feign设置header，使用ResquestMapping的header属性
   2. openfeign底层原理
   3. spring gateway
      1. 三大概念：路由（Route）、断言（Predicate）、Filter（过滤），route配置id，uri，predicate和filter，通过predicate来实现路由的匹配规则，filter去做过滤器逻辑。
      2. 工作流程：客户端请求，gateway通过gateway handler Mapping找到匹配路径的路由，发送给gateway web handler，handler通过filter chain进行过滤操作，比如修改请求头，参数校验，权限校验等，过滤后转发到对应服务进行业务处理。响应返回时再经过过滤后返回客户端。
      3. zuul的区别，gateway内部实现了限流、负载均衡、熔断等。zuul没有。gateway支持异步（webflux），zuul只支持同步。
      4. 如何做限流，在gateway拦截器中使用RequestRateLimiterGatewayFilterFactory来使用redis作为限流
      5. 限流算法，固定窗口，滑动窗口，漏桶，令牌桶
   4. ribbon底层实现，使用restTemplate的拦截器，在RPC调用前通过LoadBalanceInterceptor进行负载均衡。ribbon中定义了LoadBalanceInterceptor类，然后注入到restTemplate中，然后在restTemplate远程调用时，拦截RPC调用，对注册中心的服务列表进行负载均衡算法后进行调用。当ribbon和open feign结合后，主要是通过feignloadBalancer去进行负载均衡，ribbon会注册一个IloadBalancer，feignclient通过loadbalancerFeignClient调用feignloadbalancer的executeWithLoadBalancer方法使用IloadBalancer算法选择一个服务节点。
   5. eureka和nacos区别：eureka保证AP，nacos支持CP+AP，eureka有自我保护机制，即当server节点在短时间内丢失了过多的心跳时，会进入保护机制，这时不会剔除心跳超时的服务，同时不同步服务列表到其他server节点上，当网络稳定后再进行节点间同步，优先保证CP。nacos的保护机制是当某个服务的健康实例过少时，会将不健康的实例返回给client，保证其余健康实例也能返回给client。nacos还支持配置中心。
9. redis 多线程模型（6.0）、集群运行、路由算法
      1. redis单线程实现，多线程实现  io多路复用和事件分派器，io读取采用多线程
      2. redis集群运行 主备，哨兵，集群
      3. redis集群复制以及通信
         1. 如何判断节点的角色，当启动两个节点时，默认都是master，当一个节点发送slaveof mastrip masterport命令给另一个节点时，此节点就会成为slave节点。当从节点先主节点发送slaveof no one命令时，会主动断开连接。slaveof可以在配置文件，启动参数以及手动命令开启。
         2. 主从复制流程：slave节点向主节点发送slaveof命令成为slave节点->slave节点发送PING命令确认master节点是redis实例->master节点返回PONG命令代表master节点准备完成->slave节点发送SYNC命令请求同步数据->master节点将slave节点加入列表，同时启动一个子线程保存RDB文件，文件保存成功后向slave节点传输->slave节点获取到RDB文件后在本地加载。
         3. SYNC命令会通知master节点进行RDB文件的生成，在高并发情况下会对master节点和slave节点的效率有影响，所以redis引入了PSYNC命令，PSYNC命令有两种模式，全量复制和部分复制，全量复制会将master节点的所有数据发送给slave，重型操作，一般在初次复制或者部分复制无法使用的情况。部分复制会将maste节点在slave节点断开连接的时间内写入数据发送给slave节点，相比全量复制更为高效，但是当slave节点断开连接时间过长导致无法master节点无法保存写入数据时，任会采用全量复制，数据维护是在主从节点分别维护对应的复制偏移量，重连后通过对比确认需要复制的数据。
      4. redis路由算法，hash solt，16384
      5. 项目中使用场景，缓存
      6. redis在集群下读取到最新的数据，强制读取master节点
      7. 分布式锁,red lock，大部分节点在指定时间内加锁成功则视为成功。
      8. red lock超时续期，redisson加锁时会在后台启动一个watch dog线程，定时查询key的有效时间，默认10s，当锁过期时会自动进行续期操作。
      9. zset数据结构，sorted set，value-sort结构，当存储的元素较少时，使用ziplist的方式存储数据，ziplist是redis实现的一种压缩列表结构，使用连续完整的内存空间来存储ziplist，每个节点存储元素和sort，元素在前，sort在后，支持顺序和倒序查找，但是在插入和删除时会涉及到其他元素的移动，所以当元素数量增大时，采用dict（hashMap）+skiplist来存储数据，skiplist存储sort和元素，并且使用sort作为索引来排序，可以根据sort查询元素，精确或范围查询，dict存储的是元素和sort结构，用来解决在通过元素查询sort时skiplist查询过慢的问题。ziplist转为zset的要求是当Sorted Set存储的数据大于128个或者Sort Set存储的数据长度大于64字节。
      10. 基本命令
          1. 获取Sorted Set指定排名数据：ZRANG key start end [WITHSCORES ]：返回指定排名的数据，WITHSCORES同时返回排序。
      11. 分布式锁的底层实现，
      12. 缓存设计，穿透，雪崩，击穿
          1. 雪崩：定时缓存的大批数据同一时间失效。解决，存储时采用随机过期时间，保证在同一时间失效的数据不多，或者不设置失效时间，手动更新缓存
          2. 穿透：缓存和数据库内没有数据，导致一直访问数据库，增加数据库压力。解决，参数校验，比如id<=0不查询数据库，设置空缓存，布隆过滤器。
          3. 击穿：缓存的某个数据高频访问，导致数据失效时请求打入数据库。解决，数据不过期或者采用分布式锁。
      13. redis的过期策略如何实现，LRU有哪些算法
      14. redis集群命令和单点命令，redis的所有命令都可以在集群和单点上执行，只是执行逻辑不同，在集群上执行需要指定对应的分片信息，随机、所有或者特殊的节点上执行，但是scan指令比较特殊，scan指令是模糊匹配key，同时分页返回，但是在集群模式下，由于数据都是分片在不同节点上，分页时需要获取所有数据进行匹配，效率低。所以scan无法在集群模式下执行，需要自行实现分片获取和聚合。
      15. redis为什么容易收到攻击，redis默认端口为6379，当使用默认端口启动，同时没有设置密码时，可以使用本地redis客户端连接redis服务器，如果这时候redis的服务器权限又是root时，可以将自己的RSA公钥使用RDB的方式持久化在指定目录下，这样就可以使用RSA私钥登录服务器。
10. rocketMQ
    1. 哪些消息，普通消息，事务消息，顺序消息
    2. 事务消息，2PC，prepare，commit
11. kafka：
    1. 如何解决线上消息堆积，新建topic，更多数量的partition，消费者多实例消费
    2. kafka和RocketMQ的优缺点
       1. 存储可靠性：kafka异步刷盘，异步复制，rocketMQ异步/同步刷盘，异步/同步复制。
       2. 性能：RocketMQ写入不如kafka，kafka支持合并批量写入。
       3. 失败重试：Kafka不支持失败重试。
       4. 消息顺序：kafka和rocketMQ支持单个topic分区有序，但是kafka在broker宕机后消息会乱序，rocketMQ的broker宕机后会写入失败，保证消息的有序性
       5. 延时消息：rocketMQ支持延时消息，kafka不支持
       6. 消息过滤：rocketMQ在broker端过滤，支持tag和自定义过滤逻辑，kafka需要消费端自己实现过滤逻辑。
       7. DLQ(dead letter queue)：rocketMQ支持死信队列，kafka不支持，需要三方工具将消费失败消息写入专门的topic
       8. 回溯消息：rocketMQ支持时间回溯，kafka支持offset回溯
       9. 分布式事务：rocketMQ支持分布式事务消息，kafka不支持分布式事务消息
    3. kafka如何实现低延迟、高吞吐
       1. 批量提交消息：发送端使用批量提交，消费端也是批量拉取，减少网络IO延迟。
       2. 顺序读写：数据按照每个partition顺序写入log文件，写满了就重新写一个文件，读取时也是按照顺序读取，提升读取磁盘IO效率。
       3. pageCache：文件在内存中的副本，读取时先读取pageCache，没有时从磁盘中加载到pageCache，使用LRU清理pageCache，kafka的消息及时性高，pageCache的命中率高，读取性能提升，间接使写入数据的效率提升。
       4. 0拷贝：消息发送给消费端需要经过4步，数据从磁盘到内核缓冲区，内核缓冲区复制到用户缓冲区，用户缓冲区复制到socket缓冲区，socket缓冲区复制到网卡缓冲区，0拷贝是操作系统提供可以直接将内核缓冲区复制到socket缓冲区，节省一次复制，提高性能。java提供java.nio.channals.FileChannel的transferTo方法，封装了操作系统SendFile函数。
       5. 
    4. kafka可靠性相对低，kafka异步刷盘，异步复制，rocketMQ同步/异步刷盘、同步/异步复制。
    5. kafka如何保证顺序性，全局有序一个topic一个partition，局部有序同一顺序放在同一个partition中，Java里面如何设置
    6. kafka如何保证消息不丢失，每个partition可以拥有多个副本，设置ack=all，保证发送到partition的数据需要同步到所有副本之后才返回成功，但是会降低系统的吞吐量；设置replication.factory>=3，保证每个partition至少有三个分区；设置min.insync.replicas>1，保证至少写入2个副本才算写入成功；unclean.leader.election.enable=false,当leader副本发生故障时，follower中和leader数据相差较多的不会被选为leader，保证数据的最大可靠性。
    7. 全局有序如何实现，一个topic一个partition
12. nacos：
          1. nacos宕机后服务可用性，服务本地会缓存服务ip地址，宕机后还可以提供服务
          3. nacos注册流程，client启动时向nacos server注册数据，ip，port，server存储在双层map中，注册完成后client会启动心跳定时上报自身状态，同时server集群之间会进行数据同步，client在调用相关服务时会从server获取服务列表缓存在本地，同时本地开启定时任务更新本地缓存数据。当client在指定时间内未发送心跳时，则认为服务异常，剔除相关服务列表。
             3. nacos下线流程，下线后会通知nacos server，nacos server 更新完成后通知消费端更新服务列表
             4. ap和cp的区别，数据一致性协议不同，cp使用raft协议，ap使用distro协议，raft需要进行选主操作，选举期间无法对外服务，选举完成后，client的请求都会发送到leader处理，leader和follower进行同步，适合持久性服务。distro每个节点处理存储所有数据，写入数据时会异步同步给其他节点。适合临时性服务。
             5. nacos实现原理
13. mysql log、崩溃恢复
    1. 索引结构，B+ Tree
    2. mysql log有哪些 ，binlog， undo log，redo log
    3. mysql如何保证崩溃恢复之后事务不丢失，redo log，使用2PC，事务提交之前，redo log prepara，binlog写入，事务提交后redo log commit。回滚则使用undo log。
    4. 聚簇和非聚簇索引，主键和非主键
    5. 事务隔离级别，读未提交（脏读、幻读、不可重复读），读已提交（幻读、不可重复读），可重复读（幻读），串行化
    6. 可重复读如何解决幻读，根据查询不同，如果使用select，则是MVCC生成read view保证在一个事务内读取，但是如果在事务中使用修改操作（insert、delete、update），则会读取最新的记录，所以如果需要在更新时也避免幻读的产生。需要使用select ... for updte，select for update使用next-key lock来实现，recored lock+ gap lock来锁住记录，其他事务修改时会等待。
    7. update时是锁表还是锁行，使用索引，锁行，不使用索引，锁表。
    8. 最左匹配是否命中，abc索引，ab,ba,abc可以
    9. binlog 模式
       1. statment：默认，每一条修改记录都会存储，slave复制时会解析sql执行。
       2. row：基于行复制，会记录每一行数据的变更，slave复制时对每一行进行修改。避免存储过程或者function以及trigger的执行无法正确复制，但是会产生大量数据。
       3. mixed：会根据具体的sql来自动选择statment or row存储。
    10. 死锁场景和解决，mybatis plus执行saveOrUpdate(T entity,Wrapper<T> updateWrapper)时，会先尝试更新数据，更新不成功会去插入数据。更新操作主键不存在时会对主键加gap锁，插入数据时需要获取到插入锁。当两个事务并发执行时，A事务获取gapA，B事务获取gapB锁，A事务插入数据时发现gapB锁，等待B事务释放，B事务插入时发现gapA锁，等待A事务释放，这样就形成死锁。解决方法不使用自增主键，避免两个数据在相同范围内，同时使用saveOrUpdate(T entity)，先查询在判断是否更新。
    11. 唯一索引和普通索引区别，插入和查询效率比较，普通索引可以重复，唯一索引不能重复，普通索引需要查询到所有符合数据，唯一索引只需要查询唯一，插入时唯一索引需要判断索引是否存在
    12. 主从同步延迟，在写入高峰期时，主从复制会出现延迟，导致无法在从库即时查询到对应数据，由于从库同步时会将主库的并从操作串行化执行，所以在写入高峰期会出现延迟。对于需要查询的数据可以使用缓存，或者强制读取主库数据。
    13. 如何优化sql，索引失效场景，模糊匹配通配符开头，未遵循最左匹配，使用函数，计算，类型转化等，不等于，is not null，or前后存在非索引，order by。子查询等（会扫描外部查询的所有数据，然后每条数据传入子查询进行关联，可使用inner join关联查询）
        1. explain查看sql执行过程，避免全表扫描，当数据量太多导致sql无法优化时，需要考虑分库分表。
    14. explain的指标
        1. type：本次查询的表连接类型，ALL，index，range等
        2. key：最终选择的索引，using filesort，using temporary，using where，using index
        3. key_len：本地查询实际过滤索引长度
        4. rows：预计扫描行数
        5. Extra：额外信息，是否出现using filesort,using temporary
    15. 缓冲池
    16. 常用语句
        1. select *  from A union select * from B（聚合，同时去重，排序）
        2. select *  from A union all select * from B （聚合，不去重，不排序）
14. mybatis
    1. 数据映射底层原理。使用\<resultMap>标签或者sql的别名和entity对应，然后通过反射创建对象和属性赋值。
    2. #和\$区别，#传入的参数会默认为字符串，\$传入的参数会使用原始数据。#在预处理阶段会使用？代替，而\$则是简单替换，会更容易出现SQL注入，所以尽量使用#。
    3. 模糊查询使用\$还是#，使用#，采用concat('%','#{}','%')方式，或者"%"#{}"%"。
    4. 接口和SQL如何绑定，每个xml文件会有namespace，对应的是接口的全限定名，同时每个sql的id对应的是interface内部的方法名。
    5. mybatis的缓存，一级缓存，在一次会话中对于查询条件相同的sql，会进行一级缓存的设置，避免直接查库，提升性能。二级缓存，在不同的sqlSession中提供共享缓存。先查询二级缓存，然后一级缓存，最后查询数据库。
15. es集群运行，数据存储，filter和query区别
    1. es的数据存储结构，倒排索引，为doc内的每一个field建立倒排索引，对应存储相应的doc_ids，field称为term，doc_ids称为posting list,由于term的数据多，为了提升查询效率，es将term排序之后存储，称为term dictionary，为了进一步提升查询term效率，es将term dictionary的前缀构造成一个树，存储在内存中，称为term index，这样通过term index可以快速找到term dictionary的磁盘地址，从而提升es的查询效率。
    2. 倒排索引底层实现，正排索引是指通过文档-关键词的形式建立索引，倒排索引是通过关键词-文档的形式建立索引。
    3. filter和query：query是查询文档，返回文档，匹配度，排序等；filter是查询文档是否匹配
    4. 近实时，内存buffer，异步刷盘
    5. 深度分页，解决API，scroll和search_after，scroll是采用时间点的数据快照，在指定时间窗口内获取快照数据。search_after是从指定数据开始，查询偏移量，类似下拉加载。
    6. 新增字段如何处理，es对于每个字段建立索引，当新增字段时需要重建索引，所以新增字段需要重新建立表结构，然后同步数据，避免索引重建。
    7. 如何分词
16. flink
    1. event time和processing time，processing time指系统时间，当前时间窗口内处理的数据；event time指事件时间，事件发生时间为时间窗口
    2. 集群模式如何保证各个节点数据的可见性
    3. kafka接收消息，flink做计算，电量统计，按照设备进行分组，之后设置滑动窗口，统计指定时间间隔的电量，然后导入mysql。
17. canal
    1. 如何实现同步，监听binlog日志
    2. 如何保证在数据库高并发下数据的顺序性，通过外部MQ，将顺序数据写入kafka的partition，保证顺序性。
18. 系统
    1. 在高并发情况下如何保证服务不宕机以及接口效率
19. MQTT
    1. 和HTTP的优势，更加轻量级，设备端资源消耗少，双向数据交换，支持QOS
    2. 长连接如何保证服务端平滑发版不断开，两个服务端，分批次切换流量。
20. 算法 OR code
    1. 排序 冒泡*，选择，插入 O(n2)，并归，堆，快速 O(nlogn)
    2. 单例 双判断
21. 其他
    1. 雪花算法和redis分布式锁如何避免时间回拨问题，记录上一次生成id的时间戳，本地生成获取时间戳时和上次比对，如果出现时间回拨，则进行相应处理，最简单是等待时间大于上次再生成，但是对于高并发会阻塞影响性能；可以再上一次id的基础上累加，如果出现时间回拨，则在前一次id基础上累加。
    2. 列式数据库和行式数据库区别，行式数据库存储的基本单元的一行，一行存储完毕后再存储下一行，适合关系型数据库，一般用于基本的CRUD；列式数据库存储的基本单元是一列，将一列的数据存储完毕后再存储下一列，适合于大数据数据库，适合数据量大，更新不频繁，需要大量聚合运算的场景。
    3. 接口幂等如何保证，库存预扣如何保证幂等，使用数据库唯一索引保证只插入一次，乐观锁保证，悲观锁保证，token令牌，每次请求前获取唯一token，后端判断token存在则执行，不存在则不执行。
    4. 两个亿级数据如何快速去重，分治策略，将数据hash取模之后分别存储文件，然后对每一个文件使用hashSet去重。布隆过滤器，有误差，有可能存在，一定不存在。使用bitmap。
    5. 分布式锁除了redis和zk以外，数据库使用唯一约束特性，插入成功代表获取到锁，解锁则删除数据。
    6. paas和saas的区别，paas即平台服务，用户使用平台提供的编程语言、库、服务以及开发工具来创建、开发应用并进行部署，比如各种云服务提供商，人脸识别，短信服务、语音服务等。主要面向的是开发人员，可自行管理自己的应用。saas即软件服务，用户使用提供的应用程序，比如各种APP。
    7. tomcat支持多少请求，默认最大线程200，最大连接10000
    8. 秒杀系统，瞬时高并发场景，页面静态化，CDN，保证商品页面访问的正常，读多写少，查询库存走redis缓存，第一次为了避免缓存击穿，采用分布式锁来保证数据加载到缓存，或者提前预热数据。为了避免缓存穿透，采用布隆过滤器。对于库存扣减后生成订单的用户，需要进行支付操作，当支付不成功或者超时之后需要回滚库存，为了保证库存不超卖，数据库可以使用乐观锁限制，redis自减或者采用lua脚本。同时秒杀服务并发量高，采用异步MQ方式通知下单服务。同时需要对用户的点击请求做限流，ip，次数，验证码等限制用户提交频率。
    9. 工作中印象最深的难题，以及如何解决的？jaeger引发OOM问题，dump文件发现大量jaeger对象未释放，trace信息都是保存在ThreadlocalScopeManager的ThreadLoca变量中，由于逻辑使用异步方式，所以新创建的线程会创建新的threadlocal，我们为了能够在多线程中传递Threadlocal变量，使用了阿里的transmittable-thread-local，自定义ThreadlocalScopeManager，用TransmittableThreadLocal替换Threadlocal，同时在配置文件中修改默认ThreadLocalScopeManager为自定义ThreadLocalScopeManager。但是在线程池中线程没有销毁，同时我们没有调用scope的close方法，导致线程一直持有scope对象未释放，导致OOM。
    10. http的常用状态码，200，404，500，401没有认证，403拒绝响应（有认证但是无权限）
    11. 微博突发热点如何保证高可用和消息的及时性