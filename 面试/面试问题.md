1. java基础
   1. 基础类型的字节占用，最大最小值，int 4字节，-2^31~2^31-1，20亿。long 8字节，-2^63~2^63-1。short 2字节，byte 1字节。
   2. Object的方法，具体有toString，clone，equals，wait，notify，notifyAll，getClass，hashCode
   3. string，stringBuffer，stringBuilder，string采用final修饰数组，无法修改，所以需要创建新对象，stringbuffer和stringbuild没有使用final修饰数组，所以可以修改原数组，stringbuffer线程安全，stringbuilder线程不安全。string的不可变性是为了保证运行常量池的需要，保证在常量池中的字符串不可变，为了保证在多线程下同步的问题，由于string的不变性，hashcode不变，可以缓存hashcode。避免安全问题。
   4. 深拷贝和浅拷贝，String的拷贝，深拷贝，对象内的引用变量拷贝一份，浅拷贝，对象内的引用变量拷贝地址。
   5. 反射能够获取的信息，类信息，属性，方法，注解
   6. 泛型的作用，JDK 1.5之前没有泛型时，当需要定义集合类时，由于集合可以存储String、Integer等不同对象，只能定义为Object对象，但是这样当插入不同类型数据时需要手动进行类型转化，同时运行期可能出现类型转化错误，所以JDK 1.5出现泛型，创建时确定参数类型，类型转化判断提前到编译器。
      1. 类型安全，类型转化错误从运行期提前到编译期
      2. 消除强制类型转化，可以直接获取对应的类型，无需强制转化
   7. 泛型擦除，由于泛型是在编译器实现，所以在字节码层面不包含泛型的类型信息，这主要是为了保证和JDK 1.5之前的版本开发的依赖库进行兼容，因此泛型的类型是相同的，一般都是object类型，List<String>.class = List<Integer>.class，字节码层面都是List。这样如果通过反射调用List的add()方法就可以插入不同类型的数据，因为反射是在字节码层面去实现的。
   8. 泛型 extends和super的区别，extends T代表泛型的数据都是T的子类，获取的数据都可以转化成T，所以可以进行数据的读取，但是在插入时编译器无法判断子类数据之间是否有冲突，所以限制数据的插入。super T代表泛型的数据都是T的超类，甚至是Object，插入数据可以保证是T的超类，但是在获取时无法判断是T的哪个父类，甚至是Object的，所以限制数据的获取。
   9. 注解的作用，可以对包，参数，类，接口，方法等添加标注，使用反射可以获取对应的标注信息。比如spring在类上添加@Component或者在属性上添加@Value，可以通过反射获取到对应的注解信息。
   10. java特性，使用场景，封装（将对象的属性隐藏在内部，只能用对外提供的方法操作属性，优势是出口统一，方便做统一处理；对外隐藏内部实现，修改无需改变方法调用），继承（在已有类的基础上创建新类，新类可在父类基础上新增功能，优势是可以提高代码的复用性，程序的可维护性，提升开发效率，子类拥有父类所有属性和方法，无法访问父类私有属性和方法），多态（一个对象在不同情况下有多种状态，父类引用实际指向子类的实例，运行期确认状态）
   11. 自定义注解使用场景，做统一处理，日志或者接口权限校验
   12. 抽象类使用，抽象子类同一属性。
   13. 设计模式使用场景，责任链、适配器、模板、策略模式、观察者
   14. for和foreach区别，foreach无法跳出循环，无法进行修改。foreach使用的是迭代器，内部使用next来进行遍历，会有额外操作，所以在大数据量下会比单纯的forloop效率低。
   15. function和consumer区别，function消费对象，需要有返回值，consumer消费对象，不需返回值。
   16. SPI，service provider interface，java内置的服务发现机制，java定义一个抽象接口，开发人员可自定义加载外部实现类来做到扩展和替换。类似JDBC和Dubbo等框架定义接口形式，开发可自行进行扩展和实现。主要是通过ServiceLoader来反射获取对应实现类，在配置完成接口和实现类后，需要在META-INF/services下新建对应接口的全限定名文件，然后文件内部配置实现类全限定名。然后通过ServiceLoader加载配置文件，然后通过反射实例化所有实现类，加载到内存中。缺点是一个接口多个实现需要全部遍历实例化，会破坏双亲委派原则，SPI直接使用classloader加载具体类。
   17. 反射
2. 集合
   1. Map实现类，HashMap put流程，resize过程
   2. HashMap、HashTable、ConcurrentHashMap线程安全和实现，hashMap线程不安全，hashTable线程安全，效率低，get，put都使用synchronized修饰，ConcurrentHashMap线程安全，1.7分段加锁，1.8单个node节点加锁
   3. CopyOnWriteArrayList多线程访问，写写加锁，读取时copy一份数据，读写不干扰。
   4. 有序map，TreeMap
   5. arrayList和LinkedList内存分配区别，ArrayList分配的是连续内存，LinkedList分配的是不连续内存。
3. 多线程
   1. volatile原理（内存屏障，可见性）、synchronized原理（互斥锁，重量级锁）
   2. synchronized和ReentrantLock区别（可重入，公平非公平锁，自动解锁，中断，唤醒指定线程）
   3. AQS 思想、实现类（通过同步器来实现互斥，队列存储线程（双向链表），Reentrantlock，Simphore，CountDownLatch、CyclicBarrier），公平和非公平区别，非公平锁比公平锁多一次CAS操作。
      1. 如何判断可重入，线程获取到锁时会将exclusiveOwnerThread设置为获取到锁的线程，当再次尝试获取锁时会判断线程是否一致，如果一致则重入。
      2. 等待队列的线程是如何等待和唤醒的，等待队列结构是双向链表结构，每一个节点保存了前驱指针，后驱指针，当前节点线程和等待状态。当线程进入等待队列时，会判断等待队列是否有队尾数据，没有则会初始化一个线程为空的等待队列节点作为头节点，当前线程放在头节点之后。入队操作都是采用CAS方式，当失败时会一直循环直到加队成功。至于为什么需要初始化一个空线程作为头节点，因为在设计中，等待队列中线程的唤醒是需要前驱节点来触发的，所以为了保证流程统一，所以需要创建一个虚节点来作为头节点。当等待队列构建完成后，线程本身还处在运行状态，所以需要对线程进行阻塞操作，但是如果一开始就进行阻塞操作，需要进行用户态和内核态的转化，开销较大。所以在进入队列以后，线程首先判断当前节点的前驱节点是否是头节点，如果是，代表当前节点是等待队列最前面的节点，这时会尝试进行加锁操作，如果获取锁成功，会把等待队列的头节点设置为当前节点，原来的头节点出队，等待GC回收。当前节点的前驱节点不是头节点时，代表队列中还有等待的节点，这时会判断前驱节点的状态，节点的等待状态有SIGNAL(线程需要唤醒)，CANCELLED(线程已中止)，CONDITION（线程等待条件），PROPAGATE（线程无需条件）。当前驱节点状态为SIGNAL时，代表前驱节点需要被唤醒，所以当前节点需要阻塞park。当前驱节点是CANCELLED时，代表前驱节点已中止，则会持续遍历前驱节点，将所有中止的节点剔除出队。其他状态则需要把前驱节点设置为SIGNAL，因为只有这样当前节点才能阻塞。当节点自选或者阻塞失败时，会把当前节点的状态改为CANCELLED，然后中断线程。至于唤醒操作就是在解锁时通知头节点以后第一个状态不为CANCELLED的节点，遍历方式是从尾节点向前遍历。由于线程入队的操作不是原子性的，是先将当前节点的前驱设置为队尾，然后队尾的后驱设置为当前节点，如果从头遍历，正好在第一步和第二部之间，就无法获取到后驱节点，也就有线程无法被唤醒，所以采用从后往前遍历。
   4. CAS，具体实现类有哪些（JUC下atomic包，AtomicInteger，AtomicBoolean，AtomicReference，getAndSet，compareAndSet）
   5. 如何确定线程池初始化数量，CPU密集型（一些逻辑运算）使用cpu+1，IO密集型（文件网络操作）使用2*cpu。线程池线程数量为什么不能设置很大，由于CPU的核心数是固定的，当正在运行的线程数大于CPU核心时，需要操作系统进行调度，给每个线程分配时间片资源，然后进行不停切换，从而才能达到”并行”的效果，但是这样频繁的进行线程之间的切换，会导致CPU在切换上耗费时间。所以对于CPU密集型，线程数量不能比CPU核心数多太多，因为这类操作对CPU负载很大，如果再进行频繁的线程切换，会导致并发效率低。IO密集型因为主要是需要等待IO操作的返回，对于CPU的负载不高，而且等待期间可以切换其他线程执行，所以IO密集型可以适当增加线程数，提高并发效率。
   6. 线程池为什么需等待队列满后才创建新线程，如何反转这个流程，由于创建线程需要获取到全局锁，会影响并发效率，所以线程池在核心线程满了以后会把任务放入等待队列中，是为了作为缓冲，避免线程创建引发的锁竞争。如果想反转这个流程需要自定义线程池，继承ThreadPoolExecutor，重写execute方法，同时需要自定义队列，继承LinkedBlockingQueue，重写offer方法，execute内部去创建新线程，同时自定义队列的offer去判断最大线程数来放入队列。tomcat线程池类似。
   7. 哪些线程安全的类，atomic，stringbuffer，concurrentHashMap，copyOnWriteArrayList
4. JVM
   1. jmm内存模型，原子性，可见性和有序性，原子性：赋值，可见性：内存屏障，有序性：指令重排
   2. 1.8的metaspace的gc和1.7的永久代gc的不同，都是在full gc过程中去回收内存，永久代是根据对象的可达性分析去回收，元空间是判断对象的类加载器ClassLoader是否可以回收来回收对象。
   3. 内存分配方式，空闲列表（free list）和碰撞指针（bump pointer）
   4. 对象回收判断方法，引用计数法和可达性分析，引用计数法如何解决循环引用，使用recycler算法解决
   5. GC Root，必须是一组活跃的引用，即全局引用变量以及栈内的引用变量。活跃线程栈帧的引用变量；类的静态引用变量；已被加载的java类以及类加载器；JNI句柄；方法区常量池中的引用；被synchronized持有的引用对象等。
   6. 常见垃圾回收器，CMS（并发老年代），G1（并发新老代，分区），Serial（新生代串行），Serial Old（老年代串行）
   7. JVM的GC有哪些，都是在哪些情况下出现，young gc（eden满）、old gc（老年代满了）、full gc（元空间满了）
   8. gc的stw，如何高效进行垃圾回收
   9. full GC，老年代或者元空间内存不足，如何解决，调高新生代内存分配，
   10. 如何判断CPU升高原因，top查看进程CPU占用，查找CPU占用过高的进程，然后查询进程下占用CPU高的线程，然后使用jstack显示堆栈信息，是否有频繁GC，使用jstat查看GC次数，jmap下载dump文件查看堆栈快照。使用MAT分析dump文件。
   11. G1设置停顿时间的参数，MaxGCPauseMillis
   12. 大对象导致full gc解决，
       1. 调大新生代的内存，保证生命周期更长的对象才能进入老年代，Xmn
       2. 调整年龄代之间的比例，SurvivorRatio（eden和Survivor比例），NewRatio（新生代和老年代比例）
       3. 调大进入老年代的GC年龄，InitialTenuringThreshol
       4. 调大对象直接分配在老年代的阈值，PretenureSizeThreshold
       5. 调大垃圾回收时老年代内存占用的阈值，CMSInitiatingOccupancyFraction
5. spring AOP底层实现
   1. 静态代理：代理类和真实类实现相同接口，动态代理：真实类实现接口（反射）、cglib：真实类继承父类（ASM，拦截器）
   2. 流程 annotation->注入AnnotationAwareAspectJAutoProxyCreator Bean->BeanPostProcessor处理->获取所有切面通知组装成链表->使用JDK或者cglib生成代理对象->方法调用时动态代理使用invoke方法增强，cglib会调用第一个拦截器的intercept方法->筛选通知链表->链式调用通知->调用真实方法
6. spring 容器启动流程 prepareRefresh（预处理，开始时间和活跃标志，property source初始化）-> obtainFreshBeanFactory（刷新beanfactory，xml注入需要销毁重新加载，annotation设置ID）-> prepareBeanFactory（设置beanfactory class loader，设置忽略自动装配和进行自动装配的接口）-> postProcessBeanFactory（子类实现自定义beanfacotoryPostprocessor）-> invokeBeanfactoryPostProcess（顺序执行beanfactoryPostProcessor，手动指定，实现PriorityOrder接口，实现Order接口，剩余beanfactoryPostProcessor）-> registerBeanPostProcessor（注册BeanPostProcessor，顺序和上面一样）-> initMessageSource（国际化、消息绑定与解析）-> initApplicationEventMulticaster（初始化事件广播器）-> OnRefresh（子类自定义刷新逻辑）-> registerListeners（注册监听器，接收广播器事件派发）-> finishBeanFactoryInitialization（初始化所有单例bean）-> finishRefresh（清理缓存，初始化生命周期后置处理器，回调生命周期后置处理器OnRefresh，发布刷新事件）-> restCommonCaches（重置反射元数据缓存）
   1. bean的生命周期，初始化->设置属性->调用自定义Aware接口实现->beanPostProcessor前置处理->afterProperties->调用init->beanPostProcessor后置处理->使用->销毁调用destory方法
   2. beanFactory和factoryBean区别：beanFactory是一个工厂类，是IOC的核心接口，用于实例化、定位、配置以及管理对象之间的的依赖，定义了IOC底层的编程规范。factorybean是一个bean，是一个能够生产或者修饰对象的工厂bean。beanFacotry只提供了基本的依赖注入、依赖查找，而factorybean则提供了复杂bean的创建，比如代理对象的创建等。
   3. beanfactoryPostprocessor和beanPostprocessor，beanfactoryPostprocessor是在beanfactory完成所有beanDefinition的加载后的自定义操作，由于这时候bean还未实例化，所以一般是用于bean属性的覆盖或者新增。beanPostProcessor是在bean完成实例化后，进行初始化方法的前后进行自定义操作，由于这时bean已经实例化，无法修改属性或者新增，所以一般是做一些bean初始化前后的统一处理，或者获取bean的注解信息进行其他逻辑处理。
   4. 自定义bean
   5. 事务传播级别
      1. PROPAGATION_REQUIRED：存在则合并，否则新建事务
      2. PROPAGATION_SUPPORTS：存在则合并，否则就没有事务
      3. PROPAGATION_MANDATORY：存在则合并，否则就报错
      4. PROPAGATION_REQUIRES_NEW：创建新事务，存在则挂起旧事务
      5. PROPAGATION_NOT_SUPPORTED：非事务运行，存在则挂起旧事务
      6. PROPAGATION_NEVER：非事务运行，存在则报错
      7. PROPAGATION_NESTED：存在事务则嵌套，否则就新建事务
   6. 如何判断有没有事务
   7. 循环依赖，三级缓存，singletonObjects（初始化完成的bean），earlySingletonObjects（实例化未初始化的bean），singletonFactories（进入实例化阶段的单例工厂bean），三级缓存逐级查询，首先放在三级缓存中，实例化后放在二级缓存，初始化后放在一级缓存中，三级缓存的目的是为了保证注入是代理对象，因为代理对象是在bean的后置处理器生成的，如果只有两级缓存就无法获取代理对象，所以需要三级缓存来处理注入代理对象的问题。
   8. 如何构建一个starter，spring boot 启动时会有自动装配的过程，即会在对应依赖包resources/META-INF路径下查找spring.factories文件，加载自动配置的bean到IOC容器中，所以构建一个自定义starter，首先创建一个spring项目，引入spring boot starter依赖，然后创建一个自动配置类，使用@Configuration和@Bean注解，然后再项目的resources/META-INF目录下创建spring.factories文件，文件配置对应的类，org.springframework.boot.autoconfigure.EnableAutoConfiguration=配置类全限定名。然后构建完成后就可以再起来项目中使用。
   9. 自动装配设计，通过扫描依赖包resources/META-INF/spring.factories文件，将文件配置中的类信息加载到spring容器中，并执行类中定义的各种操作，无需配置xml文件即可使用三方依赖组件的功能。
   10. 自定义注解实现，创建一个类，使用@interface修饰，设置@Targe，@Retention，@Targe代表注解的作用范围（METHOD，PARAMETER，FIELD），@Retention代表注释的生命周期（RUNTIME，CLASS，SOURCE）
   11. 如何集成tomcat，启动时会触发refresh方法，内部有OnRefresh方法，对应的子类实现有ServletWebApplicationContext，对应的实现会去createWebServer，默认实现的容器有JettyServletWebServerFactory，TomcatServletWebFactory和UndertowServletWebFactory。
7. spring mvc，解决了在java web开发中使用Servlet的复杂度，通过Model-View-Controller的结构，对外屏蔽Servlet的原始方法，开发者更加注重于API相关设计和开发。
8. spring cloud
   1. spring feign设置header，使用ResquestMapping的header属性
   2. openfeign流程：Spring启动根据@EnableFeignClients定义的包路径扫描所有被@FeignClient修饰的接口，同时将接口转化成bean->接口经过MVC Contract协议解析，将方法上的MVC注解解析成MethodMetadata->对于每一个接口都会生成一个代理类，代理类持有每个方法对应的Method Handler->服务调用接口的方法->代理类找到对应方法的Method Handler，获取对应的MethodMetadata，组装成对应的Request请求->通过负载均衡算法找到服务的实例信息，拼接对应的URL，发起HTTP调用。
   3. openfeign底层原理，spring容器启动时，根据@enableFeignclient注解设置的的路径扫描所有使用@FeignClient注解的接口，将这些接口解析成beanDefinition进行注入，当注入这些bean时会尝试在容器中寻找对应的实现类，当没有时。feign会为对应接口创建一个代理对象注册到容器中，最终会注入代理对象，当进行调用时，会统一转发到feign实现的InvocationHandler中，InvocationHandler负责将接口的参数，地址转化为HTTP调用，使用restTemplate发送到服务端，同时解析服务端返回参数成Java对象。
   4. spring gateway
      1. 三大概念：路由（Route）、断言（Predicate）、Filter（过滤），route配置id，uri，predicate和filter，通过predicate来实现路由的匹配规则，filter去做过滤器逻辑。
      2. 工作流程：客户端请求，gateway通过gateway handler Mapping找到匹配路径的路由，发送给gateway web handler，handler通过filter chain进行过滤操作，比如修改请求头，参数校验，权限校验等，过滤后转发到对应服务进行业务处理。响应返回时再经过过滤后返回客户端。
      3. zuul的区别，gateway内部实现了限流、负载均衡、熔断等。zuul没有。gateway支持异步（webflux），zuul只支持同步。
      4. 如何做限流，在gateway拦截器中使用RequestRateLimiterGatewayFilterFactory来使用redis作为限流
      5. 限流算法，固定窗口，滑动窗口，漏桶，令牌桶
   5. ribbon底层实现，使用restTemplate的拦截器，在RPC调用前通过LoadBalanceInterceptor进行负载均衡。ribbon中定义了LoadBalanceInterceptor类，然后注入到restTemplate中，然后在restTemplate远程调用时，拦截RPC调用，对注册中心的服务列表进行负载均衡算法后进行调用。当ribbon和open feign结合后，主要是通过feignloadBalancer去进行负载均衡，ribbon会注册一个IloadBalancer，feignclient通过loadbalancerFeignClient调用feignloadbalancer的executeWithLoadBalancer方法使用IloadBalancer算法选择一个服务节点。
   6. hystrix实现，
   7. eureka和nacos区别：eureka保证AP，nacos支持CP+AP，eureka有自我保护机制，即当server节点在短时间内丢失了过多的心跳时，会进入保护机制，这时不会剔除心跳超时的服务，同时不同步服务列表到其他server节点上，当网络稳定后再进行节点间同步，优先保证CP。nacos的保护机制是当某个服务的健康实例过少时，会将不健康的实例返回给client，保证其余健康实例也能返回给client。nacos还支持配置中心。在节点下线后，nacos可以通过通知的方法发送给client，eureka则只能通过定时同步机制去删除。
9. redis 多线程模型（6.0）、集群运行、路由算法
      1. redis单线程实现，多线程实现  io多路复用和事件分派器，io读取采用多线程
      2. redis集群运行 主备，哨兵，集群
      3. redis集群复制以及通信
         1. 如何判断节点的角色，当启动两个节点时，默认都是master，当一个节点发送slaveof masterip masterport命令给另一个节点时，此节点就会成为slave节点。当从节点向主节点发送slaveof no one命令时，会主动断开连接。slaveof可以在配置文件，启动参数以及手动命令开启。
         2. 主从复制流程：slave节点向主节点发送slaveof命令成为slave节点->slave节点发送PING命令确认master节点是redis实例->master节点返回PONG命令代表master节点准备完成->slave节点发送SYNC命令请求同步数据->master节点将slave节点加入列表，同时启动一个子线程保存RDB文件，文件保存成功后向slave节点传输->slave节点获取到RDB文件后在本地加载。
         3. SYNC命令会通知master节点进行RDB文件的生成，在高并发情况下会对master节点和slave节点的效率有影响，所以redis引入了PSYNC命令，PSYNC命令有两种模式，全量复制和部分复制，全量复制会将master节点的所有数据发送给slave，重型操作，一般在初次复制或者部分复制无法使用的情况。部分复制会将maste节点在slave节点断开连接的时间内写入数据发送给slave节点，相比全量复制更为高效，但是当slave节点断开连接时间过长导致master节点无法保存写入数据时，仍会采用全量复制，数据维护是在主从节点分别维护对应的复制偏移量，重连后通过对比确认需要复制的数据。
      4. redis选主流程：redis cluster节点之间使用gossip通信，进行元数据交换，更新->某一个节点ping其他节点没有响应时，则认为这个节点pfail（主观宕机）->向所有节点发送该节点宕机信息->当半数以上的节点认为该节点宕机时，则认为该节点fail（客观宕机）->当该节点是master节点时，会进行选主操作->检查每个slave节点和master节点断开连接时间，超过cluster-node-timeout*cluster-slave-validity-factor，则不满足选主需要->剩下的slave节点根据自己复制数据的offset来设置选举时间，offset越大的，选举时间越前->其他的master的节点给slave节点投票，获得半数以上master节点投票的slave节点选举成新的master节点->slave节点执行slave no one命令退出从节点模式，切换为主节点->通知其他节点
      5. redis路由算法，hash solt，16384
      6. 项目中使用场景，缓存
      7. redis在集群下读取到最新的数据，强制读取master节点
      8. 分布式锁,red lock，大部分节点在指定时间内加锁成功则视为成功。
      9. red lock超时续期，redisson加锁时会在后台启动一个watch dog线程，定时查询key的有效时间，默认10s，当锁过期时会自动进行续期操作。
      10. zset数据结构，sorted set，value-sort结构，当存储的元素较少时，使用ziplist的方式存储数据，ziplist是redis实现的一种压缩列表结构，使用连续完整的内存空间来存储ziplist，每个节点存储元素和sort，元素在前，sort在后，支持顺序和倒序查找，但是在插入和删除时会涉及到其他元素的移动，所以当元素数量增大时，采用dict（hashMap）+skiplist来存储数据，skiplist存储sort和元素，并且使用sort作为索引来排序，可以根据sort查询元素，精确或范围查询，dict存储的是元素和sort结构，用来解决在通过元素查询sort时skiplist查询过慢的问题。ziplist转为zset的要求是当Sorted Set存储的数据大于128个或者Sort Set存储的数据长度大于64字节。
      11. 基本命令
          1. 获取Sorted Set指定排名数据：ZRANG key start end [WITHSCORES]：返回指定排名的数据，WITHSCORES同时返回排序。
      12. 分布式锁的底层实现，每个节点上SETNX，超时放弃，半数以上节点设置成功并且没有超过过期时间则认为加锁成功。
      13. 缓存设计，雪崩、穿透、击穿
          1. 雪崩：定时缓存的大批数据同一时间失效。解决，存储时采用随机过期时间，保证在同一时间失效的数据不多，或者不设置失效时间，手动更新缓存，提前预热数据。增加二级缓存。
          2. 穿透：缓存和数据库内没有数据，导致一直访问数据库，增加数据库压力。解决，参数校验，比如id<=0不查询数据库，设置空缓存，布隆过滤器。
          3. 击穿：缓存的某个数据高频访问，导致数据失效时请求打入数据库。解决，数据不过期或者采用分布式锁。
      14. redis的过期策略如何实现，LRU有哪些算法，近似LRU。
      15. redis如何实现hash某一个field的ttl，采用定时任务或者监听的方式，将field+time作为key设置ttl，监听对应过期删除事件来删除对应的field。
      16. redis集群命令和单点命令，redis的所有命令都可以在集群和单点上执行，只是执行逻辑不同，在集群上执行需要指定对应的分片信息，随机、所有或者特殊的节点上执行，但是scan指令比较特殊，scan指令是模糊匹配key，同时分页返回，但是在集群模式下，由于数据都是分片在不同节点上，分页时需要获取所有数据进行匹配，效率低。所以scan无法在集群模式下执行，需要自行实现分片获取和聚合。
      17. redis为什么容易收到攻击，redis默认端口为6379，当使用默认端口启动，同时没有设置密码时，可以使用本地redis客户端连接redis服务器，如果这时候redis的服务器权限又是root时，可以将自己的RSA公钥使用RDB的方式持久化在指定目录下，这样就可以使用RSA私钥登录服务器。
      18. redis底层数据结构
          1. SDS：简单动态字符串，string类型底层结构，由于redis底层使用C编写，C对于字符串操作效率比较低，所以redis使用SDS结构替代C底层的字符串操作，通过新增len，alloc和flags数据来解决字符串时间复杂度，缓存区溢出以及节省内存。
          2. 双向链表：List底层数据结构之一，数据内存分配不连续。
          3. 压缩列表：当数据量较少时会采用压缩列表，是由连续内存块组成的顺序型数据结构。list，hash，zset数据量少时会采用。
          4. 哈希表：K-V数据结构，采用数组+单向链表方式存储。
          5. 整数集合：Set底层数据结构之一，内存分配连续的数组。
          6. 跳表：Zset底层数据结构，将sort作为跳表索引，加快查询和排序效率。
      19. rehash，由于redis对于hash采用数组+链表方式存储，当hash冲突频繁时，会导致链表长度增加，查询效率降低。redis采用rehash的方式解决，当hash数据增多时，会新分配一个hash表，容量是原来的2倍，然后将原数据迁移至新hash表中，同时将原hash表释放。但是当原数据过大时，在迁移过程中会导致redis阻塞，无法处理其他请求，所以redis采用渐进式rehash方式。当Redis对数据进行操作时会判断是否需要rehash，即查询、新增，修改，删除等操作，会迁移一个bucket内的数据到新hash表中，然后再执行对应的操作命令，将rehash的操作分摊到每一个操作中，降低rehash的工作开销。在rehash过程中，数据的操作都需要在两个hash表中去完成，查询会先查询原表，然后再查新表，新增会只在新表中插入。rehash的触发条件是hash的负载因子>=1，并且redis没有进行RDB获取AOF重写时，或者负载因子>=5。
      20. LRU和LFU实现：
          1. LRU最近最少使用的key，可以使用链表结构，然后将访问频繁的放在队头，内存不足时从队尾删除。但是redis的数据量大，移动数据需要的消耗较大，所以redis采用时钟+近似LRU来实现，redis每个对象内记录了最新一次访问的时间戳，redis启动时会初始化一个大小固定的待淘汰候选key的集合，默认是16。当触发内存淘汰时，根据LRU设置随机取出一定数量的key，默认是5，然后更新待淘汰集合，更新流程是获取集合中比当前key空闲时间大的数据最小下标k，由于集合根据空闲时间排序，所以k以及后面的数据的空闲时间都比当前key大。如果集合未满，则右移k后所有数据一位，并且插入当前key到k位置，如果集合已满，则将k左边的数据左移一位，移除开头的数据，然后插入当前key到k-1位置。集合根据key的空闲时间从小到大排序，然后淘汰集合最后一个不为null的key。通过固定大小集合，删除集合内访问时间更久的数据，实现近似LRU算法。
          2. LFU最不频繁使用的key，依据key的访问频率。redis在对象中记录最后一次访问的时间和访问次数，当key被访问时，需要根据上次访问的时间来减少访问次数，因为LFU根据访问频率，当两次访问时间间隔较长时，访问的频率也需要随之降低。所以再更新访问时间的同时会根据访问时间差来衰减访问次数。默认使用分钟来计算，相差多少分钟则衰减多少次，最多减少到0。再衰减完访问次数后，会根据设置的阈值p和随机数r比较来增加访问的次数，当r<p时才会使访问次数+1，最大255。当触发内存淘汰时，LFU和LRU大体步骤一致，首先初始化待淘汰集合，然后根据访问次数近似访问频率做插入和排序，将访问次数大的排在前，淘汰访问次数小的，使用访问次数来近似访问频率实现LFU算法。
      21. RDB和AOF触发
          1. RDB：手动执行bgsave或者save，自动执行需要在config设置 save m n 参数，m是时间窗口，默认是s，n是key的变动次数，save m n代表在m秒中有n个key发生变化则执行RDB，可以设置多个，任一匹配则触发。执行flushall或者主从同步时也会触发RDB。
          2. AOF：手动执行gbrewriteaof，自动需要设置aof触发策略，always，everysec或者no，基本采用everysec。
10. rocketMQ
    1. 哪些消息，普通消息，事务消息，顺序消息
    2. 事务消息，2PC，prepare，commit
    3. 消息失败重试如何实现，消息在rocketMQ有5种状态，ready（就绪），inflight（处理中），waitingretry（待重试），commit（提交），DLQ（死信状态）。当消费者消费消息时在处理中状态，当消费超时或者失败时，会触发失败重试，同时消息状态为待重试，当重试到达设置次数时，会变成死信状态，投递到死信队列。
11. kafka：
    1. 如何解决线上消息堆积，新建topic，更多数量的partition，消费者多实例消费
    2. kafka和RocketMQ的优缺点
       1. 存储可靠性：kafka异步刷盘，异步复制，rocketMQ异步/同步刷盘，异步/同步复制。
       2. 性能：RocketMQ写入不如kafka，kafka支持合并批量写入。
       3. 失败重试：Kafka不支持失败重试。
       4. 消息顺序：kafka和rocketMQ支持单个topic分区有序，但是kafka在broker宕机后消息会乱序，rocketMQ的broker宕机后会写入失败，保证消息的有序性
       5. 延时消息：rocketMQ支持延时消息，kafka不支持
       6. 消息过滤：rocketMQ在broker端过滤，支持tag和自定义过滤逻辑，kafka需要消费端自己实现过滤逻辑。
       7. DLQ(dead letter queue)：rocketMQ支持死信队列，kafka不支持，需要三方工具将消费失败消息写入专门的topic
       8. 回溯消息：rocketMQ支持时间回溯，kafka支持offset回溯
       9. 分布式事务：rocketMQ支持分布式事务消息，kafka不支持分布式事务消息
    3. kafka如何实现低延迟、高吞吐
       1. 批量和压缩消息：发送端使用批量提交，消费端也是批量拉取，减少网络IO延迟。
       2. 顺序读写：有序性和不可变性，数据按照每个partition顺序写入segment log文件，写满了就重新写一个文件，读取时也是按照顺序读取，减少磁盘寻道时间，提升读取磁盘IO效率。
       3. pageCache：文件在内存中的副本，读取时先读取pageCache，没有时从磁盘中加载到pageCache，使用LRU清理pageCache，kafka的消息及时性高，pageCache的命中率高，读取性能提升，间接使写入数据的效率提升。
       4. 0拷贝：消息发送给消费端需要经过4步，数据从磁盘到内核缓冲区，内核缓冲区复制到用户缓冲区，用户缓冲区复制到内核态的socket缓冲区，socket缓冲区复制到网卡缓冲区，0拷贝是操作系统提供可以直接将内核缓冲区复制到socket缓冲区，节省一次复制，提高性能。java提供java.nio.channals.FileChannel的transferTo方法，封装了操作系统SendFile函数。
       5. 使用NIO，Reactor线程模型。IO多路复用。
       6. partition分区，通过增加partition来提高并发。
       7. 稀疏索引，提高查询消息效率。
       8. mmap
    4. kafka可靠性相对低，kafka异步刷盘，异步复制，rocketMQ同步/异步刷盘、同步/异步复制。
    5. kafka如何保证顺序性，全局有序一个topic一个partition，局部有序同一顺序放在同一个partition中，Java里面如何设置
    6. kafka如何保证消息不丢失，每个partition可以拥有多个副本，设置ack=all，保证发送到partition的数据需要同步到所有副本之后才返回成功，但是会降低系统的吞吐量；设置replication.factory>=3，保证每个partition至少有三个分区；设置min.insync.replicas>1，保证至少写入2个副本才算写入成功；unclean.leader.election.enable=false,当leader副本发生故障时，follower中和leader数据相差较多的不会被选为leader，保证数据的最大可靠性。
    7. 全局有序如何实现，一个topic一个partition
    8. kafka zk作用，Broker上下线处理，topic创建，partition扩容，副本leader选举，消费者分区，offset信息。client通过watcher来监听相关数据改变。新版本放弃zk存储元数据，自身集成部分zk功能，将元数据保存在partition中，通过raft协议保证一致性。
    9. kafka多副本选主流程，早期使用Zk的ZAB，新版本使用raft协议。
    10. partition和consumer分配，rebalance过程，一个topic下的一个partition只能分配给一个group下的一个consumer，当partition<consumer，会有consumer空闲，partition>consumer，会有consumer分配多个partition。rebalance是当partition和consumer数量发生变更或者由于consumer消费超时或者心跳超时导致被剔除时，会重新进行partition-consumer分配，但是rebalance会导致STW的出现，所以尽量将partition和consumer的数量保持一致，避免consumer空闲或负载较高。消费者加入group时会向协调者发送JoinGroup请求，第一个发送请求的consumer会成为群主，协调者将group列表发送给群主，群主执行partition分配策略后将结果通过SyncGroup发送给协调者，其他consumer也向协调者发送syncGroup，协调者将每个consumer的分配结果分别发送给对应的consumer。
    11. partition分配策略：
        1. Range：默认，对consumer排序，排序高的分配更多，P0，P1，P2，ConsumerA>ConsumerB，P0,P1->A,P2->B。订阅topic多会导致分配不均。
        2. RoundRobin：轮询，经过轮询分配。
        3. Sticky：粘性，尽量分配给上一个consumer，保证连接复用。
    12. kafka消息发送策略
        1. 发送并忘记，不管结果
        2. 同步发送，返回Future对象
        3. 异步发送，回调指定函数
    13. AR，ISR，OSR，AR（Assigned Replicas），所有的副本集合。ISR(InSyncReplicas)，和leader副本保持同步的副本集合，包括leader。OSR（Out of replicas），和leader副本同步滞后的副本集合。当副本和leader同步滞后太多，会将副本从ISR剔除，当OSR副本和leader保持同步后，会再次进入ISR，同时只有ISR的副本才能参与选举过程。
    14. kafka通信，broker启动会在zk上注册,同时订阅其他broker节点->producer启动后连接任一broker，获取所有broker信息->producer和所有broker建立TCP连接->producer发送消息->consumer连接任一broker，获取协调者broker->consumer和协调者broker建立TCP连接，获取元数据->获取partition分配->consumer和partition的leader副本的broker建立连接->消费消息。
    15. 保证消息不丢失
        1. producer：异步回调发送，失败重试，acks=all
        2. broker：多副本，写入副本数量，选举同步完成的follower成为leader
        3. consumer：手动提交offset
    16. 副本同步机制，HW（High watermark）代表副本之间已同步数据offset，HW以前的数据可以被consumer消费。LEO(log end offset) 代表副本中最后写入数据的offset。当leader节点写入数据时，还未同步到follower，leader的HW为0，LEO增加。当follower拉取消息后，follower的LEO增加，HW为0，当follower再次拉取数据时，leader会取follower中最小的LEO作为HW更新，同时将HW同步给follower，follower更新HW。
12. nacos：
       1. nacos宕机后服务可用性，服务本地会缓存服务ip地址，宕机后还可以提供服务
       2. nacos注册流程，client启动时向nacos server注册数据，ip，port，server存储在双层map中，注册完成后client会启动心跳定时上报自身状态，同时server集群之间会进行数据同步，client在调用相关服务时会从server获取服务列表缓存在本地，同时本地开启定时任务更新本地缓存数据。当client在指定时间内未发送心跳时，则认为服务异常，剔除相关服务列表，同时通知client更新本地服务列表。
       3. nacos下线流程，下线后会通知nacos server，nacos server 更新完成后通知消费端更新服务列表
       4. ap和cp的区别，数据一致性协议不同，cp使用raft协议，ap使用distro协议，raft需要进行选主操作，选举期间无法对外服务，选举完成后，client的请求都会发送到leader处理，leader和follower进行同步，适合持久性服务。distro每个节点处理存储所有数据，写入数据时会异步同步给其他节点。适合临时性服务。
       5. nacos如何通知客户端服务改变
       6. nacos实现原理
13. mysql log、崩溃恢复
    1. mysql一条查询如何执行的，客户端和mysql server连接器连接，负责客户端连接，权限管理->查看缓存中是否有对应数据，有则直接返回->词法分析器，语法分析器分析sql语句的正确性->优化器对索引选择，执行顺序进行自动优化->执行器操作存储引擎进行数据查询
    2. 索引结构，B+ Tree
    3. mysql log有哪些 ，binlog， undo log，redo log
    4. mysql如何保证崩溃恢复之后事务不丢失，redo log，使用2PC，事务提交之前，redo log prepara，binlog写入，事务提交后redo log commit。回滚则使用undo log。
    5. 聚簇和非聚簇索引，主键和非主键
    6. 事务隔离级别，读未提交（脏读、幻读、不可重复读），读已提交（幻读、不可重复读），可重复读（幻读），串行化
    7. 可重复读如何解决幻读，根据查询不同，如果使用select，则是MVCC生成read view保证在一个事务内读取，但是如果在事务中使用修改操作（insert、delete、update），则会读取最新的记录，所以如果需要在更新时也避免幻读的产生。需要使用select ... for updte，select for update使用next-key lock来实现，recored lock+ gap lock来锁住索引记录，其他事务修改时会等待。
    8. update时是锁表还是锁行，使用索引，锁行，不使用索引，锁表。
    9. 最左匹配是否命中，abc索引，ab,ba,abc可以
    10. binlog 模式
           1. statment：默认，每一条修改记录都会存储，slave复制时会解析sql执行。
           2. row：基于行复制，会记录每一行数据的变更，slave复制时对每一行进行修改。避免存储过程或者function以及trigger的执行无法正确复制，但是会产生大量数据。
           3. mixed：会根据具体的sql来自动选择statment or row存储。
    11. 死锁场景和解决，mybatis plus执行saveOrUpdate(T entity,Wrapper<T> updateWrapper)时，会先尝试更新数据，更新不成功会去插入数据。更新操作主键不存在时会对主键加gap锁，插入数据时需要获取到插入锁。当两个事务并发执行时，A事务获取gapA，B事务获取gapB锁，A事务插入数据时发现gapB锁，等待B事务释放，B事务插入时发现gapA锁，等待A事务释放，这样就形成死锁。解决方法不使用自增主键，避免两个数据在相同范围内，同时使用saveOrUpdate(T entity)，先查询在判断是否更新。
    12. 唯一索引和普通索引区别，插入和查询效率比较，普通索引可以重复，唯一索引不能重复，普通索引需要查询到所有符合数据，唯一索引只需要查询唯一，插入时唯一索引需要判断索引是否存在。唯一索引无法使用change buffer，普通索引可以使用change buffer，change buffer是指数据库会把数据页缓存在change buffer中，后续直接在change buffer中操作数据页，提升性能，后续定时将数据merge会磁盘。
    13. 主从同步延迟，在写入高峰期时，主从复制会出现延迟，导致无法在从库即时查询到对应数据，由于从库同步时会将主库的并从操作串行化执行，所以在写入高峰期会出现延迟。对于需要查询的数据可以使用缓存，或者强制读取主库数据。
    14. 如何优化sql，索引失效场景，模糊匹配通配符开头，未遵循最左匹配，使用函数，计算，类型转化等，不等于，is not null，or前后存在非索引，order by。子查询等（会扫描外部查询的所有数据，然后每条数据传入子查询进行关联，可使用inner join关联查询）
           1. 先运行看是否很慢
           2. 使用explain
           3. order by limit 让排序表优先查询
    15. 关联查询语句，left join（左表和部分右表），inner join（交集），right join（右表和部分左表），union（全表） ，left join是左表驱动右表，所以需要将小表放在左边，提高查询效率。inner join会自动进行选择，将小表作为驱动表，所以查询时尽量使用inner join。被驱动表会走索引，所以需要给大表建立索引。
    16. explain的指标
           1. select_type：查询类型，simple，Primary，union等
           2. type：本次查询的表连接类型，system>constent(常量，唯一或主键索引)>eq_ref（唯一或主键）>ref(最左匹配或普通索引)>fulltext（全文索引）>ref_or_null（ref的is null操作）>index_merge（索引合并）>range（范围索引查询）>index（全索引扫描）>All（全表扫描）
           3. key：最终选择的索引
           4. key_len：本地查询实际过滤索引长度
           5. rows：预计扫描行数
           6. Extra：额外信息，using index（覆盖索引），using index condition（索引下推），using filesort（外部索引文件排序），using where（条件过滤），using temporary（排序使用临时表）
    17. 索引下推，5.6出现的数据库优化，联合索引时，通过在索引文件中过滤数据来减少回表操作，提升查询性能。
    18. filesort优化，filesort表示需要进行额外排序，表示排序字段未走索引，所以需要保证排序字段能够走索引即可。
    19. 如何优化模糊查询中间匹配
           1. 采用索引下推，让模糊匹配的查询使用联合索引，并且触发索引下推，减少回表次数。
           2. 采用全文索引查询，match(field) against("a")。
    20. 缓冲池
    21. 主从复制流程，从库请求复制，主库创建binlog dump线程读取binlog日志发送给从库，从库将日志更新到relay log中，从库的SQL线程读取relay log在本地应用。
    22. mysql深分页问题，mysql分页是查询offset+limit条数据，然后抛弃offset条数据，所以如果在命中普通索引时，需要回表查询offset+count条数据，在分页深度比较高时会出现查询延迟，解决是采用游标上下滑动，或者采用覆盖索引减少回表次数。
    23. mysql count，count(field)统计字段不为null的行数,需要读取对应字段数据判断，count(*)和count(1)统计总行数，只需要累加。count执行时，会自动选择数据量小的普通索引去统计。
    24. 常用语句
           1. select *  from A union select * from B（聚合，同时去重，排序）
           2. select *  from A union all select * from B （聚合，不去重，不排序）
    25. mysql的锁有哪些，共享锁、排他锁，意向共享锁，意向排他锁，gap锁，record锁，next-key锁，插入意向锁。
14. mybatis
          1. 数据映射底层原理。使用\<resultMap>标签或者sql的别名和entity对应，然后通过反射创建对象和属性赋值。
          2. #和\$区别，#传入的参数会默认为字符串，\$传入的参数会使用原始数据。#在预处理阶段会使用？代替，而\$则是简单替换，会更容易出现SQL注入，所以尽量使用#，底层逻辑，在处理动态sql时，mybatis会进行预编译，能够对sql进行优化和重复使用。#会被替换成？占位符，执行时直接替换参数，而$则是在执行sql时直接使用变量替换。
          3. 模糊查询使用\$还是#，使用#，采用concat('%','#{}','%')方式，或者"%"#{}"%"。
             4. 接口和SQL如何绑定，每个xml文件会有namespace，对应的是接口的全限定名，同时每个sql的id对应的是interface内部的方法名。
             5. interface多个parameter如何绑定sql参数，根据@param参数名映射，或者根据bean的参数映射。
             6. mybatis的缓存，一级缓存，在一次会话中对于查询条件相同的sql，会进行一级缓存的设置，避免直接查库，提升性能。二级缓存，在不同的sqlSession中提供共享缓存。先查询二级缓存，然后一级缓存，最后查询数据库。
15. es集群运行，数据存储，filter和query区别
          1. es的数据存储结构，倒排索引，为doc内的每一个field建立倒排索引，对应存储相应的doc_ids，field称为term，doc_ids称为posting list,由于term的数据多，为了提升查询效率，es将term排序之后存储，称为term dictionary，为了进一步提升查询term效率，es将term dictionary的前缀构造成一个树，存储在内存中，称为term index，这样通过term index可以快速找到term dictionary的磁盘地址，从而提升es的查询效率。
          2. 倒排索引底层实现，正排索引是指通过文档-关键词的形式建立索引，倒排索引是通过关键词-文档的形式建立索引。
          3. filter和query：query是查询文档，返回文档，匹配度，排序等；filter是查询文档是否匹配，当使用query子句时会返回文档的匹配度，而filter不会。
          4. 近实时，内存buffer，异步刷盘
          5. 深度分页，解决API，scroll和search_after，scroll是采用时间点的数据快照，在指定时间窗口内获取快照数据。search_after是从指定数据开始，查询偏移量，类似下拉加载。
          6. 新增字段如何处理，es对于每个字段建立索引，当新增字段时需要重建索引，所以新增字段需要重新建立表结构，然后同步数据，避免索引重建。
             7. 如何分词
             8. 聚合查询
                 1. 简单统计，aggs
                     2. 嵌套统计，aggs嵌套aggs
             9. es不支持部分更新操作，实际的update是删除原来的doc，然后新建一个update之后的doc。
             10. es分布式保证
                    1. 可靠性：由于Lucene设计中不保证可靠性，es通过replica和translog保证
                    2. 一致性：es的NRT不能保证primary和replica数据的强一致，只能保证最终一致性、
                    3. 原子性：Lucene的add和delete通过version和锁保证原子性
                    4. 隔离性：version和锁保证版本隔离
                    5. 实时性：NRT
                    6. 性能：只需要特定数目replica返回数据，异步刷新数据到磁盘。
16. flink
       1. event time和processing time，processing time指系统时间，当前时间窗口内处理的数据；event time指事件时间，事件发生时间为时间窗口
       2. 集群模式如何保证各个节点数据的可见性
       3. kafka接收消息，flink做计算，电量统计，按照设备进行分组，之后设置滑动窗口，统计指定时间间隔的电量，然后导入mysql。
17. canal
       1. 如何实现同步，监听binlog日志
       2. 如何保证在数据库高并发下数据的顺序性，通过外部MQ，将顺序数据写入kafka的partition，保证顺序性。
18. 系统
       1. 在高并发情况下如何保证服务不宕机以及接口效率
19. MQTT
       1. 和HTTP的优势，更加轻量级，设备端资源消耗少，双向数据交换，支持QOS
       2. 长连接如何保证服务端平滑发版不断开，两个服务端，分批次切换流量。
20. 算法 OR code
       1. 排序 冒泡*，选择，插入 O(n2)，并归，堆，快速 O(nlogn)
       2. 单例 双判断
21. 其他
           1. 雪花算法和redis分布式锁如何避免时间回拨问题，记录上一次生成id的时间戳，本地生成获取时间戳时和上次比对，如果出现时间回拨，则进行相应处理，最简单是等待时间大于上次再生成，但是对于高并发会阻塞影响性能；可以再上一次id的基础上累加，如果出现时间回拨，则在前一次id基础上累加。
           2. 列式数据库和行式数据库区别，行式数据库存储的基本单元的一行，一行存储完毕后再存储下一行，适合关系型数据库，一般用于基本的CRUD；列式数据库存储的基本单元是一列，将一列的数据存储完毕后再存储下一列，适合于大数据数据库，适合数据量大，更新不频繁，需要大量聚合运算的场景。
           3. 接口幂等如何保证，库存预扣如何保证幂等，使用数据库唯一索引保证只插入一次，乐观锁保证，悲观锁保证，token令牌，每次请求前获取唯一token，后端判断token存在则执行，不存在则不执行。
           4. 两个亿级数据如何快速去重，分治策略，将数据hash取模之后分别存储文件，然后对每一个文件使用hashSet去重。布隆过滤器，有误差，对于存在的数据一定存在，但是对于不存在的数据可能返回存在。使用bitmap。
           5. 分布式锁除了redis和zk以外，数据库使用唯一约束特性，插入成功代表获取到锁，解锁则删除数据。
           6. paas和saas的区别，paas即平台服务，用户使用平台提供的编程语言、库、服务以及开发工具来创建、开发应用并进行部署，比如各种云服务提供商，人脸识别，短信服务、语音服务等。主要面向的是开发人员，可自行管理自己的应用。saas即软件服务，用户使用提供的应用程序，比如各种APP。
           7. tomcat支持多少请求，默认最大线程200，最大连接10000
           8. 秒杀系统，瞬时高并发场景，页面静态化，CDN，保证商品页面访问的正常，读多写少，查询库存走redis缓存，第一次为了避免缓存击穿，采用分布式锁来保证数据加载到缓存，或者提前预热数据。为了避免缓存穿透，采用布隆过滤器。对于库存扣减后生成订单的用户，需要进行支付操作，当支付不成功或者超时之后需要回滚库存，为了保证库存不超卖，数据库可以使用乐观锁限制，redis自减或者采用lua脚本。同时秒杀服务并发量高，采用异步MQ方式通知下单服务。同时需要对用户的点击请求做限流，ip，次数，验证码等限制用户提交频率。
           9. 工作中印象最深的难题，以及如何解决的？jaeger引发OOM问题，dump文件发现大量jaeger对象未释放，trace信息都是保存在ThreadlocalScopeManager的ThreadLoca变量中，由于逻辑使用异步方式，所以新创建的线程会创建新的threadlocal，我们为了能够在多线程中传递Threadlocal变量，使用了阿里的transmittable-thread-local，自定义ThreadlocalScopeManager，用TransmittableThreadLocal替换Threadlocal，同时在配置文件中修改默认ThreadLocalScopeManager为自定义ThreadLocalScopeManager。但是在线程池中线程没有销毁，同时我们没有调用scope的close方法，导致线程一直持有scope对象未释放，导致OOM。
           10. http的常用状态码，200，404，500，401没有认证，403拒绝响应（有认证但是无权限）
           11. 微博突发热点如何保证高可用和消息的及时性
           12. 分布式事务保证，2PC，prepara->commit(rollback)，同步阻塞，单点问题。3PC，canCommit->PreCommit->DoCommit。TCC，try->commit->cancel，代码侵入高。事务消息
           13. tcp和http,http1和http2，tcp是传输层，http是应用层，http是建立在tcp之上。http2二进制协议，多路复用，header压缩，服务端推送，数据流
           14. mqtt结构，mqtt和MQ，mqtt是协议，MQ是中间件，
           15. 优势，良好的时间管理，对于任务的分配。良好的团队合作。适应力强，新工作，新技术